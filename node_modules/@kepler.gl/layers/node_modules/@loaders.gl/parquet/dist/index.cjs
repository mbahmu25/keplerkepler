"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var __publicField = (obj, key, value) => {
  __defNormalProp(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};

// dist/index.js
var dist_exports = {};
__export(dist_exports, {
  Buffer: () => Buffer3,
  BufferPolyfill: () => Buffer2,
  GeoParquetLoader: () => GeoParquetLoader,
  GeoParquetWorkerLoader: () => GeoParquetWorkerLoader,
  ParquetColumnarLoader: () => ParquetColumnarLoader,
  ParquetColumnarWorkerLoader: () => ParquetColumnarWorkerLoader,
  ParquetEncoder: () => ParquetEncoder,
  ParquetLoader: () => ParquetLoader,
  ParquetReader: () => ParquetReader,
  ParquetSchema: () => ParquetSchema,
  ParquetWasmLoader: () => ParquetWasmLoader,
  ParquetWasmWorkerLoader: () => ParquetWasmWorkerLoader,
  ParquetWasmWriter: () => ParquetWasmWriter,
  ParquetWorkerLoader: () => ParquetWorkerLoader,
  _ParquetWriter: () => ParquetWriter,
  convertParquetSchema: () => convertParquetSchema,
  convertParquetToArrowSchema: () => convertParquetSchema,
  installBufferPolyfill: () => installBufferPolyfill,
  preloadCompressions: () => preloadCompressions
});
module.exports = __toCommonJS(dist_exports);

// dist/polyfills/buffer/buffer.js
var import_base64_js = __toESM(require("base64-js"), 1);
var import_ieee754 = __toESM(require("ieee754"), 1);
var kMaxLength = 2147483647;
var INSPECT_MAX_BYTES = 50;
var _Buffer = class extends Uint8Array {
  // not used by this implementation
  // length: number; inherited
  get parent() {
    if (!_Buffer.isBuffer(this))
      return void 0;
    return this.buffer;
  }
  get offset() {
    if (!_Buffer.isBuffer(this))
      return void 0;
    return this.byteOffset;
  }
  /** This property is used by `Buffer.isBuffer` (and the `is-buffer` npm package)
   * to detect a Buffer instance. It's not possible to use `instanceof Buffer`
   * reliably in a browserify context because there could be multiple different
   * copies of the 'buffer' package in use. This method works even for Buffer
   * instances that were created from another copy of the `buffer` package.
   * @see: https://github.com/feross/buffer/issues/154
   */
  _isBuffer = true;
  constructor(arg, encodingOrOffset, length) {
    if (typeof arg !== "number") {
      return _Buffer.from(arg, encodingOrOffset, length);
    }
    const size = arg;
    if (size > kMaxLength) {
      throw new RangeError(`The value "${size}" is invalid for option "size"`);
    }
    if (typeof encodingOrOffset === "string") {
      throw new TypeError('The "string" argument must be of type string. Received type number');
    }
    super(size < 0 ? 0 : checked(size) | 0);
    return;
  }
  static from(value, encodingOrOffset, length) {
    if (typeof value === "string") {
      return fromString(value, encodingOrOffset);
    }
    if (ArrayBuffer.isView(value)) {
      return fromArrayView(value);
    }
    if (value == null) {
      throw new TypeError(`${"The first argument must be one of type string, Buffer, ArrayBuffer, Array, or Array-like Object. Received type "}${typeof value}`);
    }
    if (isInstance(value, ArrayBuffer) || value && isInstance(value.buffer, ArrayBuffer)) {
      return fromArrayBuffer(value, encodingOrOffset, length);
    }
    if (typeof SharedArrayBuffer !== "undefined" && (isInstance(value, SharedArrayBuffer) || value && isInstance(value.buffer, SharedArrayBuffer))) {
      return fromArrayBuffer(value, encodingOrOffset, length);
    }
    if (typeof value === "number") {
      throw new TypeError('The "value" argument must not be of type number. Received type number');
    }
    const valueOf = value.valueOf && value.valueOf();
    if (valueOf != null && valueOf !== value) {
      return _Buffer.from(valueOf, encodingOrOffset, length);
    }
    const b = fromObject(value);
    if (b)
      return b;
    if (typeof Symbol !== "undefined" && Symbol.toPrimitive != null && typeof value[Symbol.toPrimitive] === "function") {
      return _Buffer.from(value[Symbol.toPrimitive]("string"), encodingOrOffset, length);
    }
    throw new TypeError(`${"The first argument must be one of type string, Buffer, ArrayBuffer, Array, or Array-like Object. Received type "}${typeof value}`);
  }
  /**
   * Returns true if {obj} is a Buffer
   *
   * @param obj object to test.
   */
  static isBuffer(b) {
    return b != null && b._isBuffer === true && b !== _Buffer.prototype;
  }
  /**
   * The same as buf1.compare(buf2).
   */
  static compare(a, b) {
    if (!_Buffer.isBuffer(a) && isInstance(a, Uint8Array))
      a = _Buffer.from(a, a.offset, a.byteLength);
    if (!_Buffer.isBuffer(b) && isInstance(b, Uint8Array))
      b = _Buffer.from(b, b.offset, b.byteLength);
    if (!_Buffer.isBuffer(a) || !_Buffer.isBuffer(b)) {
      throw new TypeError('The "buf1", "buf2" arguments must be one of type Buffer or Uint8Array');
    }
    if (a === b)
      return 0;
    let x = a.length;
    let y = b.length;
    for (let i = 0, len = Math.min(x, y); i < len; ++i) {
      if (a[i] !== b[i]) {
        x = a[i];
        y = b[i];
        break;
      }
    }
    if (x < y)
      return -1;
    if (y < x)
      return 1;
    return 0;
  }
  /**
   * Returns true if {encoding} is a valid encoding argument.
   * Valid string encodings in Node 0.12: 'ascii'|'utf8'|'utf16le'|'ucs2'(alias of 'utf16le')|'base64'|'binary'(deprecated)|'hex'
   *
   * @param encoding string to test.
   */
  static isEncoding(encoding) {
    switch (String(encoding).toLowerCase()) {
      case "hex":
      case "utf8":
      case "utf-8":
      case "ascii":
      case "latin1":
      case "binary":
      case "base64":
      case "ucs2":
      case "ucs-2":
      case "utf16le":
      case "utf-16le":
        return true;
      default:
        return false;
    }
  }
  /**
   * Returns a buffer which is the result of concatenating all the buffers in the list together.
   *
   * If the list has no items, or if the totalLength is 0, then it returns a zero-length buffer.
   * If the list has exactly one item, then the first item of the list is returned.
   * If the list has more than one item, then a new Buffer is created.
   *
   * @param list An array of Buffer objects to concatenate
   * @param totalLength Total length of the buffers when concatenated.
   *   If totalLength is not provided, it is read from the buffers in the list. However, this adds an additional loop to the function, so it is faster to provide the length explicitly.
   */
  static concat(list, length) {
    if (!Array.isArray(list)) {
      throw new TypeError('"list" argument must be an Array of Buffers');
    }
    if (list.length === 0) {
      return _Buffer.alloc(0);
    }
    let i;
    if (length === void 0) {
      length = 0;
      for (i = 0; i < list.length; ++i) {
        length += list[i].length;
      }
    }
    const buffer = _Buffer.allocUnsafe(length);
    let pos = 0;
    for (i = 0; i < list.length; ++i) {
      let buf = list[i];
      if (isInstance(buf, Uint8Array)) {
        if (pos + buf.length > buffer.length) {
          if (!_Buffer.isBuffer(buf)) {
            buf = _Buffer.from(buf.buffer, buf.byteOffset, buf.byteLength);
          }
          buf.copy(buffer, pos);
        } else {
          Uint8Array.prototype.set.call(buffer, buf, pos);
        }
      } else if (!_Buffer.isBuffer(buf)) {
        throw new TypeError('"list" argument must be an Array of Buffers');
      } else {
        buf.copy(buffer, pos);
      }
      pos += buf.length;
    }
    return buffer;
  }
  /**
   * Allocates a new buffer of {size} octets.
   *
   * @param size count of octets to allocate.
   * @param fill if specified, buffer will be initialized by calling buf.fill(fill).
   *    If parameter is omitted, buffer will be filled with zeros.
   * @param encoding encoding used for call to buf.fill while initializing
   */
  static alloc(size, fill, encoding) {
    return alloc(size, fill, encoding);
  }
  /**
   * Allocates a new buffer of {size} octets, leaving memory not initialized, so the contents
   * of the newly created Buffer are unknown and may contain sensitive data.
   *
   * @param size count of octets to allocate
   */
  static allocUnsafe(size) {
    assertSize(size);
    return new _Buffer(size);
  }
  /**
   * Allocates a new non-pooled buffer of {size} octets, leaving memory not initialized, so the contents
   * of the newly created Buffer are unknown and may contain sensitive data.
   *
   * @param size count of octets to allocate
   */
  static allocUnsafeSlow(size) {
    return allocUnsafe(size);
  }
  includes(val, byteOffset, encoding) {
    return this.indexOf(val, byteOffset, encoding) !== -1;
  }
  indexOf(val, byteOffset, encoding) {
    return bidirectionalIndexOf(this, val, byteOffset, encoding, true);
  }
  lastIndexOf(val, byteOffset, encoding) {
    return bidirectionalIndexOf(this, val, byteOffset, encoding, false);
  }
  readInt8(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert)
      checkOffset(offset, 1, this.length);
    if (!(this[offset] & 128))
      return this[offset];
    return (255 - this[offset] + 1) * -1;
  }
  readInt16LE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert)
      checkOffset(offset, 2, this.length);
    const val = this[offset] | this[offset + 1] << 8;
    return val & 32768 ? val | 4294901760 : val;
  }
  readInt16BE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert)
      checkOffset(offset, 2, this.length);
    const val = this[offset + 1] | this[offset] << 8;
    return val & 32768 ? val | 4294901760 : val;
  }
  readInt32LE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert)
      checkOffset(offset, 4, this.length);
    return this[offset] | this[offset + 1] << 8 | this[offset + 2] << 16 | this[offset + 3] << 24;
  }
  readInt32BE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert)
      checkOffset(offset, 4, this.length);
    return this[offset] << 24 | this[offset + 1] << 16 | this[offset + 2] << 8 | this[offset + 3];
  }
  readIntBE(offset, byteLength2, noAssert) {
    offset = offset >>> 0;
    byteLength2 = byteLength2 >>> 0;
    if (!noAssert)
      checkOffset(offset, byteLength2, this.length);
    let i = byteLength2;
    let mul = 1;
    let val = this[offset + --i];
    while (i > 0 && (mul *= 256)) {
      val += this[offset + --i] * mul;
    }
    mul *= 128;
    if (val >= mul)
      val -= Math.pow(2, 8 * byteLength2);
    return val;
  }
  readIntLE(offset, byteLength2, noAssert) {
    offset = offset >>> 0;
    byteLength2 = byteLength2 >>> 0;
    if (!noAssert)
      checkOffset(offset, byteLength2, this.length);
    let val = this[offset];
    let mul = 1;
    let i = 0;
    while (++i < byteLength2 && (mul *= 256)) {
      val += this[offset + i] * mul;
    }
    mul *= 128;
    if (val >= mul)
      val -= Math.pow(2, 8 * byteLength2);
    return val;
  }
  readBigInt64LE(offset) {
    offset = offset >>> 0;
    validateNumber(offset, "offset");
    const first = this[offset];
    const last = this[offset + 7];
    if (first === void 0 || last === void 0) {
      boundsError(offset, this.length - 8);
    }
    const val = this[offset + 4] + this[offset + 5] * 2 ** 8 + this[offset + 6] * 2 ** 16 + (last << 24);
    return (BigInt(val) << BigInt(32)) + BigInt(first + this[++offset] * 2 ** 8 + this[++offset] * 2 ** 16 + this[++offset] * 2 ** 24);
  }
  readBigInt64BE(offset) {
    offset = offset >>> 0;
    validateNumber(offset, "offset");
    const first = this[offset];
    const last = this[offset + 7];
    if (first === void 0 || last === void 0) {
      boundsError(offset, this.length - 8);
    }
    const val = (first << 24) + // Overflow
    this[++offset] * 2 ** 16 + this[++offset] * 2 ** 8 + this[++offset];
    return (BigInt(val) << BigInt(32)) + BigInt(this[++offset] * 2 ** 24 + this[++offset] * 2 ** 16 + this[++offset] * 2 ** 8 + last);
  }
  readUInt8(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert)
      checkOffset(offset, 1, this.length);
    return this[offset];
  }
  readUInt16LE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert)
      checkOffset(offset, 2, this.length);
    return this[offset] | this[offset + 1] << 8;
  }
  readUInt16BE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert)
      checkOffset(offset, 2, this.length);
    return this[offset] << 8 | this[offset + 1];
  }
  readUInt32LE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert)
      checkOffset(offset, 4, this.length);
    return (this[offset] | this[offset + 1] << 8 | this[offset + 2] << 16) + this[offset + 3] * 16777216;
  }
  readUInt32BE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert)
      checkOffset(offset, 4, this.length);
    return this[offset] * 16777216 + (this[offset + 1] << 16 | this[offset + 2] << 8 | this[offset + 3]);
  }
  readUIntLE(offset, byteLength2, noAssert) {
    offset = offset >>> 0;
    byteLength2 = byteLength2 >>> 0;
    if (!noAssert)
      checkOffset(offset, byteLength2, this.length);
    let val = this[offset];
    let mul = 1;
    let i = 0;
    while (++i < byteLength2 && (mul *= 256)) {
      val += this[offset + i] * mul;
    }
    return val;
  }
  readUIntBE(offset, byteLength2, noAssert) {
    offset = offset >>> 0;
    byteLength2 = byteLength2 >>> 0;
    if (!noAssert) {
      checkOffset(offset, byteLength2, this.length);
    }
    let val = this[offset + --byteLength2];
    let mul = 1;
    while (byteLength2 > 0 && (mul *= 256)) {
      val += this[offset + --byteLength2] * mul;
    }
    return val;
  }
  readBigUInt64LE(offset) {
    offset = offset >>> 0;
    validateNumber(offset, "offset");
    const first = this[offset];
    const last = this[offset + 7];
    if (first === void 0 || last === void 0) {
      boundsError(offset, this.length - 8);
    }
    const lo = first + this[++offset] * 2 ** 8 + this[++offset] * 2 ** 16 + this[++offset] * 2 ** 24;
    const hi = this[++offset] + this[++offset] * 2 ** 8 + this[++offset] * 2 ** 16 + last * 2 ** 24;
    return BigInt(lo) + (BigInt(hi) << BigInt(32));
  }
  readBigUInt64BE(offset) {
    offset = offset >>> 0;
    validateNumber(offset, "offset");
    const first = this[offset];
    const last = this[offset + 7];
    if (first === void 0 || last === void 0) {
      boundsError(offset, this.length - 8);
    }
    const hi = first * 2 ** 24 + this[++offset] * 2 ** 16 + this[++offset] * 2 ** 8 + this[++offset];
    const lo = this[++offset] * 2 ** 24 + this[++offset] * 2 ** 16 + this[++offset] * 2 ** 8 + last;
    return (BigInt(hi) << BigInt(32)) + BigInt(lo);
  }
  readFloatLE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert)
      checkOffset(offset, 4, this.length);
    return import_ieee754.default.read(this, offset, true, 23, 4);
  }
  readFloatBE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert)
      checkOffset(offset, 4, this.length);
    return import_ieee754.default.read(this, offset, false, 23, 4);
  }
  readDoubleLE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert)
      checkOffset(offset, 8, this.length);
    return import_ieee754.default.read(this, offset, true, 52, 8);
  }
  readDoubleBE(offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert)
      checkOffset(offset, 8, this.length);
    return import_ieee754.default.read(this, offset, false, 52, 8);
  }
  writeUInt8(value, offset, noAssert) {
    value = Number(value);
    offset = offset >>> 0;
    if (!noAssert)
      checkInt(this, value, offset, 1, 255, 0);
    this[offset] = value & 255;
    return offset + 1;
  }
  writeUInt16LE(value, offset, noAssert) {
    value = Number(value);
    offset = offset >>> 0;
    if (!noAssert)
      checkInt(this, value, offset, 2, 65535, 0);
    this[offset] = value & 255;
    this[offset + 1] = value >>> 8;
    return offset + 2;
  }
  writeUInt16BE(value, offset, noAssert) {
    value = Number(value);
    offset = offset >>> 0;
    if (!noAssert)
      checkInt(this, value, offset, 2, 65535, 0);
    this[offset] = value >>> 8;
    this[offset + 1] = value & 255;
    return offset + 2;
  }
  writeUInt32LE(value, offset, noAssert) {
    value = Number(value);
    offset = offset >>> 0;
    if (!noAssert)
      checkInt(this, value, offset, 4, 4294967295, 0);
    this[offset + 3] = value >>> 24;
    this[offset + 2] = value >>> 16;
    this[offset + 1] = value >>> 8;
    this[offset] = value & 255;
    return offset + 4;
  }
  writeUInt32BE(value, offset, noAssert) {
    value = Number(value);
    offset = offset >>> 0;
    if (!noAssert)
      checkInt(this, value, offset, 4, 4294967295, 0);
    this[offset] = value >>> 24;
    this[offset + 1] = value >>> 16;
    this[offset + 2] = value >>> 8;
    this[offset + 3] = value & 255;
    return offset + 4;
  }
  writeUIntLE(value, offset, byteLength2, noAssert) {
    value = Number(value);
    offset = offset >>> 0;
    byteLength2 = byteLength2 >>> 0;
    if (!noAssert) {
      const maxBytes = Math.pow(2, 8 * byteLength2) - 1;
      checkInt(this, value, offset, byteLength2, maxBytes, 0);
    }
    let mul = 1;
    let i = 0;
    this[offset] = value & 255;
    while (++i < byteLength2 && (mul *= 256)) {
      this[offset + i] = value / mul & 255;
    }
    return offset + byteLength2;
  }
  writeUIntBE(value, offset, byteLength2, noAssert) {
    value = Number(value);
    offset = offset >>> 0;
    byteLength2 = byteLength2 >>> 0;
    if (!noAssert) {
      const maxBytes = Math.pow(2, 8 * byteLength2) - 1;
      checkInt(this, value, offset, byteLength2, maxBytes, 0);
    }
    let i = byteLength2 - 1;
    let mul = 1;
    this[offset + i] = value & 255;
    while (--i >= 0 && (mul *= 256)) {
      this[offset + i] = value / mul & 255;
    }
    return offset + byteLength2;
  }
  writeBigUInt64LE(value, offset = 0) {
    return wrtBigUInt64LE(this, value, offset, BigInt(0), BigInt("0xffffffffffffffff"));
  }
  writeBigUInt64BE(value, offset = 0) {
    return wrtBigUInt64BE(this, value, offset, BigInt(0), BigInt("0xffffffffffffffff"));
  }
  writeIntLE(value, offset, byteLength2, noAssert) {
    value = Number(value);
    offset = offset >>> 0;
    if (!noAssert) {
      const limit = Math.pow(2, 8 * byteLength2 - 1);
      checkInt(this, value, offset, byteLength2, limit - 1, -limit);
    }
    let i = 0;
    let mul = 1;
    let sub = 0;
    this[offset] = value & 255;
    while (++i < byteLength2 && (mul *= 256)) {
      if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {
        sub = 1;
      }
      this[offset + i] = (value / mul >> 0) - sub & 255;
    }
    return offset + byteLength2;
  }
  writeIntBE(value, offset, byteLength2, noAssert) {
    value = Number(value);
    offset = offset >>> 0;
    if (!noAssert) {
      const limit = Math.pow(2, 8 * byteLength2 - 1);
      checkInt(this, value, offset, byteLength2, limit - 1, -limit);
    }
    let i = byteLength2 - 1;
    let mul = 1;
    let sub = 0;
    this[offset + i] = value & 255;
    while (--i >= 0 && (mul *= 256)) {
      if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {
        sub = 1;
      }
      this[offset + i] = (value / mul >> 0) - sub & 255;
    }
    return offset + byteLength2;
  }
  writeInt8(value, offset, noAssert) {
    value = Number(value);
    offset = offset >>> 0;
    if (!noAssert)
      checkInt(this, value, offset, 1, 127, -128);
    if (value < 0)
      value = 255 + value + 1;
    this[offset] = value & 255;
    return offset + 1;
  }
  writeInt16LE(value, offset, noAssert) {
    value = Number(value);
    offset = offset >>> 0;
    if (!noAssert)
      checkInt(this, value, offset, 2, 32767, -32768);
    this[offset] = value & 255;
    this[offset + 1] = value >>> 8;
    return offset + 2;
  }
  writeInt16BE(value, offset, noAssert) {
    value = Number(value);
    offset = offset >>> 0;
    if (!noAssert)
      checkInt(this, value, offset, 2, 32767, -32768);
    this[offset] = value >>> 8;
    this[offset + 1] = value & 255;
    return offset + 2;
  }
  writeInt32LE(value, offset, noAssert) {
    value = Number(value);
    offset = offset >>> 0;
    if (!noAssert)
      checkInt(this, value, offset, 4, 2147483647, -2147483648);
    this[offset] = value & 255;
    this[offset + 1] = value >>> 8;
    this[offset + 2] = value >>> 16;
    this[offset + 3] = value >>> 24;
    return offset + 4;
  }
  writeInt32BE(value, offset, noAssert) {
    value = Number(value);
    offset = offset >>> 0;
    if (!noAssert)
      checkInt(this, value, offset, 4, 2147483647, -2147483648);
    if (value < 0)
      value = 4294967295 + value + 1;
    this[offset] = value >>> 24;
    this[offset + 1] = value >>> 16;
    this[offset + 2] = value >>> 8;
    this[offset + 3] = value & 255;
    return offset + 4;
  }
  writeBigInt64LE(value, offset = 0) {
    return wrtBigUInt64LE(this, value, offset, -BigInt("0x8000000000000000"), BigInt("0x7fffffffffffffff"));
  }
  writeBigInt64BE(value, offset = 0) {
    return wrtBigUInt64BE(this, value, offset, -BigInt("0x8000000000000000"), BigInt("0x7fffffffffffffff"));
  }
  writeFloatLE(value, offset, noAssert) {
    return writeFloat(this, value, offset, true, noAssert);
  }
  writeFloatBE(value, offset, noAssert) {
    return writeFloat(this, value, offset, false, noAssert);
  }
  writeDoubleLE(value, offset, noAssert) {
    return writeDouble(this, value, offset, true, noAssert);
  }
  writeDoubleBE(value, offset, noAssert) {
    return writeDouble(this, value, offset, false, noAssert);
  }
  write(string, offset, length, encoding) {
    if (offset === void 0) {
      encoding = "utf8";
      length = this.length;
      offset = 0;
    } else if (length === void 0 && typeof offset === "string") {
      encoding = offset;
      length = this.length;
      offset = 0;
    } else if (isFinite(offset)) {
      offset = offset >>> 0;
      if (isFinite(length)) {
        length = length >>> 0;
        if (encoding === void 0)
          encoding = "utf8";
      } else {
        encoding = length;
        length = void 0;
      }
    } else {
      throw new Error("Buffer.write(string, encoding, offset[, length]) is no longer supported");
    }
    const remaining = this.length - offset;
    if (length === void 0 || length > remaining)
      length = remaining;
    if (string.length > 0 && (length < 0 || offset < 0) || offset > this.length) {
      throw new RangeError("Attempt to write outside buffer bounds");
    }
    if (!encoding)
      encoding = "utf8";
    let loweredCase = false;
    for (; ; ) {
      switch (encoding) {
        case "hex":
          return hexWrite(this, string, offset, length);
        case "utf8":
        case "utf-8":
          return utf8Write(this, string, offset, length);
        case "ascii":
        case "latin1":
        case "binary":
          return asciiWrite(this, string, offset, length);
        case "base64":
          return base64Write(this, string, offset, length);
        case "ucs2":
        case "ucs-2":
        case "utf16le":
        case "utf-16le":
          return ucs2Write(this, string, offset, length);
        default:
          if (loweredCase)
            throw new TypeError(`Unknown encoding: ${encoding}`);
          encoding = `${encoding}`.toLowerCase();
          loweredCase = true;
      }
    }
  }
  // copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)
  copy(target, targetStart, start, end) {
    if (!_Buffer.isBuffer(target))
      throw new TypeError("argument should be a Buffer");
    if (!start)
      start = 0;
    if (!end && end !== 0)
      end = this.length;
    if (targetStart >= target.length)
      targetStart = target.length;
    if (!targetStart)
      targetStart = 0;
    if (end > 0 && end < start)
      end = start;
    if (end === start)
      return 0;
    if (target.length === 0 || this.length === 0)
      return 0;
    if (targetStart < 0) {
      throw new RangeError("targetStart out of bounds");
    }
    if (start < 0 || start >= this.length)
      throw new RangeError("Index out of range");
    if (end < 0)
      throw new RangeError("sourceEnd out of bounds");
    if (end > this.length)
      end = this.length;
    if (target.length - targetStart < end - start) {
      end = target.length - targetStart + start;
    }
    const len = end - start;
    if (this === target && typeof Uint8Array.prototype.copyWithin === "function") {
      this.copyWithin(targetStart, start, end);
    } else {
      Uint8Array.prototype.set.call(target, this.subarray(start, end), targetStart);
    }
    return len;
  }
  // Usage:
  //    buffer.fill(number[, offset[, end]])
  //    buffer.fill(buffer[, offset[, end]])
  //    buffer.fill(string[, offset[, end]][, encoding])
  fill(val, start, end, encoding) {
    if (typeof val === "string") {
      if (typeof start === "string") {
        encoding = start;
        start = 0;
        end = this.length;
      } else if (typeof end === "string") {
        encoding = end;
        end = this.length;
      }
      if (encoding !== void 0 && typeof encoding !== "string") {
        throw new TypeError("encoding must be a string");
      }
      if (typeof encoding === "string" && !_Buffer.isEncoding(encoding)) {
        throw new TypeError(`Unknown encoding: ${encoding}`);
      }
      if (val.length === 1) {
        const code = val.charCodeAt(0);
        if (encoding === "utf8" && code < 128 || encoding === "latin1") {
          val = code;
        }
      }
    } else if (typeof val === "number") {
      val = val & 255;
    } else if (typeof val === "boolean") {
      val = Number(val);
    }
    if (start < 0 || this.length < start || this.length < end) {
      throw new RangeError("Out of range index");
    }
    if (end <= start) {
      return this;
    }
    start = start >>> 0;
    end = end === void 0 ? this.length : end >>> 0;
    if (!val)
      val = 0;
    let i;
    if (typeof val === "number") {
      for (i = start; i < end; ++i) {
        this[i] = val;
      }
    } else {
      const bytes = _Buffer.isBuffer(val) ? val : _Buffer.from(val, encoding);
      const len = bytes.length;
      if (len === 0) {
        throw new TypeError(`The value "${val}" is invalid for argument "value"`);
      }
      for (i = 0; i < end - start; ++i) {
        this[i + start] = bytes[i % len];
      }
    }
    return this;
  }
  swap16() {
    const len = this.length;
    if (len % 2 !== 0) {
      throw new RangeError("Buffer size must be a multiple of 16-bits");
    }
    for (let i = 0; i < len; i += 2) {
      swap(this, i, i + 1);
    }
    return this;
  }
  swap32() {
    const len = this.length;
    if (len % 4 !== 0) {
      throw new RangeError("Buffer size must be a multiple of 32-bits");
    }
    for (let i = 0; i < len; i += 4) {
      swap(this, i, i + 3);
      swap(this, i + 1, i + 2);
    }
    return this;
  }
  swap64() {
    const len = this.length;
    if (len % 8 !== 0) {
      throw new RangeError("Buffer size must be a multiple of 64-bits");
    }
    for (let i = 0; i < len; i += 8) {
      swap(this, i, i + 7);
      swap(this, i + 1, i + 6);
      swap(this, i + 2, i + 5);
      swap(this, i + 3, i + 4);
    }
    return this;
  }
  toString(encoding, start, end) {
    const length = this.length;
    if (length === 0)
      return "";
    if (arguments.length === 0)
      return utf8Slice(this, 0, length);
    return this._slowToString(...arguments);
  }
  // toLocaleString(b) {
  //   if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer');
  //   if (this === b) return true;
  //   return Buffer.compare(this, b) === 0;
  // }
  inspect() {
    let str = "";
    const max = INSPECT_MAX_BYTES;
    str = this.toString("hex", 0, max).replace(/(.{2})/g, "$1 ").trim();
    if (this.length > max)
      str += " ... ";
    return `<Buffer ${str}>`;
  }
  // if (customInspectSymbol) {
  //   Buffer.prototype[customInspectSymbol] =  Buffer.prototype.inspect;
  // }
  // }
  equals(b) {
    if (!_Buffer.isBuffer(b))
      throw new TypeError("Argument must be a Buffer");
    if (this === b)
      return true;
    return _Buffer.compare(this, b) === 0;
  }
  compare(target, start, end, thisStart, thisEnd) {
    if (!_Buffer.isBuffer(target) && isInstance(target, Uint8Array)) {
      target = _Buffer.from(target, target.offset, target.byteLength);
    }
    if (!_Buffer.isBuffer(target)) {
      throw new TypeError(`${'The "target" argument must be one of type Buffer or Uint8Array. Received type '}${typeof target}`);
    }
    if (start === void 0) {
      start = 0;
    }
    if (end === void 0) {
      end = target ? target.length : 0;
    }
    if (thisStart === void 0) {
      thisStart = 0;
    }
    if (thisEnd === void 0) {
      thisEnd = this.length;
    }
    if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {
      throw new RangeError("out of range index");
    }
    if (thisStart >= thisEnd && start >= end) {
      return 0;
    }
    if (thisStart >= thisEnd) {
      return -1;
    }
    if (start >= end) {
      return 1;
    }
    start >>>= 0;
    end >>>= 0;
    thisStart >>>= 0;
    thisEnd >>>= 0;
    if (this === target)
      return 0;
    let x = thisEnd - thisStart;
    let y = end - start;
    const len = Math.min(x, y);
    const thisCopy = this.slice(thisStart, thisEnd);
    const targetCopy = target.slice(start, end);
    for (let i = 0; i < len; ++i) {
      if (thisCopy[i] !== targetCopy[i]) {
        x = thisCopy[i];
        y = targetCopy[i];
        break;
      }
    }
    if (x < y)
      return -1;
    if (y < x)
      return 1;
    return 0;
  }
  toJSON() {
    return {
      type: "Buffer",
      data: Array.prototype.slice.call(this._arr || this, 0)
    };
  }
  slice(start, end) {
    const len = this.length;
    start = ~~start;
    end = end === void 0 ? len : ~~end;
    if (start < 0) {
      start += len;
      if (start < 0)
        start = 0;
    } else if (start > len) {
      start = len;
    }
    if (end < 0) {
      end += len;
      if (end < 0)
        end = 0;
    } else if (end > len) {
      end = len;
    }
    if (end < start)
      end = start;
    const newBuf = this.subarray(start, end);
    Object.setPrototypeOf(newBuf, _Buffer.prototype);
    return newBuf;
  }
  // Typo support?
  // readUint8(offset: number, noAssert?: boolean): number {
  //   return this.readUInt8(...arguments);
  // }
  // readUint16LE(offset: number, noAssert?: boolean): number {
  //   return this.readUInt16LE(...arguments);
  // }
  // readUint16BE(offset: number, noAssert?: boolean): number {
  //   return this.readUInt16BE(...arguments);
  // }
  // readUint32LE(offset: number, noAssert?: boolean): number {
  //   return this.readUInt32LE(...arguments);
  // }
  // readUint32BE(offset: number, noAssert?: boolean): number {
  //   return this.readUInt32BE(...arguments);
  // }
  // writeUint8() {
  //   return this.writeUInt8(...arguments);
  // }
  // writeUint16LE
  // writeUint16LE
  // writeUint32LE = Buffer.prototype.
  // Buffer.prototype.writeUint32BE
  _slowToString(encoding, start, end) {
    let loweredCase = false;
    if (start === void 0 || start < 0) {
      start = 0;
    }
    if (start > this.length) {
      return "";
    }
    if (end === void 0 || end > this.length) {
      end = this.length;
    }
    if (end <= 0) {
      return "";
    }
    end >>>= 0;
    start >>>= 0;
    if (end <= start) {
      return "";
    }
    if (!encoding)
      encoding = "utf8";
    while (true) {
      switch (encoding) {
        case "hex":
          return hexSlice(this, start, end);
        case "utf8":
        case "utf-8":
          return utf8Slice(this, start, end);
        case "ascii":
          return asciiSlice(this, start, end);
        case "latin1":
        case "binary":
          return latin1Slice(this, start, end);
        case "base64":
          return base64Slice(this, start, end);
        case "ucs2":
        case "ucs-2":
        case "utf16le":
        case "utf-16le":
          return utf16leSlice(this, start, end);
        default:
          if (loweredCase)
            throw new TypeError(`Unknown encoding: ${encoding}`);
          encoding = `${encoding}`.toLowerCase();
          loweredCase = true;
      }
    }
  }
};
var Buffer2 = _Buffer;
__publicField(Buffer2, "poolSize", 8192);
function checkInt(buf, value, offset, ext, max, min) {
  if (!Buffer2.isBuffer(buf))
    throw new TypeError('"buffer" argument must be a Buffer instance');
  if (value > max || value < min)
    throw new RangeError('"value" argument is out of bounds');
  if (offset + ext > buf.length)
    throw new RangeError("Index out of range");
}
function wrtBigUInt64LE(buf, value, offset, min, max) {
  checkIntBI(value, min, max, buf, offset, 7);
  let lo = Number(value & BigInt(4294967295));
  buf[offset++] = lo;
  lo = lo >> 8;
  buf[offset++] = lo;
  lo = lo >> 8;
  buf[offset++] = lo;
  lo = lo >> 8;
  buf[offset++] = lo;
  let hi = Number(value >> BigInt(32) & BigInt(4294967295));
  buf[offset++] = hi;
  hi = hi >> 8;
  buf[offset++] = hi;
  hi = hi >> 8;
  buf[offset++] = hi;
  hi = hi >> 8;
  buf[offset++] = hi;
  return offset;
}
function wrtBigUInt64BE(buf, value, offset, min, max) {
  checkIntBI(value, min, max, buf, offset, 7);
  let lo = Number(value & BigInt(4294967295));
  buf[offset + 7] = lo;
  lo = lo >> 8;
  buf[offset + 6] = lo;
  lo = lo >> 8;
  buf[offset + 5] = lo;
  lo = lo >> 8;
  buf[offset + 4] = lo;
  let hi = Number(value >> BigInt(32) & BigInt(4294967295));
  buf[offset + 3] = hi;
  hi = hi >> 8;
  buf[offset + 2] = hi;
  hi = hi >> 8;
  buf[offset + 1] = hi;
  hi = hi >> 8;
  buf[offset] = hi;
  return offset + 8;
}
function assertSize(size) {
  if (typeof size !== "number") {
    throw new TypeError('"size" argument must be of type number');
  } else if (size < 0) {
    throw new RangeError(`The value "${size}" is invalid for option "size"`);
  }
}
function alloc(size, fill, encoding) {
  assertSize(size);
  if (size <= 0) {
    return new Buffer2(size);
  }
  if (fill !== void 0) {
    return typeof encoding === "string" ? new Buffer2(size).fill(fill, encoding) : new Buffer2(size).fill(fill);
  }
  return new Buffer2(size);
}
function fromString(string, encoding) {
  if (typeof encoding !== "string" || encoding === "") {
    encoding = "utf8";
  }
  if (!Buffer2.isEncoding(encoding)) {
    throw new TypeError(`Unknown encoding: ${encoding}`);
  }
  const length = byteLength(string, encoding) | 0;
  let buf = new Buffer2(length);
  const actual = buf.write(string, encoding);
  if (actual !== length) {
    buf = buf.slice(0, actual);
  }
  return buf;
}
function fromArrayLike(array) {
  const length = array.length < 0 ? 0 : checked(array.length) | 0;
  const buf = new Buffer2(length);
  for (let i = 0; i < length; i += 1) {
    buf[i] = array[i] & 255;
  }
  return buf;
}
function fromArrayView(arrayView) {
  if (isInstance(arrayView, Uint8Array)) {
    const copy = new Uint8Array(arrayView);
    return fromArrayBuffer(copy.buffer, copy.byteOffset, copy.byteLength);
  }
  return fromArrayLike(arrayView);
}
function fromArrayBuffer(array, byteOffset, length) {
  if (byteOffset < 0 || array.byteLength < byteOffset) {
    throw new RangeError('"offset" is outside of buffer bounds');
  }
  if (array.byteLength < byteOffset + (length || 0)) {
    throw new RangeError('"length" is outside of buffer bounds');
  }
  let buf;
  if (byteOffset === void 0 && length === void 0) {
    buf = new Uint8Array(array);
  } else if (length === void 0) {
    buf = new Uint8Array(array, byteOffset);
  } else {
    buf = new Uint8Array(array, byteOffset, length);
  }
  Object.setPrototypeOf(buf, Buffer2.prototype);
  return buf;
}
function fromObject(obj) {
  if (Buffer2.isBuffer(obj)) {
    const len = checked(obj.length) | 0;
    const buf = new Buffer2(len);
    if (buf.length === 0) {
      return buf;
    }
    obj.copy(buf, 0, 0, len);
    return buf;
  }
  if (obj.length !== void 0) {
    if (typeof obj.length !== "number" || numberIsNaN(obj.length)) {
      return new Buffer2(0);
    }
    return fromArrayLike(obj);
  }
  if (obj.type === "Buffer" && Array.isArray(obj.data)) {
    return fromArrayLike(obj.data);
  }
}
function checked(length) {
  if (length >= kMaxLength) {
    throw new RangeError(`${"Attempt to allocate Buffer larger than maximum size: 0x"}${kMaxLength.toString(16)} bytes`);
  }
  return length | 0;
}
function byteLength(string, encoding) {
  if (Buffer2.isBuffer(string)) {
    return string.length;
  }
  if (ArrayBuffer.isView(string) || isInstance(string, ArrayBuffer)) {
    return string.byteLength;
  }
  if (typeof string !== "string") {
    throw new TypeError(`${'The "string" argument must be one of type string, Buffer, or ArrayBuffer. Received type '}${typeof string}`);
  }
  const len = string.length;
  const mustMatch = arguments.length > 2 && arguments[2] === true;
  if (!mustMatch && len === 0)
    return 0;
  let loweredCase = false;
  for (; ; ) {
    switch (encoding) {
      case "ascii":
      case "latin1":
      case "binary":
        return len;
      case "utf8":
      case "utf-8":
        return utf8ToBytes(string).length;
      case "ucs2":
      case "ucs-2":
      case "utf16le":
      case "utf-16le":
        return len * 2;
      case "hex":
        return len >>> 1;
      case "base64":
        return base64ToBytes(string).length;
      default:
        if (loweredCase) {
          return mustMatch ? -1 : utf8ToBytes(string).length;
        }
        encoding = `${encoding}`.toLowerCase();
        loweredCase = true;
    }
  }
}
function swap(b, n, m) {
  const i = b[n];
  b[n] = b[m];
  b[m] = i;
}
function bidirectionalIndexOf(buffer, val, byteOffset, encoding, dir) {
  if (buffer.length === 0)
    return -1;
  if (typeof byteOffset === "string") {
    encoding = byteOffset;
    byteOffset = 0;
  } else if (byteOffset > 2147483647) {
    byteOffset = 2147483647;
  } else if (byteOffset < -2147483648) {
    byteOffset = -2147483648;
  }
  byteOffset = Number(byteOffset);
  if (numberIsNaN(byteOffset)) {
    byteOffset = dir ? 0 : buffer.length - 1;
  }
  if (byteOffset < 0)
    byteOffset = buffer.length + byteOffset;
  if (byteOffset >= buffer.length) {
    if (dir)
      return -1;
    byteOffset = buffer.length - 1;
  } else if (byteOffset < 0) {
    if (dir)
      byteOffset = 0;
    else
      return -1;
  }
  if (typeof val === "string") {
    val = Buffer2.from(val, encoding);
  }
  if (Buffer2.isBuffer(val)) {
    if (val.length === 0) {
      return -1;
    }
    return arrayIndexOf(buffer, val, byteOffset, encoding, dir);
  } else if (typeof val === "number") {
    val = val & 255;
    if (typeof Uint8Array.prototype.indexOf === "function") {
      if (dir) {
        return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset);
      }
      return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset);
    }
    return arrayIndexOf(buffer, [val], byteOffset, encoding, dir);
  }
  throw new TypeError("val must be string, number or Buffer");
}
function arrayIndexOf(arr, val, byteOffset, encoding, dir) {
  let indexSize = 1;
  let arrLength = arr.length;
  let valLength = val.length;
  if (encoding !== void 0) {
    encoding = String(encoding).toLowerCase();
    if (encoding === "ucs2" || encoding === "ucs-2" || encoding === "utf16le" || encoding === "utf-16le") {
      if (arr.length < 2 || val.length < 2) {
        return -1;
      }
      indexSize = 2;
      arrLength /= 2;
      valLength /= 2;
      byteOffset /= 2;
    }
  }
  function read(buf, i2) {
    if (indexSize === 1) {
      return buf[i2];
    }
    return buf.readUInt16BE(i2 * indexSize);
  }
  let i;
  if (dir) {
    let foundIndex = -1;
    for (i = byteOffset; i < arrLength; i++) {
      if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {
        if (foundIndex === -1)
          foundIndex = i;
        if (i - foundIndex + 1 === valLength)
          return foundIndex * indexSize;
      } else {
        if (foundIndex !== -1)
          i -= i - foundIndex;
        foundIndex = -1;
      }
    }
  } else {
    if (byteOffset + valLength > arrLength)
      byteOffset = arrLength - valLength;
    for (i = byteOffset; i >= 0; i--) {
      let found = true;
      for (let j = 0; j < valLength; j++) {
        if (read(arr, i + j) !== read(val, j)) {
          found = false;
          break;
        }
      }
      if (found)
        return i;
    }
  }
  return -1;
}
function hexWrite(buf, string, offset, length) {
  offset = Number(offset) || 0;
  const remaining = buf.length - offset;
  if (!length) {
    length = remaining;
  } else {
    length = Number(length);
    if (length > remaining) {
      length = remaining;
    }
  }
  const strLen = string.length;
  if (length > strLen / 2) {
    length = strLen / 2;
  }
  let i;
  for (i = 0; i < length; ++i) {
    const parsed = parseInt(string.substr(i * 2, 2), 16);
    if (numberIsNaN(parsed))
      return i;
    buf[offset + i] = parsed;
  }
  return i;
}
function utf8Write(buf, string, offset, length) {
  return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length);
}
function asciiWrite(buf, string, offset, length) {
  return blitBuffer(asciiToBytes(string), buf, offset, length);
}
function base64Write(buf, string, offset, length) {
  return blitBuffer(base64ToBytes(string), buf, offset, length);
}
function ucs2Write(buf, string, offset, length) {
  return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length);
}
function base64Slice(buf, start, end) {
  if (start === 0 && end === buf.length) {
    return import_base64_js.default.fromByteArray(buf);
  }
  return import_base64_js.default.fromByteArray(buf.slice(start, end));
}
function utf8Slice(buf, start, end) {
  end = Math.min(buf.length, end);
  const res = [];
  let i = start;
  while (i < end) {
    const firstByte = buf[i];
    let codePoint = null;
    let bytesPerSequence = firstByte > 239 ? 4 : firstByte > 223 ? 3 : firstByte > 191 ? 2 : 1;
    if (i + bytesPerSequence <= end) {
      let fourthByte;
      let secondByte;
      let tempCodePoint;
      let thirdByte;
      switch (bytesPerSequence) {
        case 1:
          if (firstByte < 128) {
            codePoint = firstByte;
          }
          break;
        case 2:
          secondByte = buf[i + 1];
          if ((secondByte & 192) === 128) {
            tempCodePoint = (firstByte & 31) << 6 | secondByte & 63;
            if (tempCodePoint > 127) {
              codePoint = tempCodePoint;
            }
          }
          break;
        case 3:
          secondByte = buf[i + 1];
          thirdByte = buf[i + 2];
          if ((secondByte & 192) === 128 && (thirdByte & 192) === 128) {
            tempCodePoint = (firstByte & 15) << 12 | (secondByte & 63) << 6 | thirdByte & 63;
            if (tempCodePoint > 2047 && (tempCodePoint < 55296 || tempCodePoint > 57343)) {
              codePoint = tempCodePoint;
            }
          }
          break;
        case 4:
          secondByte = buf[i + 1];
          thirdByte = buf[i + 2];
          fourthByte = buf[i + 3];
          if ((secondByte & 192) === 128 && (thirdByte & 192) === 128 && (fourthByte & 192) === 128) {
            tempCodePoint = (firstByte & 15) << 18 | (secondByte & 63) << 12 | (thirdByte & 63) << 6 | fourthByte & 63;
            if (tempCodePoint > 65535 && tempCodePoint < 1114112) {
              codePoint = tempCodePoint;
            }
          }
      }
    }
    if (codePoint === null) {
      codePoint = 65533;
      bytesPerSequence = 1;
    } else if (codePoint > 65535) {
      codePoint -= 65536;
      res.push(codePoint >>> 10 & 1023 | 55296);
      codePoint = 56320 | codePoint & 1023;
    }
    res.push(codePoint);
    i += bytesPerSequence;
  }
  return decodeCodePointsArray(res);
}
var MAX_ARGUMENTS_LENGTH = 4096;
function decodeCodePointsArray(codePoints) {
  const len = codePoints.length;
  if (len <= MAX_ARGUMENTS_LENGTH) {
    return String.fromCharCode.apply(String, codePoints);
  }
  let res = "";
  let i = 0;
  while (i < len) {
    res += String.fromCharCode.apply(String, codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH));
  }
  return res;
}
function asciiSlice(buf, start, end) {
  let ret = "";
  end = Math.min(buf.length, end);
  for (let i = start; i < end; ++i) {
    ret += String.fromCharCode(buf[i] & 127);
  }
  return ret;
}
function latin1Slice(buf, start, end) {
  let ret = "";
  end = Math.min(buf.length, end);
  for (let i = start; i < end; ++i) {
    ret += String.fromCharCode(buf[i]);
  }
  return ret;
}
function hexSlice(buf, start, end) {
  const len = buf.length;
  if (!start || start < 0)
    start = 0;
  if (!end || end < 0 || end > len)
    end = len;
  let out = "";
  for (let i = start; i < end; ++i) {
    out += hexSliceLookupTable[buf[i]];
  }
  return out;
}
function utf16leSlice(buf, start, end) {
  const bytes = buf.slice(start, end);
  let res = "";
  for (let i = 0; i < bytes.length - 1; i += 2) {
    res += String.fromCharCode(bytes[i] + bytes[i + 1] * 256);
  }
  return res;
}
function checkOffset(offset, ext, length) {
  if (offset % 1 !== 0 || offset < 0)
    throw new RangeError("offset is not uint");
  if (offset + ext > length)
    throw new RangeError("Trying to access beyond buffer length");
}
function checkIEEE754(buf, value, offset, ext, max, min) {
  if (offset + ext > buf.length)
    throw new RangeError("Index out of range");
  if (offset < 0)
    throw new RangeError("Index out of range");
}
function writeFloat(buf, value, offset, littleEndian, noAssert) {
  value = Number(value);
  offset = offset >>> 0;
  if (!noAssert) {
    checkIEEE754(buf, value, offset, 4, 34028234663852886e22, -34028234663852886e22);
  }
  import_ieee754.default.write(buf, value, offset, littleEndian, 23, 4);
  return offset + 4;
}
function writeDouble(buf, value, offset, littleEndian, noAssert) {
  value = Number(value);
  offset = offset >>> 0;
  if (!noAssert) {
    checkIEEE754(buf, value, offset, 8, 17976931348623157e292, -17976931348623157e292);
  }
  import_ieee754.default.write(buf, value, offset, littleEndian, 52, 8);
  return offset + 8;
}
var errors = {};
function E(sym, getMessage, Base) {
  errors[sym] = class NodeError extends Base {
    constructor() {
      super();
      Object.defineProperty(this, "message", {
        value: getMessage.apply(this, arguments),
        writable: true,
        configurable: true
      });
      this.name = `${this.name} [${sym}]`;
      this.stack;
      delete this.name;
    }
    get code() {
      return sym;
    }
    set code(value) {
      Object.defineProperty(this, "code", {
        configurable: true,
        enumerable: true,
        value,
        writable: true
      });
    }
    toString() {
      return `${this.name} [${sym}]: ${this.message}`;
    }
  };
}
E("ERR_BUFFER_OUT_OF_BOUNDS", function(name) {
  if (name) {
    return `${name} is outside of buffer bounds`;
  }
  return "Attempt to access memory outside buffer bounds";
}, RangeError);
E("ERR_INVALID_ARG_TYPE", function(name, actual) {
  return `The "${name}" argument must be of type number. Received type ${typeof actual}`;
}, TypeError);
E("ERR_OUT_OF_RANGE", function(str, range, input) {
  let msg = `The value of "${str}" is out of range.`;
  let received = input;
  if (Number.isInteger(input) && Math.abs(input) > 2 ** 32) {
    received = addNumericalSeparator(String(input));
  } else if (typeof input === "bigint") {
    received = String(input);
    if (input > BigInt(2) ** BigInt(32) || input < -(BigInt(2) ** BigInt(32))) {
      received = addNumericalSeparator(received);
    }
    received += "n";
  }
  msg += ` It must be ${range}. Received ${received}`;
  return msg;
}, RangeError);
function addNumericalSeparator(val) {
  let res = "";
  let i = val.length;
  const start = val[0] === "-" ? 1 : 0;
  for (; i >= start + 4; i -= 3) {
    res = `_${val.slice(i - 3, i)}${res}`;
  }
  return `${val.slice(0, i)}${res}`;
}
function checkBounds(buf, offset, byteLength2) {
  validateNumber(offset, "offset");
  if (buf[offset] === void 0 || buf[offset + byteLength2] === void 0) {
    boundsError(offset, buf.length - (byteLength2 + 1));
  }
}
function checkIntBI(value, min, max, buf, offset, byteLength2) {
  if (value > max || value < min) {
    const n = typeof min === "bigint" ? "n" : "";
    let range;
    if (byteLength2 > 3) {
      if (min === 0 || min === BigInt(0)) {
        range = `>= 0${n} and < 2${n} ** ${(byteLength2 + 1) * 8}${n}`;
      } else {
        range = `>= -(2${n} ** ${(byteLength2 + 1) * 8 - 1}${n}) and < 2 ** ${(byteLength2 + 1) * 8 - 1}${n}`;
      }
    } else {
      range = `>= ${min}${n} and <= ${max}${n}`;
    }
    throw new errors.ERR_OUT_OF_RANGE("value", range, value);
  }
  checkBounds(buf, offset, byteLength2);
}
function validateNumber(value, name) {
  if (typeof value !== "number") {
    throw new errors.ERR_INVALID_ARG_TYPE(name, "number", value);
  }
}
function boundsError(value, length, type) {
  if (Math.floor(value) !== value) {
    validateNumber(value, type);
    throw new errors.ERR_OUT_OF_RANGE(type || "offset", "an integer", value);
  }
  if (length < 0) {
    throw new errors.ERR_BUFFER_OUT_OF_BOUNDS();
  }
  throw new errors.ERR_OUT_OF_RANGE(type || "offset", `>= ${type ? 1 : 0} and <= ${length}`, value);
}
var INVALID_BASE64_RE = /[^+/0-9A-Za-z-_]/g;
function base64clean(str) {
  str = str.split("=")[0];
  str = str.trim().replace(INVALID_BASE64_RE, "");
  if (str.length < 2)
    return "";
  while (str.length % 4 !== 0) {
    str = `${str}=`;
  }
  return str;
}
function utf8ToBytes(string, units) {
  units = units || Infinity;
  let codePoint;
  const length = string.length;
  let leadSurrogate = null;
  const bytes = [];
  for (let i = 0; i < length; ++i) {
    codePoint = string.charCodeAt(i);
    if (codePoint > 55295 && codePoint < 57344) {
      if (!leadSurrogate) {
        if (codePoint > 56319) {
          if ((units -= 3) > -1)
            bytes.push(239, 191, 189);
          continue;
        } else if (i + 1 === length) {
          if ((units -= 3) > -1)
            bytes.push(239, 191, 189);
          continue;
        }
        leadSurrogate = codePoint;
        continue;
      }
      if (codePoint < 56320) {
        if ((units -= 3) > -1)
          bytes.push(239, 191, 189);
        leadSurrogate = codePoint;
        continue;
      }
      codePoint = (leadSurrogate - 55296 << 10 | codePoint - 56320) + 65536;
    } else if (leadSurrogate) {
      if ((units -= 3) > -1)
        bytes.push(239, 191, 189);
    }
    leadSurrogate = null;
    if (codePoint < 128) {
      if ((units -= 1) < 0)
        break;
      bytes.push(codePoint);
    } else if (codePoint < 2048) {
      if ((units -= 2) < 0)
        break;
      bytes.push(codePoint >> 6 | 192, codePoint & 63 | 128);
    } else if (codePoint < 65536) {
      if ((units -= 3) < 0)
        break;
      bytes.push(codePoint >> 12 | 224, codePoint >> 6 & 63 | 128, codePoint & 63 | 128);
    } else if (codePoint < 1114112) {
      if ((units -= 4) < 0)
        break;
      bytes.push(codePoint >> 18 | 240, codePoint >> 12 & 63 | 128, codePoint >> 6 & 63 | 128, codePoint & 63 | 128);
    } else {
      throw new Error("Invalid code point");
    }
  }
  return bytes;
}
function asciiToBytes(str) {
  const byteArray = [];
  for (let i = 0; i < str.length; ++i) {
    byteArray.push(str.charCodeAt(i) & 255);
  }
  return byteArray;
}
function utf16leToBytes(str, units) {
  let c;
  let hi;
  let lo;
  const byteArray = [];
  for (let i = 0; i < str.length; ++i) {
    if ((units -= 2) < 0)
      break;
    c = str.charCodeAt(i);
    hi = c >> 8;
    lo = c % 256;
    byteArray.push(lo);
    byteArray.push(hi);
  }
  return byteArray;
}
function base64ToBytes(str) {
  return import_base64_js.default.toByteArray(base64clean(str));
}
function blitBuffer(src, dst, offset, length) {
  let i;
  for (i = 0; i < length; ++i) {
    if (i + offset >= dst.length || i >= src.length)
      break;
    dst[i + offset] = src[i];
  }
  return i;
}
function isInstance(obj, type) {
  return obj instanceof type || obj != null && obj.constructor != null && obj.constructor.name != null && obj.constructor.name === type.name;
}
function numberIsNaN(obj) {
  return obj !== obj;
}
var hexSliceLookupTable = function() {
  const alphabet = "0123456789abcdef";
  const table = new Array(256);
  for (let i = 0; i < 16; ++i) {
    const i16 = i * 16;
    for (let j = 0; j < 16; ++j) {
      table[i16 + j] = alphabet[i] + alphabet[j];
    }
  }
  return table;
}();

// dist/polyfills/buffer/buffer-polyfill.browser.js
function installBufferPolyfill() {
  globalThis.Buffer = globalThis.Buffer || Buffer2;
  return globalThis.Buffer;
}

// dist/polyfills/buffer/install-buffer-polyfill.js
globalThis.process = globalThis.process || {};
globalThis.process.env = globalThis.process.env || {};
var Buffer3 = installBufferPolyfill();

// dist/parquet-loader.js
var import_loader_utils2 = require("@loaders.gl/loader-utils");

// dist/lib/parsers/parse-parquet.js
var import_log = __toESM(require("@probe.gl/log"), 1);

// dist/parquetjs/codecs/plain.js
var import_int53 = __toESM(require("int53"), 1);
function encodeValues(type, values, opts) {
  switch (type) {
    case "BOOLEAN":
      return encodeValues_BOOLEAN(values);
    case "INT32":
      return encodeValues_INT32(values);
    case "INT64":
      return encodeValues_INT64(values);
    case "INT96":
      return encodeValues_INT96(values);
    case "FLOAT":
      return encodeValues_FLOAT(values);
    case "DOUBLE":
      return encodeValues_DOUBLE(values);
    case "BYTE_ARRAY":
      return encodeValues_BYTE_ARRAY(values);
    case "FIXED_LEN_BYTE_ARRAY":
      return encodeValues_FIXED_LEN_BYTE_ARRAY(values, opts);
    default:
      throw new Error(`unsupported type: ${type}`);
  }
}
function decodeValues(type, cursor, count, opts) {
  switch (type) {
    case "BOOLEAN":
      return decodeValues_BOOLEAN(cursor, count);
    case "INT32":
      return decodeValues_INT32(cursor, count);
    case "INT64":
      return decodeValues_INT64(cursor, count);
    case "INT96":
      return decodeValues_INT96(cursor, count);
    case "FLOAT":
      return decodeValues_FLOAT(cursor, count);
    case "DOUBLE":
      return decodeValues_DOUBLE(cursor, count);
    case "BYTE_ARRAY":
      return decodeValues_BYTE_ARRAY(cursor, count);
    case "FIXED_LEN_BYTE_ARRAY":
      return decodeValues_FIXED_LEN_BYTE_ARRAY(cursor, count, opts);
    default:
      throw new Error(`unsupported type: ${type}`);
  }
}
function encodeValues_BOOLEAN(values) {
  const buf = Buffer.alloc(Math.ceil(values.length / 8));
  buf.fill(0);
  for (let i = 0; i < values.length; i++) {
    if (values[i]) {
      buf[Math.floor(i / 8)] |= 1 << i % 8;
    }
  }
  return buf;
}
function decodeValues_BOOLEAN(cursor, count) {
  const values = [];
  for (let i = 0; i < count; i++) {
    const b = cursor.buffer[cursor.offset + Math.floor(i / 8)];
    values.push((b & 1 << i % 8) > 0);
  }
  cursor.offset += Math.ceil(count / 8);
  return values;
}
function encodeValues_INT32(values) {
  const buf = Buffer.alloc(4 * values.length);
  for (let i = 0; i < values.length; i++) {
    buf.writeInt32LE(values[i], i * 4);
  }
  return buf;
}
function decodeValues_INT32(cursor, count) {
  const values = [];
  for (let i = 0; i < count; i++) {
    values.push(cursor.buffer.readInt32LE(cursor.offset));
    cursor.offset += 4;
  }
  return values;
}
function encodeValues_INT64(values) {
  const buf = Buffer.alloc(8 * values.length);
  for (let i = 0; i < values.length; i++) {
    import_int53.default.writeInt64LE(values[i], buf, i * 8);
  }
  return buf;
}
function decodeValues_INT64(cursor, count) {
  const values = [];
  for (let i = 0; i < count; i++) {
    values.push(import_int53.default.readInt64LE(cursor.buffer, cursor.offset));
    cursor.offset += 8;
  }
  return values;
}
function encodeValues_INT96(values) {
  const buf = Buffer.alloc(12 * values.length);
  for (let i = 0; i < values.length; i++) {
    if (values[i] >= 0) {
      import_int53.default.writeInt64LE(values[i], buf, i * 12);
      buf.writeUInt32LE(0, i * 12 + 8);
    } else {
      import_int53.default.writeInt64LE(~-values[i] + 1, buf, i * 12);
      buf.writeUInt32LE(4294967295, i * 12 + 8);
    }
  }
  return buf;
}
function decodeValues_INT96(cursor, count) {
  const values = [];
  for (let i = 0; i < count; i++) {
    const low = import_int53.default.readInt64LE(cursor.buffer, cursor.offset);
    const high = cursor.buffer.readUInt32LE(cursor.offset + 8);
    if (high === 4294967295) {
      values.push(~-low + 1);
    } else {
      values.push(low);
    }
    cursor.offset += 12;
  }
  return values;
}
function encodeValues_FLOAT(values) {
  const buf = Buffer.alloc(4 * values.length);
  for (let i = 0; i < values.length; i++) {
    buf.writeFloatLE(values[i], i * 4);
  }
  return buf;
}
function decodeValues_FLOAT(cursor, count) {
  const values = [];
  for (let i = 0; i < count; i++) {
    values.push(cursor.buffer.readFloatLE(cursor.offset));
    cursor.offset += 4;
  }
  return values;
}
function encodeValues_DOUBLE(values) {
  const buf = Buffer.alloc(8 * values.length);
  for (let i = 0; i < values.length; i++) {
    buf.writeDoubleLE(values[i], i * 8);
  }
  return buf;
}
function decodeValues_DOUBLE(cursor, count) {
  const values = [];
  for (let i = 0; i < count; i++) {
    values.push(cursor.buffer.readDoubleLE(cursor.offset));
    cursor.offset += 8;
  }
  return values;
}
function encodeValues_BYTE_ARRAY(values) {
  let buf_len = 0;
  for (let i = 0; i < values.length; i++) {
    values[i] = Buffer.from(values[i]);
    buf_len += 4 + values[i].length;
  }
  const buf = Buffer.alloc(buf_len);
  let buf_pos = 0;
  for (let i = 0; i < values.length; i++) {
    buf.writeUInt32LE(values[i].length, buf_pos);
    values[i].copy(buf, buf_pos + 4);
    buf_pos += 4 + values[i].length;
  }
  return buf;
}
function decodeValues_BYTE_ARRAY(cursor, count) {
  const values = [];
  for (let i = 0; i < count; i++) {
    const len = cursor.buffer.readUInt32LE(cursor.offset);
    cursor.offset += 4;
    values.push(cursor.buffer.slice(cursor.offset, cursor.offset + len));
    cursor.offset += len;
  }
  return values;
}
function encodeValues_FIXED_LEN_BYTE_ARRAY(values, opts) {
  if (!opts.typeLength) {
    throw new Error("missing option: typeLength (required for FIXED_LEN_BYTE_ARRAY)");
  }
  for (let i = 0; i < values.length; i++) {
    values[i] = Buffer.from(values[i]);
    if (values[i].length !== opts.typeLength) {
      throw new Error(`invalid value for FIXED_LEN_BYTE_ARRAY: ${values[i]}`);
    }
  }
  return Buffer.concat(values);
}
function decodeValues_FIXED_LEN_BYTE_ARRAY(cursor, count, opts) {
  const values = [];
  if (!opts.typeLength) {
    throw new Error("missing option: typeLength (required for FIXED_LEN_BYTE_ARRAY)");
  }
  for (let i = 0; i < count; i++) {
    values.push(cursor.buffer.slice(cursor.offset, cursor.offset + opts.typeLength));
    cursor.offset += opts.typeLength;
  }
  return values;
}

// dist/parquetjs/codecs/rle.js
var import_varint = __toESM(require("varint"), 1);
function encodeValues2(type, values, opts) {
  if (!("bitWidth" in opts)) {
    throw new Error("bitWidth is required");
  }
  switch (type) {
    case "BOOLEAN":
    case "INT32":
    case "INT64":
      values = values.map((x) => parseInt(x, 10));
      break;
    default:
      throw new Error(`unsupported type: ${type}`);
  }
  let buf = Buffer.alloc(0);
  let run = [];
  let repeats = 0;
  for (let i = 0; i < values.length; i++) {
    if (repeats === 0 && run.length % 8 === 0 && values[i] === values[i + 1]) {
      if (run.length) {
        buf = Buffer.concat([buf, encodeRunBitpacked(run, opts)]);
        run = [];
      }
      repeats = 1;
    } else if (repeats > 0 && values[i] === values[i - 1]) {
      repeats += 1;
    } else {
      if (repeats) {
        buf = Buffer.concat([buf, encodeRunRepeated(values[i - 1], repeats, opts)]);
        repeats = 0;
      }
      run.push(values[i]);
    }
  }
  if (repeats) {
    buf = Buffer.concat([buf, encodeRunRepeated(values[values.length - 1], repeats, opts)]);
  } else if (run.length) {
    buf = Buffer.concat([buf, encodeRunBitpacked(run, opts)]);
  }
  if (opts.disableEnvelope) {
    return buf;
  }
  const envelope = Buffer.alloc(buf.length + 4);
  envelope.writeUInt32LE(buf.length, void 0);
  buf.copy(envelope, 4);
  return envelope;
}
function decodeValues2(type, cursor, count, opts) {
  if (!("bitWidth" in opts)) {
    throw new Error("bitWidth is required");
  }
  if (!opts.disableEnvelope) {
    cursor.offset += 4;
  }
  let values = [];
  while (values.length < count) {
    const header = import_varint.default.decode(cursor.buffer, cursor.offset);
    cursor.offset += import_varint.default.encodingLength(header);
    let decodedValues;
    if (header & 1) {
      const count2 = (header >> 1) * 8;
      decodedValues = decodeRunBitpacked(cursor, count2, opts);
    } else {
      const count2 = header >> 1;
      decodedValues = decodeRunRepeated(cursor, count2, opts);
    }
    for (const value of decodedValues) {
      values.push(value);
    }
  }
  values = values.slice(0, count);
  if (values.length !== count) {
    throw new Error("invalid RLE encoding");
  }
  return values;
}
function decodeRunBitpacked(cursor, count, opts) {
  const bitWidth = opts.bitWidth;
  if (count % 8 !== 0) {
    throw new Error("must be a multiple of 8");
  }
  const values = new Array(count).fill(0);
  for (let b = 0; b < bitWidth * count; b++) {
    if (cursor.buffer[cursor.offset + Math.floor(b / 8)] & 1 << b % 8) {
      values[Math.floor(b / bitWidth)] |= 1 << b % bitWidth;
    }
  }
  cursor.offset += bitWidth * (count / 8);
  return values;
}
function decodeRunRepeated(cursor, count, opts) {
  const bitWidth = opts.bitWidth;
  let value = 0;
  for (let i = 0; i < Math.ceil(bitWidth / 8); i++) {
    value << 8;
    value += cursor.buffer[cursor.offset];
    cursor.offset += 1;
  }
  return new Array(count).fill(value);
}
function encodeRunBitpacked(values, opts) {
  const bitWidth = opts.bitWidth;
  for (let i = 0; i < values.length % 8; i++) {
    values.push(0);
  }
  const buf = Buffer.alloc(Math.ceil(bitWidth * (values.length / 8)));
  for (let b = 0; b < bitWidth * values.length; b++) {
    if ((values[Math.floor(b / bitWidth)] & 1 << b % bitWidth) > 0) {
      buf[Math.floor(b / 8)] |= 1 << b % 8;
    }
  }
  return Buffer.concat([Buffer.from(import_varint.default.encode(values.length / 8 << 1 | 1)), buf]);
}
function encodeRunRepeated(value, count, opts) {
  const bitWidth = opts.bitWidth;
  const buf = Buffer.alloc(Math.ceil(bitWidth / 8));
  for (let i = 0; i < buf.length; i++) {
    buf.writeUInt8(value & 255, i);
    value >> 8;
  }
  return Buffer.concat([Buffer.from(import_varint.default.encode(count << 1)), buf]);
}

// dist/parquetjs/codecs/dictionary.js
function decodeValues3(type, cursor, count, opts) {
  opts.bitWidth = cursor.buffer.slice(cursor.offset, cursor.offset + 1).readInt8(0);
  cursor.offset += 1;
  return decodeValues2(type, cursor, count, { ...opts, disableEnvelope: true });
}
function encodeValues3(type, cursor, count, opts) {
  throw new Error("Encode dictionary functionality is not supported");
}

// dist/parquetjs/codecs/index.js
var PARQUET_CODECS = {
  PLAIN: {
    encodeValues,
    decodeValues
  },
  RLE: {
    encodeValues: encodeValues2,
    decodeValues: decodeValues2
  },
  // Using the PLAIN_DICTIONARY enum value is deprecated in the Parquet 2.0 specification.
  PLAIN_DICTIONARY: {
    // @ts-ignore
    encodeValues: encodeValues3,
    decodeValues: decodeValues3
  },
  // Prefer using RLE_DICTIONARY in a data page and PLAIN in a dictionary page for Parquet 2.0+ files.
  RLE_DICTIONARY: {
    // @ts-ignore
    encodeValues: encodeValues3,
    decodeValues: decodeValues3
  }
};

// dist/parquetjs/compression.js
var import_compression = require("@loaders.gl/compression");
var import_loader_utils = require("@loaders.gl/loader-utils");
var import_lz4js = __toESM(require("lz4js"), 1);
function toBuffer(arrayBuffer) {
  return Buffer.from(arrayBuffer);
}
function toArrayBuffer(buffer) {
  if (Buffer.isBuffer(buffer)) {
    const typedArray = new Uint8Array(buffer.buffer, buffer.byteOffset, buffer.length);
    return typedArray.slice().buffer;
  }
  return buffer;
}
var modules = {
  // brotli has problems with decompress in browsers
  // brotli: {
  //   decompress: brotliDecompress,
  //   compress: () => {
  //     throw new Error('brotli compress');
  //   }
  // },
  lz4js: import_lz4js.default
  // lzo
  // 'zstd-codec': ZstdCodec
};
var PARQUET_COMPRESSION_METHODS = {
  UNCOMPRESSED: new import_compression.NoCompression(),
  GZIP: new import_compression.GZipCompression(),
  SNAPPY: new import_compression.SnappyCompression(),
  BROTLI: new import_compression.BrotliCompression({ modules }),
  // TODO: Understand difference between LZ4 and LZ4_RAW
  LZ4: new import_compression.LZ4Compression({ modules }),
  LZ4_RAW: new import_compression.LZ4Compression({ modules }),
  //
  // LZO: new LZOCompression({modules}),
  ZSTD: new import_compression.ZstdCompression({ modules })
};
async function preloadCompressions(options) {
  (0, import_loader_utils.registerJSModules)(options == null ? void 0 : options.modules);
  const compressions = Object.values(PARQUET_COMPRESSION_METHODS);
  return await Promise.all(compressions.map((compression) => compression.preload(options == null ? void 0 : options.modules)));
}
async function deflate(method, value) {
  const compression = PARQUET_COMPRESSION_METHODS[method];
  if (!compression) {
    throw new Error(`parquet: invalid compression method: ${method}`);
  }
  const inputArrayBuffer = toArrayBuffer(value);
  const compressedArrayBuffer = await compression.compress(inputArrayBuffer);
  return toBuffer(compressedArrayBuffer);
}
async function decompress(method, value, size) {
  const compression = PARQUET_COMPRESSION_METHODS[method];
  if (!compression) {
    throw new Error(`parquet: invalid compression method: ${method}`);
  }
  const inputArrayBuffer = toArrayBuffer(value);
  const compressedArrayBuffer = await compression.decompress(inputArrayBuffer, size);
  return toBuffer(compressedArrayBuffer);
}

// dist/parquetjs/schema/types.js
var import_bson = require("@loaders.gl/bson");
var PARQUET_LOGICAL_TYPES = {
  BOOLEAN: {
    primitiveType: "BOOLEAN",
    toPrimitive: toPrimitive_BOOLEAN,
    fromPrimitive: fromPrimitive_BOOLEAN
  },
  INT32: {
    primitiveType: "INT32",
    toPrimitive: toPrimitive_INT32
  },
  INT64: {
    primitiveType: "INT64",
    toPrimitive: toPrimitive_INT64
  },
  INT96: {
    primitiveType: "INT96",
    toPrimitive: toPrimitive_INT96
  },
  FLOAT: {
    primitiveType: "FLOAT",
    toPrimitive: toPrimitive_FLOAT
  },
  DOUBLE: {
    primitiveType: "DOUBLE",
    toPrimitive: toPrimitive_DOUBLE
  },
  BYTE_ARRAY: {
    primitiveType: "BYTE_ARRAY",
    toPrimitive: toPrimitive_BYTE_ARRAY
  },
  FIXED_LEN_BYTE_ARRAY: {
    primitiveType: "FIXED_LEN_BYTE_ARRAY",
    toPrimitive: toPrimitive_BYTE_ARRAY
  },
  UTF8: {
    primitiveType: "BYTE_ARRAY",
    originalType: "UTF8",
    toPrimitive: toPrimitive_UTF8,
    fromPrimitive: fromPrimitive_UTF8
  },
  TIME_MILLIS: {
    primitiveType: "INT32",
    originalType: "TIME_MILLIS",
    toPrimitive: toPrimitive_TIME_MILLIS
  },
  TIME_MICROS: {
    primitiveType: "INT64",
    originalType: "TIME_MICROS",
    toPrimitive: toPrimitive_TIME_MICROS
  },
  DATE: {
    primitiveType: "INT32",
    originalType: "DATE",
    toPrimitive: toPrimitive_DATE,
    fromPrimitive: fromPrimitive_DATE
  },
  TIMESTAMP_MILLIS: {
    primitiveType: "INT64",
    originalType: "TIMESTAMP_MILLIS",
    toPrimitive: toPrimitive_TIMESTAMP_MILLIS,
    fromPrimitive: fromPrimitive_TIMESTAMP_MILLIS
  },
  TIMESTAMP_MICROS: {
    primitiveType: "INT64",
    originalType: "TIMESTAMP_MICROS",
    toPrimitive: toPrimitive_TIMESTAMP_MICROS,
    fromPrimitive: fromPrimitive_TIMESTAMP_MICROS
  },
  UINT_8: {
    primitiveType: "INT32",
    originalType: "UINT_8",
    toPrimitive: toPrimitive_UINT8
  },
  UINT_16: {
    primitiveType: "INT32",
    originalType: "UINT_16",
    toPrimitive: toPrimitive_UINT16
  },
  UINT_32: {
    primitiveType: "INT32",
    originalType: "UINT_32",
    toPrimitive: toPrimitive_UINT32
  },
  UINT_64: {
    primitiveType: "INT64",
    originalType: "UINT_64",
    toPrimitive: toPrimitive_UINT64
  },
  INT_8: {
    primitiveType: "INT32",
    originalType: "INT_8",
    toPrimitive: toPrimitive_INT8
  },
  INT_16: {
    primitiveType: "INT32",
    originalType: "INT_16",
    toPrimitive: toPrimitive_INT16
  },
  INT_32: {
    primitiveType: "INT32",
    originalType: "INT_32",
    toPrimitive: toPrimitive_INT32
  },
  INT_64: {
    primitiveType: "INT64",
    originalType: "INT_64",
    toPrimitive: toPrimitive_INT64
  },
  JSON: {
    primitiveType: "BYTE_ARRAY",
    originalType: "JSON",
    toPrimitive: toPrimitive_JSON,
    fromPrimitive: fromPrimitive_JSON
  },
  BSON: {
    primitiveType: "BYTE_ARRAY",
    originalType: "BSON",
    toPrimitive: toPrimitive_BSON,
    fromPrimitive: fromPrimitive_BSON
  },
  INTERVAL: {
    primitiveType: "FIXED_LEN_BYTE_ARRAY",
    originalType: "INTERVAL",
    typeLength: 12,
    toPrimitive: toPrimitive_INTERVAL,
    fromPrimitive: fromPrimitive_INTERVAL
  },
  DECIMAL_INT32: {
    primitiveType: "INT32",
    originalType: "DECIMAL_INT32",
    toPrimitive: decimalToPrimitive_INT32,
    fromPrimitive: decimalFromPrimitive_INT
  },
  DECIMAL_INT64: {
    primitiveType: "INT64",
    originalType: "DECIMAL_INT64",
    toPrimitive: decimalToPrimitive_INT64,
    fromPrimitive: decimalFromPrimitive_INT
  },
  DECIMAL_BYTE_ARRAY: {
    primitiveType: "BYTE_ARRAY",
    originalType: "DECIMAL_BYTE_ARRAY",
    toPrimitive: decimalToPrimitive_BYTE_ARRAY,
    fromPrimitive: decimalFromPrimitive_BYTE_ARRAY
  },
  DECIMAL_FIXED_LEN_BYTE_ARRAY: {
    primitiveType: "FIXED_LEN_BYTE_ARRAY",
    originalType: "DECIMAL_FIXED_LEN_BYTE_ARRAY",
    toPrimitive: decimalToPrimitive_BYTE_ARRAY,
    fromPrimitive: decimalFromPrimitive_BYTE_ARRAY
  }
};
function toPrimitive(type, value, field) {
  if (!(type in PARQUET_LOGICAL_TYPES)) {
    throw new Error(`invalid type: ${type}`);
  }
  return PARQUET_LOGICAL_TYPES[type].toPrimitive(value, field);
}
function fromPrimitive(type, value, field) {
  var _a, _b;
  if (!(type in PARQUET_LOGICAL_TYPES)) {
    throw new Error(`invalid type: ${type}`);
  }
  if ("fromPrimitive" in PARQUET_LOGICAL_TYPES[type]) {
    return (_b = (_a = PARQUET_LOGICAL_TYPES[type]).fromPrimitive) == null ? void 0 : _b.call(_a, value, field);
  }
  return value;
}
function toPrimitive_BOOLEAN(value) {
  return Boolean(value);
}
function fromPrimitive_BOOLEAN(value) {
  return Boolean(value);
}
function toPrimitive_FLOAT(value) {
  const v = parseFloat(value);
  if (isNaN(v)) {
    throw new Error(`invalid value for FLOAT: ${value}`);
  }
  return v;
}
function toPrimitive_DOUBLE(value) {
  const v = parseFloat(value);
  if (isNaN(v)) {
    throw new Error(`invalid value for DOUBLE: ${value}`);
  }
  return v;
}
function toPrimitive_INT8(value) {
  const v = parseInt(value, 10);
  if (v < -128 || v > 127 || isNaN(v)) {
    throw new Error(`invalid value for INT8: ${value}`);
  }
  return v;
}
function toPrimitive_UINT8(value) {
  const v = parseInt(value, 10);
  if (v < 0 || v > 255 || isNaN(v)) {
    throw new Error(`invalid value for UINT8: ${value}`);
  }
  return v;
}
function toPrimitive_INT16(value) {
  const v = parseInt(value, 10);
  if (v < -32768 || v > 32767 || isNaN(v)) {
    throw new Error(`invalid value for INT16: ${value}`);
  }
  return v;
}
function toPrimitive_UINT16(value) {
  const v = parseInt(value, 10);
  if (v < 0 || v > 65535 || isNaN(v)) {
    throw new Error(`invalid value for UINT16: ${value}`);
  }
  return v;
}
function toPrimitive_INT32(value) {
  const v = parseInt(value, 10);
  if (v < -2147483648 || v > 2147483647 || isNaN(v)) {
    throw new Error(`invalid value for INT32: ${value}`);
  }
  return v;
}
function decimalToPrimitive_INT32(value, field) {
  const primitiveValue = value * 10 ** (field.scale || 0);
  const v = Math.round(primitiveValue * 10 ** -field.presision % 1 * 10 ** field.presision);
  if (v < -2147483648 || v > 2147483647 || isNaN(v)) {
    throw new Error(`invalid value for INT32: ${value}`);
  }
  return v;
}
function toPrimitive_UINT32(value) {
  const v = parseInt(value, 10);
  if (v < 0 || v > 281474976710655 || isNaN(v)) {
    throw new Error(`invalid value for UINT32: ${value}`);
  }
  return v;
}
function toPrimitive_INT64(value) {
  const v = parseInt(value, 10);
  if (isNaN(v)) {
    throw new Error(`invalid value for INT64: ${value}`);
  }
  return v;
}
function decimalToPrimitive_INT64(value, field) {
  const primitiveValue = value * 10 ** (field.scale || 0);
  const v = Math.round(primitiveValue * 10 ** -field.presision % 1 * 10 ** field.presision);
  if (isNaN(v)) {
    throw new Error(`invalid value for INT64: ${value}`);
  }
  return v;
}
function toPrimitive_UINT64(value) {
  const v = parseInt(value, 10);
  if (v < 0 || isNaN(v)) {
    throw new Error(`invalid value for UINT64: ${value}`);
  }
  return v;
}
function toPrimitive_INT96(value) {
  const v = parseInt(value, 10);
  if (isNaN(v)) {
    throw new Error(`invalid value for INT96: ${value}`);
  }
  return v;
}
function toPrimitive_BYTE_ARRAY(value) {
  return Buffer.from(value);
}
function decimalToPrimitive_BYTE_ARRAY(value) {
  return Buffer.from(value);
}
function toPrimitive_UTF8(value) {
  return Buffer.from(value, "utf8");
}
function fromPrimitive_UTF8(value) {
  return value.toString();
}
function toPrimitive_JSON(value) {
  return Buffer.from(JSON.stringify(value));
}
function fromPrimitive_JSON(value) {
  return JSON.parse(value);
}
function toPrimitive_BSON(value) {
  var _a, _b;
  const arrayBuffer = (_b = (_a = import_bson.BSONWriter).encodeSync) == null ? void 0 : _b.call(_a, value);
  return Buffer.from(arrayBuffer);
}
function fromPrimitive_BSON(value) {
  var _a, _b;
  return (_b = (_a = import_bson.BSONLoader).parseSync) == null ? void 0 : _b.call(_a, value);
}
function toPrimitive_TIME_MILLIS(value) {
  const v = parseInt(value, 10);
  if (v < 0 || v > 18446744073709552e3 || isNaN(v)) {
    throw new Error(`invalid value for TIME_MILLIS: ${value}`);
  }
  return v;
}
function toPrimitive_TIME_MICROS(value) {
  const v = parseInt(value, 10);
  if (v < 0 || isNaN(v)) {
    throw new Error(`invalid value for TIME_MICROS: ${value}`);
  }
  return v;
}
var kMillisPerDay = 864e5;
function toPrimitive_DATE(value) {
  if (value instanceof Date) {
    return value.getTime() / kMillisPerDay;
  }
  {
    const v = parseInt(value, 10);
    if (v < 0 || isNaN(v)) {
      throw new Error(`invalid value for DATE: ${value}`);
    }
    return v;
  }
}
function fromPrimitive_DATE(value) {
  return new Date(value * kMillisPerDay);
}
function toPrimitive_TIMESTAMP_MILLIS(value) {
  if (value instanceof Date) {
    return value.getTime();
  }
  {
    const v = parseInt(value, 10);
    if (v < 0 || isNaN(v)) {
      throw new Error(`invalid value for TIMESTAMP_MILLIS: ${value}`);
    }
    return v;
  }
}
function fromPrimitive_TIMESTAMP_MILLIS(value) {
  return new Date(value);
}
function toPrimitive_TIMESTAMP_MICROS(value) {
  if (value instanceof Date) {
    return value.getTime() * 1e3;
  }
  {
    const v = parseInt(value, 10);
    if (v < 0 || isNaN(v)) {
      throw new Error(`invalid value for TIMESTAMP_MICROS: ${value}`);
    }
    return v;
  }
}
function fromPrimitive_TIMESTAMP_MICROS(value) {
  return new Date(value / 1e3);
}
function toPrimitive_INTERVAL(value) {
  if (!value.months || !value.days || !value.milliseconds) {
    throw new Error("value for INTERVAL must be object { months: ..., days: ..., milliseconds: ... }");
  }
  const buf = Buffer.alloc(12);
  buf.writeUInt32LE(value.months, 0);
  buf.writeUInt32LE(value.days, 4);
  buf.writeUInt32LE(value.milliseconds, 8);
  return buf;
}
function fromPrimitive_INTERVAL(value) {
  const buf = Buffer.from(value);
  const months = buf.readUInt32LE(0);
  const days = buf.readUInt32LE(4);
  const millis = buf.readUInt32LE(8);
  return { months, days, milliseconds: millis };
}
function decimalFromPrimitive_INT(value, field) {
  const presisionInt = Math.round(value * 10 ** -field.presision % 1 * 10 ** field.presision);
  return presisionInt * 10 ** -(field.scale || 0);
}
function decimalFromPrimitive_BYTE_ARRAY(value, field) {
  let number = 0;
  if (value.length <= 4) {
    for (let i = 0; i < value.length; i++) {
      const component = value[i] << 8 * (value.length - i - 1);
      number += component;
    }
  } else {
    for (let i = 0; i < value.length; i++) {
      const component = value[i] * 2 ** (8 * (value.length - 1 - i));
      number += component;
    }
  }
  const presisionInt = Math.round(number * 10 ** -field.presision % 1 * 10 ** field.presision);
  return presisionInt * 10 ** -(field.scale || 0);
}

// dist/parquetjs/schema/shred.js
function shredBuffer(schema) {
  const columnData = {};
  for (const field of schema.fieldList) {
    columnData[field.key] = {
      dlevels: [],
      rlevels: [],
      values: [],
      pageHeaders: [],
      count: 0
    };
  }
  return { rowCount: 0, columnData };
}
function shredRecord(schema, record, rowGroup) {
  const data = shredBuffer(schema).columnData;
  shredRecordFields(schema.fields, record, data, 0, 0);
  if (rowGroup.rowCount === 0) {
    rowGroup.rowCount = 1;
    rowGroup.columnData = data;
    return;
  }
  rowGroup.rowCount += 1;
  for (const field of schema.fieldList) {
    Array.prototype.push.apply(rowGroup.columnData[field.key].rlevels, data[field.key].rlevels);
    Array.prototype.push.apply(rowGroup.columnData[field.key].dlevels, data[field.key].dlevels);
    Array.prototype.push.apply(rowGroup.columnData[field.key].values, data[field.key].values);
    rowGroup.columnData[field.key].count += data[field.key].count;
  }
}
function shredRecordFields(fields, record, data, rLevel, dLevel) {
  for (const name in fields) {
    const field = fields[name];
    let values = [];
    if (record && field.name in record && record[field.name] !== void 0 && record[field.name] !== null) {
      if (record[field.name].constructor === Array) {
        values = record[field.name];
      } else {
        values.push(record[field.name]);
      }
    }
    if (values.length === 0 && Boolean(record) && field.repetitionType === "REQUIRED") {
      throw new Error(`missing required field: ${field.name}`);
    }
    if (values.length > 1 && field.repetitionType !== "REPEATED") {
      throw new Error(`too many values for field: ${field.name}`);
    }
    if (values.length === 0) {
      if (field.isNested) {
        shredRecordFields(field.fields, null, data, rLevel, dLevel);
      } else {
        data[field.key].count += 1;
        data[field.key].rlevels.push(rLevel);
        data[field.key].dlevels.push(dLevel);
      }
      continue;
    }
    for (let i = 0; i < values.length; i++) {
      const rlvl = i === 0 ? rLevel : field.rLevelMax;
      if (field.isNested) {
        shredRecordFields(field.fields, values[i], data, rlvl, field.dLevelMax);
      } else {
        data[field.key].count += 1;
        data[field.key].rlevels.push(rlvl);
        data[field.key].dlevels.push(field.dLevelMax);
        data[field.key].values.push(toPrimitive(field.originalType || field.primitiveType, values[i]));
      }
    }
  }
}
function materializeRows(schema, rowGroup) {
  const rows = [];
  for (let i = 0; i < rowGroup.rowCount; i++) {
    rows.push({});
  }
  for (const key in rowGroup.columnData) {
    const columnData = rowGroup.columnData[key];
    if (columnData.count) {
      materializeColumnAsRows(schema, columnData, key, rows);
    }
  }
  return rows;
}
function materializeColumnAsRows(schema, columnData, key, rows) {
  const field = schema.findField(key);
  const branch = schema.findFieldBranch(key);
  const rLevels = new Array(field.rLevelMax + 1).fill(0);
  let vIndex = 0;
  for (let i = 0; i < columnData.count; i++) {
    const dLevel = columnData.dlevels[i];
    const rLevel = columnData.rlevels[i];
    rLevels[rLevel]++;
    rLevels.fill(0, rLevel + 1);
    let rIndex = 0;
    let record = rows[rLevels[rIndex++] - 1];
    for (const step of branch) {
      if (step === field || dLevel < step.dLevelMax) {
        break;
      }
      switch (step.repetitionType) {
        case "REPEATED":
          if (!(step.name in record)) {
            record[step.name] = [];
          }
          const ix = rLevels[rIndex++];
          while (record[step.name].length <= ix) {
            record[step.name].push({});
          }
          record = record[step.name][ix];
          break;
        default:
          record[step.name] = record[step.name] || {};
          record = record[step.name];
      }
    }
    if (dLevel === field.dLevelMax) {
      const value = fromPrimitive(
        // @ts-ignore
        field.originalType || field.primitiveType,
        columnData.values[vIndex],
        field
      );
      vIndex++;
      switch (field.repetitionType) {
        case "REPEATED":
          if (!(field.name in record)) {
            record[field.name] = [];
          }
          const ix = rLevels[rIndex];
          while (record[field.name].length <= ix) {
            record[field.name].push(null);
          }
          record[field.name][ix] = value;
          break;
        default:
          record[field.name] = value;
      }
    }
  }
}
function materializeColumns(schema, rowGroup) {
  const columns = {};
  for (const key in rowGroup.columnData) {
    const columnData = rowGroup.columnData[key];
    if (columnData.count) {
      materializeColumnAsColumnarArray(schema, columnData, rowGroup.rowCount, key, columns);
    }
  }
  return columns;
}
function materializeColumnAsColumnarArray(schema, columnData, rowCount, key, columns) {
  if (columnData.count <= 0) {
    return;
  }
  const field = schema.findField(key);
  const branch = schema.findFieldBranch(key);
  const columnName = branch[0].name;
  let column;
  const { values } = columnData;
  if (values.length === rowCount && branch[0].primitiveType) {
    column = values;
  }
  if (column) {
    columns[columnName] = column;
    return;
  }
  column = new Array(rowCount);
  for (let i = 0; i < rowCount; i++) {
    column[i] = {};
  }
  columns[columnName] = column;
  const rLevels = new Array(field.rLevelMax + 1).fill(0);
  let vIndex = 0;
  for (let i = 0; i < columnData.count; i++) {
    const dLevel = columnData.dlevels[i];
    const rLevel = columnData.rlevels[i];
    rLevels[rLevel]++;
    rLevels.fill(0, rLevel + 1);
    let rIndex = 0;
    let record = column[rLevels[rIndex++] - 1];
    for (const step of branch) {
      if (step === field || dLevel < step.dLevelMax) {
        break;
      }
      switch (step.repetitionType) {
        case "REPEATED":
          if (!(step.name in record)) {
            record[step.name] = [];
          }
          const ix = rLevels[rIndex++];
          while (record[step.name].length <= ix) {
            record[step.name].push({});
          }
          record = record[step.name][ix];
          break;
        default:
          record[step.name] = record[step.name] || {};
          record = record[step.name];
      }
    }
    if (dLevel === field.dLevelMax) {
      const value = fromPrimitive(
        // @ts-ignore
        field.originalType || field.primitiveType,
        columnData.values[vIndex],
        field
      );
      vIndex++;
      switch (field.repetitionType) {
        case "REPEATED":
          if (!(field.name in record)) {
            record[field.name] = [];
          }
          const ix = rLevels[rIndex];
          while (record[field.name].length <= ix) {
            record[field.name].push(null);
          }
          record[field.name][ix] = value;
          break;
        default:
          record[field.name] = value;
      }
    }
  }
  for (let i = 0; i < rowCount; ++i) {
    if (columnName in column[i]) {
      column[i] = column[i][columnName];
    }
  }
}

// dist/parquetjs/schema/schema.js
var ParquetSchema = class {
  schema;
  fields;
  fieldList;
  /**
   * Create a new schema from a JSON schema definition
   */
  constructor(schema) {
    this.schema = schema;
    this.fields = buildFields(schema, 0, 0, []);
    this.fieldList = listFields(this.fields);
  }
  /**
   * Retrieve a field definition
   */
  findField(path) {
    if (typeof path === "string") {
      path = path.split(",");
    } else {
      path = path.slice(0);
    }
    let n = this.fields;
    for (; path.length > 1; path.shift()) {
      n = n[path[0]].fields;
    }
    return n[path[0]];
  }
  /**
   * Retrieve a field definition and all the field's ancestors
   */
  findFieldBranch(path) {
    if (typeof path === "string") {
      path = path.split(",");
    }
    const branch = [];
    let n = this.fields;
    for (; path.length > 0; path.shift()) {
      branch.push(n[path[0]]);
      if (path.length > 1) {
        n = n[path[0]].fields;
      }
    }
    return branch;
  }
  shredRecord(row, rowGroup) {
    shredRecord(this, row, rowGroup);
  }
  materializeRows(rowGroup) {
    return materializeRows(this, rowGroup);
  }
  compress(type) {
    setCompress(this.schema, type);
    setCompress(this.fields, type);
    return this;
  }
  rowGroup() {
    return shredBuffer(this);
  }
};
function setCompress(schema, type) {
  for (const name in schema) {
    const node = schema[name];
    if (node.fields) {
      setCompress(node.fields, type);
    } else {
      node.compression = type;
    }
  }
}
function buildFields(schema, rLevelParentMax, dLevelParentMax, path) {
  const fieldList = {};
  for (const name in schema) {
    const opts = schema[name];
    const required = !opts.optional;
    const repeated = Boolean(opts.repeated);
    let rLevelMax = rLevelParentMax;
    let dLevelMax = dLevelParentMax;
    let repetitionType = "REQUIRED";
    if (!required) {
      repetitionType = "OPTIONAL";
      dLevelMax++;
    }
    if (repeated) {
      repetitionType = "REPEATED";
      rLevelMax++;
      if (required)
        dLevelMax++;
    }
    if (opts.fields) {
      const cpath2 = path.concat([name]);
      fieldList[name] = {
        name,
        path: cpath2,
        key: cpath2.join(),
        repetitionType,
        rLevelMax,
        dLevelMax,
        isNested: true,
        fieldCount: Object.keys(opts.fields).length,
        fields: buildFields(opts.fields, rLevelMax, dLevelMax, cpath2)
      };
      continue;
    }
    const typeDef = PARQUET_LOGICAL_TYPES[opts.type];
    if (!typeDef) {
      throw new Error(`invalid parquet type: ${opts.type}`);
    }
    opts.encoding = opts.encoding || "PLAIN";
    if (!(opts.encoding in PARQUET_CODECS)) {
      throw new Error(`unsupported parquet encoding: ${opts.encoding}`);
    }
    opts.compression = opts.compression || "UNCOMPRESSED";
    if (!(opts.compression in PARQUET_COMPRESSION_METHODS)) {
      throw new Error(`unsupported compression method: ${opts.compression}`);
    }
    const cpath = path.concat([name]);
    fieldList[name] = {
      name,
      primitiveType: typeDef.primitiveType,
      originalType: typeDef.originalType,
      path: cpath,
      key: cpath.join(),
      repetitionType,
      encoding: opts.encoding,
      compression: opts.compression,
      typeLength: opts.typeLength || typeDef.typeLength,
      presision: opts.presision,
      scale: opts.scale,
      rLevelMax,
      dLevelMax
    };
  }
  return fieldList;
}
function listFields(fields) {
  let list = [];
  for (const k in fields) {
    list.push(fields[k]);
    if (fields[k].isNested) {
      list = list.concat(listFields(fields[k].fields));
    }
  }
  return list;
}

// dist/parquetjs/parquet-thrift/index.js
var import_thrift = require("thrift");

// dist/parquetjs/parquet-thrift/Type.js
var Type;
(function(Type2) {
  Type2[Type2["BOOLEAN"] = 0] = "BOOLEAN";
  Type2[Type2["INT32"] = 1] = "INT32";
  Type2[Type2["INT64"] = 2] = "INT64";
  Type2[Type2["INT96"] = 3] = "INT96";
  Type2[Type2["FLOAT"] = 4] = "FLOAT";
  Type2[Type2["DOUBLE"] = 5] = "DOUBLE";
  Type2[Type2["BYTE_ARRAY"] = 6] = "BYTE_ARRAY";
  Type2[Type2["FIXED_LEN_BYTE_ARRAY"] = 7] = "FIXED_LEN_BYTE_ARRAY";
})(Type || (Type = {}));

// dist/parquetjs/parquet-thrift/ConvertedType.js
var ConvertedType;
(function(ConvertedType2) {
  ConvertedType2[ConvertedType2["UTF8"] = 0] = "UTF8";
  ConvertedType2[ConvertedType2["MAP"] = 1] = "MAP";
  ConvertedType2[ConvertedType2["MAP_KEY_VALUE"] = 2] = "MAP_KEY_VALUE";
  ConvertedType2[ConvertedType2["LIST"] = 3] = "LIST";
  ConvertedType2[ConvertedType2["ENUM"] = 4] = "ENUM";
  ConvertedType2[ConvertedType2["DECIMAL"] = 5] = "DECIMAL";
  ConvertedType2[ConvertedType2["DATE"] = 6] = "DATE";
  ConvertedType2[ConvertedType2["TIME_MILLIS"] = 7] = "TIME_MILLIS";
  ConvertedType2[ConvertedType2["TIME_MICROS"] = 8] = "TIME_MICROS";
  ConvertedType2[ConvertedType2["TIMESTAMP_MILLIS"] = 9] = "TIMESTAMP_MILLIS";
  ConvertedType2[ConvertedType2["TIMESTAMP_MICROS"] = 10] = "TIMESTAMP_MICROS";
  ConvertedType2[ConvertedType2["UINT_8"] = 11] = "UINT_8";
  ConvertedType2[ConvertedType2["UINT_16"] = 12] = "UINT_16";
  ConvertedType2[ConvertedType2["UINT_32"] = 13] = "UINT_32";
  ConvertedType2[ConvertedType2["UINT_64"] = 14] = "UINT_64";
  ConvertedType2[ConvertedType2["INT_8"] = 15] = "INT_8";
  ConvertedType2[ConvertedType2["INT_16"] = 16] = "INT_16";
  ConvertedType2[ConvertedType2["INT_32"] = 17] = "INT_32";
  ConvertedType2[ConvertedType2["INT_64"] = 18] = "INT_64";
  ConvertedType2[ConvertedType2["JSON"] = 19] = "JSON";
  ConvertedType2[ConvertedType2["BSON"] = 20] = "BSON";
  ConvertedType2[ConvertedType2["INTERVAL"] = 21] = "INTERVAL";
})(ConvertedType || (ConvertedType = {}));

// dist/parquetjs/parquet-thrift/FieldRepetitionType.js
var FieldRepetitionType;
(function(FieldRepetitionType2) {
  FieldRepetitionType2[FieldRepetitionType2["REQUIRED"] = 0] = "REQUIRED";
  FieldRepetitionType2[FieldRepetitionType2["OPTIONAL"] = 1] = "OPTIONAL";
  FieldRepetitionType2[FieldRepetitionType2["REPEATED"] = 2] = "REPEATED";
})(FieldRepetitionType || (FieldRepetitionType = {}));

// dist/parquetjs/parquet-thrift/Encoding.js
var Encoding;
(function(Encoding2) {
  Encoding2[Encoding2["PLAIN"] = 0] = "PLAIN";
  Encoding2[Encoding2["PLAIN_DICTIONARY"] = 2] = "PLAIN_DICTIONARY";
  Encoding2[Encoding2["RLE"] = 3] = "RLE";
  Encoding2[Encoding2["BIT_PACKED"] = 4] = "BIT_PACKED";
  Encoding2[Encoding2["DELTA_BINARY_PACKED"] = 5] = "DELTA_BINARY_PACKED";
  Encoding2[Encoding2["DELTA_LENGTH_BYTE_ARRAY"] = 6] = "DELTA_LENGTH_BYTE_ARRAY";
  Encoding2[Encoding2["DELTA_BYTE_ARRAY"] = 7] = "DELTA_BYTE_ARRAY";
  Encoding2[Encoding2["RLE_DICTIONARY"] = 8] = "RLE_DICTIONARY";
})(Encoding || (Encoding = {}));

// dist/parquetjs/parquet-thrift/CompressionCodec.js
var CompressionCodec;
(function(CompressionCodec2) {
  CompressionCodec2[CompressionCodec2["UNCOMPRESSED"] = 0] = "UNCOMPRESSED";
  CompressionCodec2[CompressionCodec2["SNAPPY"] = 1] = "SNAPPY";
  CompressionCodec2[CompressionCodec2["GZIP"] = 2] = "GZIP";
  CompressionCodec2[CompressionCodec2["LZO"] = 3] = "LZO";
  CompressionCodec2[CompressionCodec2["BROTLI"] = 4] = "BROTLI";
  CompressionCodec2[CompressionCodec2["LZ4"] = 5] = "LZ4";
  CompressionCodec2[CompressionCodec2["ZSTD"] = 6] = "ZSTD";
  CompressionCodec2[CompressionCodec2["LZ4_RAW"] = 7] = "LZ4_RAW";
})(CompressionCodec || (CompressionCodec = {}));

// dist/parquetjs/parquet-thrift/PageType.js
var PageType;
(function(PageType2) {
  PageType2[PageType2["DATA_PAGE"] = 0] = "DATA_PAGE";
  PageType2[PageType2["INDEX_PAGE"] = 1] = "INDEX_PAGE";
  PageType2[PageType2["DICTIONARY_PAGE"] = 2] = "DICTIONARY_PAGE";
  PageType2[PageType2["DATA_PAGE_V2"] = 3] = "DATA_PAGE_V2";
})(PageType || (PageType = {}));

// dist/parquetjs/parquet-thrift/Statistics.js
var import_node_int64 = __toESM(require("node-int64"), 1);
var thrift = __toESM(require("thrift"), 1);
var Statistics = class {
  max;
  min;
  null_count;
  distinct_count;
  max_value;
  min_value;
  constructor(args) {
    if (args != null && args.max != null) {
      this.max = args.max;
    }
    if (args != null && args.min != null) {
      this.min = args.min;
    }
    if (args != null && args.null_count != null) {
      if (typeof args.null_count === "number") {
        this.null_count = new import_node_int64.default(args.null_count);
      } else {
        this.null_count = args.null_count;
      }
    }
    if (args != null && args.distinct_count != null) {
      if (typeof args.distinct_count === "number") {
        this.distinct_count = new import_node_int64.default(args.distinct_count);
      } else {
        this.distinct_count = args.distinct_count;
      }
    }
    if (args != null && args.max_value != null) {
      this.max_value = args.max_value;
    }
    if (args != null && args.min_value != null) {
      this.min_value = args.min_value;
    }
  }
  write(output) {
    output.writeStructBegin("Statistics");
    if (this.max != null) {
      output.writeFieldBegin("max", thrift.Thrift.Type.STRING, 1);
      output.writeBinary(this.max);
      output.writeFieldEnd();
    }
    if (this.min != null) {
      output.writeFieldBegin("min", thrift.Thrift.Type.STRING, 2);
      output.writeBinary(this.min);
      output.writeFieldEnd();
    }
    if (this.null_count != null) {
      output.writeFieldBegin("null_count", thrift.Thrift.Type.I64, 3);
      output.writeI64(this.null_count);
      output.writeFieldEnd();
    }
    if (this.distinct_count != null) {
      output.writeFieldBegin("distinct_count", thrift.Thrift.Type.I64, 4);
      output.writeI64(this.distinct_count);
      output.writeFieldEnd();
    }
    if (this.max_value != null) {
      output.writeFieldBegin("max_value", thrift.Thrift.Type.STRING, 5);
      output.writeBinary(this.max_value);
      output.writeFieldEnd();
    }
    if (this.min_value != null) {
      output.writeFieldBegin("min_value", thrift.Thrift.Type.STRING, 6);
      output.writeBinary(this.min_value);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift.Thrift.Type.STRING) {
            const value_1 = input.readBinary();
            _args.max = value_1;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift.Thrift.Type.STRING) {
            const value_2 = input.readBinary();
            _args.min = value_2;
          } else {
            input.skip(fieldType);
          }
          break;
        case 3:
          if (fieldType === thrift.Thrift.Type.I64) {
            const value_3 = input.readI64();
            _args.null_count = value_3;
          } else {
            input.skip(fieldType);
          }
          break;
        case 4:
          if (fieldType === thrift.Thrift.Type.I64) {
            const value_4 = input.readI64();
            _args.distinct_count = value_4;
          } else {
            input.skip(fieldType);
          }
          break;
        case 5:
          if (fieldType === thrift.Thrift.Type.STRING) {
            const value_5 = input.readBinary();
            _args.max_value = value_5;
          } else {
            input.skip(fieldType);
          }
          break;
        case 6:
          if (fieldType === thrift.Thrift.Type.STRING) {
            const value_6 = input.readBinary();
            _args.min_value = value_6;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    return new Statistics(_args);
  }
};

// dist/parquetjs/parquet-thrift/StringType.js
var thrift2 = __toESM(require("thrift"), 1);
var StringType = class {
  constructor() {
  }
  write(output) {
    output.writeStructBegin("StringType");
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift2.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    return new StringType();
  }
};

// dist/parquetjs/parquet-thrift/UUIDType.js
var thrift3 = __toESM(require("thrift"), 1);
var UUIDType = class {
  constructor() {
  }
  write(output) {
    output.writeStructBegin("UUIDType");
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift3.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    return new UUIDType();
  }
};

// dist/parquetjs/parquet-thrift/MapType.js
var thrift4 = __toESM(require("thrift"), 1);
var MapType = class {
  constructor() {
  }
  write(output) {
    output.writeStructBegin("MapType");
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift4.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    return new MapType();
  }
};

// dist/parquetjs/parquet-thrift/ListType.js
var thrift5 = __toESM(require("thrift"), 1);
var ListType = class {
  constructor() {
  }
  write(output) {
    output.writeStructBegin("ListType");
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift5.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    return new ListType();
  }
};

// dist/parquetjs/parquet-thrift/EnumType.js
var thrift6 = __toESM(require("thrift"), 1);
var EnumType = class {
  constructor() {
  }
  write(output) {
    output.writeStructBegin("EnumType");
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift6.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    return new EnumType();
  }
};

// dist/parquetjs/parquet-thrift/DateType.js
var thrift7 = __toESM(require("thrift"), 1);
var DateType = class {
  constructor() {
  }
  write(output) {
    output.writeStructBegin("DateType");
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift7.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    return new DateType();
  }
};

// dist/parquetjs/parquet-thrift/NullType.js
var thrift8 = __toESM(require("thrift"), 1);
var NullType = class {
  constructor() {
  }
  write(output) {
    output.writeStructBegin("NullType");
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift8.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    return new NullType();
  }
};

// dist/parquetjs/parquet-thrift/DecimalType.js
var thrift9 = __toESM(require("thrift"), 1);
var DecimalType = class {
  scale;
  precision;
  constructor(args) {
    if (args != null && args.scale != null) {
      this.scale = args.scale;
    } else {
      throw new thrift9.Thrift.TProtocolException(thrift9.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[scale] is unset!");
    }
    if (args != null && args.precision != null) {
      this.precision = args.precision;
    } else {
      throw new thrift9.Thrift.TProtocolException(thrift9.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[precision] is unset!");
    }
  }
  write(output) {
    output.writeStructBegin("DecimalType");
    if (this.scale != null) {
      output.writeFieldBegin("scale", thrift9.Thrift.Type.I32, 1);
      output.writeI32(this.scale);
      output.writeFieldEnd();
    }
    if (this.precision != null) {
      output.writeFieldBegin("precision", thrift9.Thrift.Type.I32, 2);
      output.writeI32(this.precision);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift9.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift9.Thrift.Type.I32) {
            const value_1 = input.readI32();
            _args.scale = value_1;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift9.Thrift.Type.I32) {
            const value_2 = input.readI32();
            _args.precision = value_2;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.scale !== void 0 && _args.precision !== void 0) {
      return new DecimalType(_args);
    } else {
      throw new thrift9.Thrift.TProtocolException(thrift9.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read DecimalType from input");
    }
  }
};

// dist/parquetjs/parquet-thrift/MilliSeconds.js
var thrift10 = __toESM(require("thrift"), 1);
var MilliSeconds = class {
  constructor() {
  }
  write(output) {
    output.writeStructBegin("MilliSeconds");
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift10.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    return new MilliSeconds();
  }
};

// dist/parquetjs/parquet-thrift/MicroSeconds.js
var thrift11 = __toESM(require("thrift"), 1);
var MicroSeconds = class {
  constructor() {
  }
  write(output) {
    output.writeStructBegin("MicroSeconds");
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift11.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    return new MicroSeconds();
  }
};

// dist/parquetjs/parquet-thrift/TimestampType.js
var thrift13 = __toESM(require("thrift"), 1);

// dist/parquetjs/parquet-thrift/TimeUnit.js
var thrift12 = __toESM(require("thrift"), 1);
var TimeUnit = class {
  MILLIS;
  MICROS;
  constructor(args) {
    let _fieldsSet = 0;
    if (args != null) {
      if (args.MILLIS != null) {
        _fieldsSet++;
        this.MILLIS = args.MILLIS;
      }
      if (args.MICROS != null) {
        _fieldsSet++;
        this.MICROS = args.MICROS;
      }
      if (_fieldsSet > 1) {
        throw new thrift12.Thrift.TProtocolException(thrift12.Thrift.TProtocolExceptionType.INVALID_DATA, "Cannot read a TUnion with more than one set value!");
      } else if (_fieldsSet < 1) {
        throw new thrift12.Thrift.TProtocolException(thrift12.Thrift.TProtocolExceptionType.INVALID_DATA, "Cannot read a TUnion with no set value!");
      }
    }
  }
  static fromMILLIS(MILLIS) {
    return new TimeUnit({ MILLIS });
  }
  static fromMICROS(MICROS) {
    return new TimeUnit({ MICROS });
  }
  write(output) {
    output.writeStructBegin("TimeUnit");
    if (this.MILLIS != null) {
      output.writeFieldBegin("MILLIS", thrift12.Thrift.Type.STRUCT, 1);
      this.MILLIS.write(output);
      output.writeFieldEnd();
    }
    if (this.MICROS != null) {
      output.writeFieldBegin("MICROS", thrift12.Thrift.Type.STRUCT, 2);
      this.MICROS.write(output);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    let _fieldsSet = 0;
    let _returnValue = null;
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift12.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift12.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_1 = MilliSeconds.read(input);
            _returnValue = TimeUnit.fromMILLIS(value_1);
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift12.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_2 = MicroSeconds.read(input);
            _returnValue = TimeUnit.fromMICROS(value_2);
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_fieldsSet > 1) {
      throw new thrift12.Thrift.TProtocolException(thrift12.Thrift.TProtocolExceptionType.INVALID_DATA, "Cannot read a TUnion with more than one set value!");
    } else if (_fieldsSet < 1) {
      throw new thrift12.Thrift.TProtocolException(thrift12.Thrift.TProtocolExceptionType.INVALID_DATA, "Cannot read a TUnion with no set value!");
    }
    if (_returnValue !== null) {
      return _returnValue;
    } else {
      throw new thrift12.Thrift.TProtocolException(thrift12.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read data for TUnion");
    }
  }
};

// dist/parquetjs/parquet-thrift/TimestampType.js
var TimestampType = class {
  isAdjustedToUTC;
  unit;
  constructor(args) {
    if (args != null && args.isAdjustedToUTC != null) {
      this.isAdjustedToUTC = args.isAdjustedToUTC;
    } else {
      throw new thrift13.Thrift.TProtocolException(thrift13.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[isAdjustedToUTC] is unset!");
    }
    if (args != null && args.unit != null) {
      this.unit = args.unit;
    } else {
      throw new thrift13.Thrift.TProtocolException(thrift13.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[unit] is unset!");
    }
  }
  write(output) {
    output.writeStructBegin("TimestampType");
    if (this.isAdjustedToUTC != null) {
      output.writeFieldBegin("isAdjustedToUTC", thrift13.Thrift.Type.BOOL, 1);
      output.writeBool(this.isAdjustedToUTC);
      output.writeFieldEnd();
    }
    if (this.unit != null) {
      output.writeFieldBegin("unit", thrift13.Thrift.Type.STRUCT, 2);
      this.unit.write(output);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift13.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift13.Thrift.Type.BOOL) {
            const value_1 = input.readBool();
            _args.isAdjustedToUTC = value_1;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift13.Thrift.Type.STRUCT) {
            const value_2 = TimeUnit.read(input);
            _args.unit = value_2;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.isAdjustedToUTC !== void 0 && _args.unit !== void 0) {
      return new TimestampType(_args);
    } else {
      throw new thrift13.Thrift.TProtocolException(thrift13.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read TimestampType from input");
    }
  }
};

// dist/parquetjs/parquet-thrift/TimeType.js
var thrift14 = __toESM(require("thrift"), 1);
var TimeType = class {
  isAdjustedToUTC;
  unit;
  constructor(args) {
    if (args != null && args.isAdjustedToUTC != null) {
      this.isAdjustedToUTC = args.isAdjustedToUTC;
    } else {
      throw new thrift14.Thrift.TProtocolException(thrift14.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[isAdjustedToUTC] is unset!");
    }
    if (args != null && args.unit != null) {
      this.unit = args.unit;
    } else {
      throw new thrift14.Thrift.TProtocolException(thrift14.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[unit] is unset!");
    }
  }
  write(output) {
    output.writeStructBegin("TimeType");
    if (this.isAdjustedToUTC != null) {
      output.writeFieldBegin("isAdjustedToUTC", thrift14.Thrift.Type.BOOL, 1);
      output.writeBool(this.isAdjustedToUTC);
      output.writeFieldEnd();
    }
    if (this.unit != null) {
      output.writeFieldBegin("unit", thrift14.Thrift.Type.STRUCT, 2);
      this.unit.write(output);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift14.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift14.Thrift.Type.BOOL) {
            const value_1 = input.readBool();
            _args.isAdjustedToUTC = value_1;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift14.Thrift.Type.STRUCT) {
            const value_2 = TimeUnit.read(input);
            _args.unit = value_2;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.isAdjustedToUTC !== void 0 && _args.unit !== void 0) {
      return new TimeType(_args);
    } else {
      throw new thrift14.Thrift.TProtocolException(thrift14.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read TimeType from input");
    }
  }
};

// dist/parquetjs/parquet-thrift/IntType.js
var thrift15 = __toESM(require("thrift"), 1);
var IntType = class {
  bitWidth;
  isSigned;
  constructor(args) {
    if (args != null && args.bitWidth != null) {
      this.bitWidth = args.bitWidth;
    } else {
      throw new thrift15.Thrift.TProtocolException(thrift15.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[bitWidth] is unset!");
    }
    if (args != null && args.isSigned != null) {
      this.isSigned = args.isSigned;
    } else {
      throw new thrift15.Thrift.TProtocolException(thrift15.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[isSigned] is unset!");
    }
  }
  write(output) {
    output.writeStructBegin("IntType");
    if (this.bitWidth != null) {
      output.writeFieldBegin("bitWidth", thrift15.Thrift.Type.BYTE, 1);
      output.writeByte(this.bitWidth);
      output.writeFieldEnd();
    }
    if (this.isSigned != null) {
      output.writeFieldBegin("isSigned", thrift15.Thrift.Type.BOOL, 2);
      output.writeBool(this.isSigned);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift15.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift15.Thrift.Type.BYTE) {
            const value_1 = input.readByte();
            _args.bitWidth = value_1;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift15.Thrift.Type.BOOL) {
            const value_2 = input.readBool();
            _args.isSigned = value_2;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.bitWidth !== void 0 && _args.isSigned !== void 0) {
      return new IntType(_args);
    } else {
      throw new thrift15.Thrift.TProtocolException(thrift15.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read IntType from input");
    }
  }
};

// dist/parquetjs/parquet-thrift/JsonType.js
var thrift16 = __toESM(require("thrift"), 1);
var JsonType = class {
  constructor() {
  }
  write(output) {
    output.writeStructBegin("JsonType");
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift16.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    return new JsonType();
  }
};

// dist/parquetjs/parquet-thrift/BsonType.js
var thrift17 = __toESM(require("thrift"), 1);
var BsonType = class {
  constructor() {
  }
  write(output) {
    output.writeStructBegin("BsonType");
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift17.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    return new BsonType();
  }
};

// dist/parquetjs/parquet-thrift/SchemaElement.js
var thrift19 = __toESM(require("thrift"), 1);

// dist/parquetjs/parquet-thrift/LogicalType.js
var thrift18 = __toESM(require("thrift"), 1);
var LogicalType = class {
  STRING;
  MAP;
  LIST;
  ENUM;
  DECIMAL;
  DATE;
  TIME;
  TIMESTAMP;
  INTEGER;
  UNKNOWN;
  JSON;
  BSON;
  UUID;
  constructor(args) {
    let _fieldsSet = 0;
    if (args != null) {
      if (args.STRING != null) {
        _fieldsSet++;
        this.STRING = args.STRING;
      }
      if (args.MAP != null) {
        _fieldsSet++;
        this.MAP = args.MAP;
      }
      if (args.LIST != null) {
        _fieldsSet++;
        this.LIST = args.LIST;
      }
      if (args.ENUM != null) {
        _fieldsSet++;
        this.ENUM = args.ENUM;
      }
      if (args.DECIMAL != null) {
        _fieldsSet++;
        this.DECIMAL = args.DECIMAL;
      }
      if (args.DATE != null) {
        _fieldsSet++;
        this.DATE = args.DATE;
      }
      if (args.TIME != null) {
        _fieldsSet++;
        this.TIME = args.TIME;
      }
      if (args.TIMESTAMP != null) {
        _fieldsSet++;
        this.TIMESTAMP = args.TIMESTAMP;
      }
      if (args.INTEGER != null) {
        _fieldsSet++;
        this.INTEGER = args.INTEGER;
      }
      if (args.UNKNOWN != null) {
        _fieldsSet++;
        this.UNKNOWN = args.UNKNOWN;
      }
      if (args.JSON != null) {
        _fieldsSet++;
        this.JSON = args.JSON;
      }
      if (args.BSON != null) {
        _fieldsSet++;
        this.BSON = args.BSON;
      }
      if (args.UUID != null) {
        _fieldsSet++;
        this.UUID = args.UUID;
      }
      if (_fieldsSet > 1) {
        throw new thrift18.Thrift.TProtocolException(thrift18.Thrift.TProtocolExceptionType.INVALID_DATA, "Cannot read a TUnion with more than one set value!");
      } else if (_fieldsSet < 1) {
        throw new thrift18.Thrift.TProtocolException(thrift18.Thrift.TProtocolExceptionType.INVALID_DATA, "Cannot read a TUnion with no set value!");
      }
    }
  }
  static fromSTRING(STRING) {
    return new LogicalType({ STRING });
  }
  static fromMAP(MAP) {
    return new LogicalType({ MAP });
  }
  static fromLIST(LIST) {
    return new LogicalType({ LIST });
  }
  static fromENUM(ENUM) {
    return new LogicalType({ ENUM });
  }
  static fromDECIMAL(DECIMAL) {
    return new LogicalType({ DECIMAL });
  }
  static fromDATE(DATE) {
    return new LogicalType({ DATE });
  }
  static fromTIME(TIME) {
    return new LogicalType({ TIME });
  }
  static fromTIMESTAMP(TIMESTAMP) {
    return new LogicalType({ TIMESTAMP });
  }
  static fromINTEGER(INTEGER) {
    return new LogicalType({ INTEGER });
  }
  static fromUNKNOWN(UNKNOWN) {
    return new LogicalType({ UNKNOWN });
  }
  static fromJSON(JSON2) {
    return new LogicalType({ JSON: JSON2 });
  }
  static fromBSON(BSON) {
    return new LogicalType({ BSON });
  }
  static fromUUID(UUID) {
    return new LogicalType({ UUID });
  }
  write(output) {
    output.writeStructBegin("LogicalType");
    if (this.STRING != null) {
      output.writeFieldBegin("STRING", thrift18.Thrift.Type.STRUCT, 1);
      this.STRING.write(output);
      output.writeFieldEnd();
    }
    if (this.MAP != null) {
      output.writeFieldBegin("MAP", thrift18.Thrift.Type.STRUCT, 2);
      this.MAP.write(output);
      output.writeFieldEnd();
    }
    if (this.LIST != null) {
      output.writeFieldBegin("LIST", thrift18.Thrift.Type.STRUCT, 3);
      this.LIST.write(output);
      output.writeFieldEnd();
    }
    if (this.ENUM != null) {
      output.writeFieldBegin("ENUM", thrift18.Thrift.Type.STRUCT, 4);
      this.ENUM.write(output);
      output.writeFieldEnd();
    }
    if (this.DECIMAL != null) {
      output.writeFieldBegin("DECIMAL", thrift18.Thrift.Type.STRUCT, 5);
      this.DECIMAL.write(output);
      output.writeFieldEnd();
    }
    if (this.DATE != null) {
      output.writeFieldBegin("DATE", thrift18.Thrift.Type.STRUCT, 6);
      this.DATE.write(output);
      output.writeFieldEnd();
    }
    if (this.TIME != null) {
      output.writeFieldBegin("TIME", thrift18.Thrift.Type.STRUCT, 7);
      this.TIME.write(output);
      output.writeFieldEnd();
    }
    if (this.TIMESTAMP != null) {
      output.writeFieldBegin("TIMESTAMP", thrift18.Thrift.Type.STRUCT, 8);
      this.TIMESTAMP.write(output);
      output.writeFieldEnd();
    }
    if (this.INTEGER != null) {
      output.writeFieldBegin("INTEGER", thrift18.Thrift.Type.STRUCT, 10);
      this.INTEGER.write(output);
      output.writeFieldEnd();
    }
    if (this.UNKNOWN != null) {
      output.writeFieldBegin("UNKNOWN", thrift18.Thrift.Type.STRUCT, 11);
      this.UNKNOWN.write(output);
      output.writeFieldEnd();
    }
    if (this.JSON != null) {
      output.writeFieldBegin("JSON", thrift18.Thrift.Type.STRUCT, 12);
      this.JSON.write(output);
      output.writeFieldEnd();
    }
    if (this.BSON != null) {
      output.writeFieldBegin("BSON", thrift18.Thrift.Type.STRUCT, 13);
      this.BSON.write(output);
      output.writeFieldEnd();
    }
    if (this.UUID != null) {
      output.writeFieldBegin("UUID", thrift18.Thrift.Type.STRUCT, 14);
      this.UUID.write(output);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    let _fieldsSet = 0;
    let _returnValue = null;
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift18.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift18.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_1 = StringType.read(input);
            _returnValue = LogicalType.fromSTRING(value_1);
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift18.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_2 = MapType.read(input);
            _returnValue = LogicalType.fromMAP(value_2);
          } else {
            input.skip(fieldType);
          }
          break;
        case 3:
          if (fieldType === thrift18.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_3 = ListType.read(input);
            _returnValue = LogicalType.fromLIST(value_3);
          } else {
            input.skip(fieldType);
          }
          break;
        case 4:
          if (fieldType === thrift18.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_4 = EnumType.read(input);
            _returnValue = LogicalType.fromENUM(value_4);
          } else {
            input.skip(fieldType);
          }
          break;
        case 5:
          if (fieldType === thrift18.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_5 = DecimalType.read(input);
            _returnValue = LogicalType.fromDECIMAL(value_5);
          } else {
            input.skip(fieldType);
          }
          break;
        case 6:
          if (fieldType === thrift18.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_6 = DateType.read(input);
            _returnValue = LogicalType.fromDATE(value_6);
          } else {
            input.skip(fieldType);
          }
          break;
        case 7:
          if (fieldType === thrift18.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_7 = TimeType.read(input);
            _returnValue = LogicalType.fromTIME(value_7);
          } else {
            input.skip(fieldType);
          }
          break;
        case 8:
          if (fieldType === thrift18.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_8 = TimestampType.read(input);
            _returnValue = LogicalType.fromTIMESTAMP(value_8);
          } else {
            input.skip(fieldType);
          }
          break;
        case 10:
          if (fieldType === thrift18.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_9 = IntType.read(input);
            _returnValue = LogicalType.fromINTEGER(value_9);
          } else {
            input.skip(fieldType);
          }
          break;
        case 11:
          if (fieldType === thrift18.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_10 = NullType.read(input);
            _returnValue = LogicalType.fromUNKNOWN(value_10);
          } else {
            input.skip(fieldType);
          }
          break;
        case 12:
          if (fieldType === thrift18.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_11 = JsonType.read(input);
            _returnValue = LogicalType.fromJSON(value_11);
          } else {
            input.skip(fieldType);
          }
          break;
        case 13:
          if (fieldType === thrift18.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_12 = BsonType.read(input);
            _returnValue = LogicalType.fromBSON(value_12);
          } else {
            input.skip(fieldType);
          }
          break;
        case 14:
          if (fieldType === thrift18.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_13 = UUIDType.read(input);
            _returnValue = LogicalType.fromUUID(value_13);
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_fieldsSet > 1) {
      throw new thrift18.Thrift.TProtocolException(thrift18.Thrift.TProtocolExceptionType.INVALID_DATA, "Cannot read a TUnion with more than one set value!");
    } else if (_fieldsSet < 1) {
      throw new thrift18.Thrift.TProtocolException(thrift18.Thrift.TProtocolExceptionType.INVALID_DATA, "Cannot read a TUnion with no set value!");
    }
    if (_returnValue !== null) {
      return _returnValue;
    } else {
      throw new thrift18.Thrift.TProtocolException(thrift18.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read data for TUnion");
    }
  }
};

// dist/parquetjs/parquet-thrift/SchemaElement.js
var SchemaElement = class {
  type;
  type_length;
  repetition_type;
  name;
  num_children;
  converted_type;
  scale;
  precision;
  field_id;
  logicalType;
  constructor(args) {
    if (args != null && args.type != null) {
      this.type = args.type;
    }
    if (args != null && args.type_length != null) {
      this.type_length = args.type_length;
    }
    if (args != null && args.repetition_type != null) {
      this.repetition_type = args.repetition_type;
    }
    if (args != null && args.name != null) {
      this.name = args.name;
    } else {
      throw new thrift19.Thrift.TProtocolException(thrift19.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[name] is unset!");
    }
    if (args != null && args.num_children != null) {
      this.num_children = args.num_children;
    }
    if (args != null && args.converted_type != null) {
      this.converted_type = args.converted_type;
    }
    if (args != null && args.scale != null) {
      this.scale = args.scale;
    }
    if (args != null && args.precision != null) {
      this.precision = args.precision;
    }
    if (args != null && args.field_id != null) {
      this.field_id = args.field_id;
    }
    if (args != null && args.logicalType != null) {
      this.logicalType = args.logicalType;
    }
  }
  write(output) {
    output.writeStructBegin("SchemaElement");
    if (this.type != null) {
      output.writeFieldBegin("type", thrift19.Thrift.Type.I32, 1);
      output.writeI32(this.type);
      output.writeFieldEnd();
    }
    if (this.type_length != null) {
      output.writeFieldBegin("type_length", thrift19.Thrift.Type.I32, 2);
      output.writeI32(this.type_length);
      output.writeFieldEnd();
    }
    if (this.repetition_type != null) {
      output.writeFieldBegin("repetition_type", thrift19.Thrift.Type.I32, 3);
      output.writeI32(this.repetition_type);
      output.writeFieldEnd();
    }
    if (this.name != null) {
      output.writeFieldBegin("name", thrift19.Thrift.Type.STRING, 4);
      output.writeString(this.name);
      output.writeFieldEnd();
    }
    if (this.num_children != null) {
      output.writeFieldBegin("num_children", thrift19.Thrift.Type.I32, 5);
      output.writeI32(this.num_children);
      output.writeFieldEnd();
    }
    if (this.converted_type != null) {
      output.writeFieldBegin("converted_type", thrift19.Thrift.Type.I32, 6);
      output.writeI32(this.converted_type);
      output.writeFieldEnd();
    }
    if (this.scale != null) {
      output.writeFieldBegin("scale", thrift19.Thrift.Type.I32, 7);
      output.writeI32(this.scale);
      output.writeFieldEnd();
    }
    if (this.precision != null) {
      output.writeFieldBegin("precision", thrift19.Thrift.Type.I32, 8);
      output.writeI32(this.precision);
      output.writeFieldEnd();
    }
    if (this.field_id != null) {
      output.writeFieldBegin("field_id", thrift19.Thrift.Type.I32, 9);
      output.writeI32(this.field_id);
      output.writeFieldEnd();
    }
    if (this.logicalType != null) {
      output.writeFieldBegin("logicalType", thrift19.Thrift.Type.STRUCT, 10);
      this.logicalType.write(output);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift19.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift19.Thrift.Type.I32) {
            const value_1 = input.readI32();
            _args.type = value_1;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift19.Thrift.Type.I32) {
            const value_2 = input.readI32();
            _args.type_length = value_2;
          } else {
            input.skip(fieldType);
          }
          break;
        case 3:
          if (fieldType === thrift19.Thrift.Type.I32) {
            const value_3 = input.readI32();
            _args.repetition_type = value_3;
          } else {
            input.skip(fieldType);
          }
          break;
        case 4:
          if (fieldType === thrift19.Thrift.Type.STRING) {
            const value_4 = input.readString();
            _args.name = value_4;
          } else {
            input.skip(fieldType);
          }
          break;
        case 5:
          if (fieldType === thrift19.Thrift.Type.I32) {
            const value_5 = input.readI32();
            _args.num_children = value_5;
          } else {
            input.skip(fieldType);
          }
          break;
        case 6:
          if (fieldType === thrift19.Thrift.Type.I32) {
            const value_6 = input.readI32();
            _args.converted_type = value_6;
          } else {
            input.skip(fieldType);
          }
          break;
        case 7:
          if (fieldType === thrift19.Thrift.Type.I32) {
            const value_7 = input.readI32();
            _args.scale = value_7;
          } else {
            input.skip(fieldType);
          }
          break;
        case 8:
          if (fieldType === thrift19.Thrift.Type.I32) {
            const value_8 = input.readI32();
            _args.precision = value_8;
          } else {
            input.skip(fieldType);
          }
          break;
        case 9:
          if (fieldType === thrift19.Thrift.Type.I32) {
            const value_9 = input.readI32();
            _args.field_id = value_9;
          } else {
            input.skip(fieldType);
          }
          break;
        case 10:
          if (fieldType === thrift19.Thrift.Type.STRUCT) {
            const value_10 = LogicalType.read(input);
            _args.logicalType = value_10;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.name !== void 0) {
      return new SchemaElement(_args);
    } else {
      throw new thrift19.Thrift.TProtocolException(thrift19.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read SchemaElement from input");
    }
  }
};

// dist/parquetjs/parquet-thrift/DataPageHeader.js
var thrift20 = __toESM(require("thrift"), 1);
var DataPageHeader = class {
  num_values;
  encoding;
  definition_level_encoding;
  repetition_level_encoding;
  statistics;
  constructor(args) {
    if (args != null && args.num_values != null) {
      this.num_values = args.num_values;
    } else {
      throw new thrift20.Thrift.TProtocolException(thrift20.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[num_values] is unset!");
    }
    if (args != null && args.encoding != null) {
      this.encoding = args.encoding;
    } else {
      throw new thrift20.Thrift.TProtocolException(thrift20.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[encoding] is unset!");
    }
    if (args != null && args.definition_level_encoding != null) {
      this.definition_level_encoding = args.definition_level_encoding;
    } else {
      throw new thrift20.Thrift.TProtocolException(thrift20.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[definition_level_encoding] is unset!");
    }
    if (args != null && args.repetition_level_encoding != null) {
      this.repetition_level_encoding = args.repetition_level_encoding;
    } else {
      throw new thrift20.Thrift.TProtocolException(thrift20.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[repetition_level_encoding] is unset!");
    }
    if (args != null && args.statistics != null) {
      this.statistics = args.statistics;
    }
  }
  write(output) {
    output.writeStructBegin("DataPageHeader");
    if (this.num_values != null) {
      output.writeFieldBegin("num_values", thrift20.Thrift.Type.I32, 1);
      output.writeI32(this.num_values);
      output.writeFieldEnd();
    }
    if (this.encoding != null) {
      output.writeFieldBegin("encoding", thrift20.Thrift.Type.I32, 2);
      output.writeI32(this.encoding);
      output.writeFieldEnd();
    }
    if (this.definition_level_encoding != null) {
      output.writeFieldBegin("definition_level_encoding", thrift20.Thrift.Type.I32, 3);
      output.writeI32(this.definition_level_encoding);
      output.writeFieldEnd();
    }
    if (this.repetition_level_encoding != null) {
      output.writeFieldBegin("repetition_level_encoding", thrift20.Thrift.Type.I32, 4);
      output.writeI32(this.repetition_level_encoding);
      output.writeFieldEnd();
    }
    if (this.statistics != null) {
      output.writeFieldBegin("statistics", thrift20.Thrift.Type.STRUCT, 5);
      this.statistics.write(output);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift20.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift20.Thrift.Type.I32) {
            const value_1 = input.readI32();
            _args.num_values = value_1;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift20.Thrift.Type.I32) {
            const value_2 = input.readI32();
            _args.encoding = value_2;
          } else {
            input.skip(fieldType);
          }
          break;
        case 3:
          if (fieldType === thrift20.Thrift.Type.I32) {
            const value_3 = input.readI32();
            _args.definition_level_encoding = value_3;
          } else {
            input.skip(fieldType);
          }
          break;
        case 4:
          if (fieldType === thrift20.Thrift.Type.I32) {
            const value_4 = input.readI32();
            _args.repetition_level_encoding = value_4;
          } else {
            input.skip(fieldType);
          }
          break;
        case 5:
          if (fieldType === thrift20.Thrift.Type.STRUCT) {
            const value_5 = Statistics.read(input);
            _args.statistics = value_5;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.num_values !== void 0 && _args.encoding !== void 0 && _args.definition_level_encoding !== void 0 && _args.repetition_level_encoding !== void 0) {
      return new DataPageHeader(_args);
    } else {
      throw new thrift20.Thrift.TProtocolException(thrift20.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read DataPageHeader from input");
    }
  }
};

// dist/parquetjs/parquet-thrift/IndexPageHeader.js
var thrift21 = __toESM(require("thrift"), 1);
var IndexPageHeader = class {
  constructor() {
  }
  write(output) {
    output.writeStructBegin("IndexPageHeader");
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift21.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    return new IndexPageHeader();
  }
};

// dist/parquetjs/parquet-thrift/DictionaryPageHeader.js
var thrift22 = __toESM(require("thrift"), 1);
var DictionaryPageHeader = class {
  num_values;
  encoding;
  is_sorted;
  constructor(args) {
    if (args != null && args.num_values != null) {
      this.num_values = args.num_values;
    } else {
      throw new thrift22.Thrift.TProtocolException(thrift22.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[num_values] is unset!");
    }
    if (args != null && args.encoding != null) {
      this.encoding = args.encoding;
    } else {
      throw new thrift22.Thrift.TProtocolException(thrift22.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[encoding] is unset!");
    }
    if (args != null && args.is_sorted != null) {
      this.is_sorted = args.is_sorted;
    }
  }
  write(output) {
    output.writeStructBegin("DictionaryPageHeader");
    if (this.num_values != null) {
      output.writeFieldBegin("num_values", thrift22.Thrift.Type.I32, 1);
      output.writeI32(this.num_values);
      output.writeFieldEnd();
    }
    if (this.encoding != null) {
      output.writeFieldBegin("encoding", thrift22.Thrift.Type.I32, 2);
      output.writeI32(this.encoding);
      output.writeFieldEnd();
    }
    if (this.is_sorted != null) {
      output.writeFieldBegin("is_sorted", thrift22.Thrift.Type.BOOL, 3);
      output.writeBool(this.is_sorted);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift22.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift22.Thrift.Type.I32) {
            const value_1 = input.readI32();
            _args.num_values = value_1;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift22.Thrift.Type.I32) {
            const value_2 = input.readI32();
            _args.encoding = value_2;
          } else {
            input.skip(fieldType);
          }
          break;
        case 3:
          if (fieldType === thrift22.Thrift.Type.BOOL) {
            const value_3 = input.readBool();
            _args.is_sorted = value_3;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.num_values !== void 0 && _args.encoding !== void 0) {
      return new DictionaryPageHeader(_args);
    } else {
      throw new thrift22.Thrift.TProtocolException(thrift22.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read DictionaryPageHeader from input");
    }
  }
};

// dist/parquetjs/parquet-thrift/DataPageHeaderV2.js
var thrift23 = __toESM(require("thrift"), 1);
var DataPageHeaderV2 = class {
  num_values;
  num_nulls;
  num_rows;
  encoding;
  definition_levels_byte_length;
  repetition_levels_byte_length;
  is_compressed = true;
  statistics;
  constructor(args) {
    if (args != null && args.num_values != null) {
      this.num_values = args.num_values;
    } else {
      throw new thrift23.Thrift.TProtocolException(thrift23.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[num_values] is unset!");
    }
    if (args != null && args.num_nulls != null) {
      this.num_nulls = args.num_nulls;
    } else {
      throw new thrift23.Thrift.TProtocolException(thrift23.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[num_nulls] is unset!");
    }
    if (args != null && args.num_rows != null) {
      this.num_rows = args.num_rows;
    } else {
      throw new thrift23.Thrift.TProtocolException(thrift23.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[num_rows] is unset!");
    }
    if (args != null && args.encoding != null) {
      this.encoding = args.encoding;
    } else {
      throw new thrift23.Thrift.TProtocolException(thrift23.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[encoding] is unset!");
    }
    if (args != null && args.definition_levels_byte_length != null) {
      this.definition_levels_byte_length = args.definition_levels_byte_length;
    } else {
      throw new thrift23.Thrift.TProtocolException(thrift23.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[definition_levels_byte_length] is unset!");
    }
    if (args != null && args.repetition_levels_byte_length != null) {
      this.repetition_levels_byte_length = args.repetition_levels_byte_length;
    } else {
      throw new thrift23.Thrift.TProtocolException(thrift23.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[repetition_levels_byte_length] is unset!");
    }
    if (args != null && args.is_compressed != null) {
      this.is_compressed = args.is_compressed;
    }
    if (args != null && args.statistics != null) {
      this.statistics = args.statistics;
    }
  }
  write(output) {
    output.writeStructBegin("DataPageHeaderV2");
    if (this.num_values != null) {
      output.writeFieldBegin("num_values", thrift23.Thrift.Type.I32, 1);
      output.writeI32(this.num_values);
      output.writeFieldEnd();
    }
    if (this.num_nulls != null) {
      output.writeFieldBegin("num_nulls", thrift23.Thrift.Type.I32, 2);
      output.writeI32(this.num_nulls);
      output.writeFieldEnd();
    }
    if (this.num_rows != null) {
      output.writeFieldBegin("num_rows", thrift23.Thrift.Type.I32, 3);
      output.writeI32(this.num_rows);
      output.writeFieldEnd();
    }
    if (this.encoding != null) {
      output.writeFieldBegin("encoding", thrift23.Thrift.Type.I32, 4);
      output.writeI32(this.encoding);
      output.writeFieldEnd();
    }
    if (this.definition_levels_byte_length != null) {
      output.writeFieldBegin("definition_levels_byte_length", thrift23.Thrift.Type.I32, 5);
      output.writeI32(this.definition_levels_byte_length);
      output.writeFieldEnd();
    }
    if (this.repetition_levels_byte_length != null) {
      output.writeFieldBegin("repetition_levels_byte_length", thrift23.Thrift.Type.I32, 6);
      output.writeI32(this.repetition_levels_byte_length);
      output.writeFieldEnd();
    }
    if (this.is_compressed != null) {
      output.writeFieldBegin("is_compressed", thrift23.Thrift.Type.BOOL, 7);
      output.writeBool(this.is_compressed);
      output.writeFieldEnd();
    }
    if (this.statistics != null) {
      output.writeFieldBegin("statistics", thrift23.Thrift.Type.STRUCT, 8);
      this.statistics.write(output);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift23.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift23.Thrift.Type.I32) {
            const value_1 = input.readI32();
            _args.num_values = value_1;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift23.Thrift.Type.I32) {
            const value_2 = input.readI32();
            _args.num_nulls = value_2;
          } else {
            input.skip(fieldType);
          }
          break;
        case 3:
          if (fieldType === thrift23.Thrift.Type.I32) {
            const value_3 = input.readI32();
            _args.num_rows = value_3;
          } else {
            input.skip(fieldType);
          }
          break;
        case 4:
          if (fieldType === thrift23.Thrift.Type.I32) {
            const value_4 = input.readI32();
            _args.encoding = value_4;
          } else {
            input.skip(fieldType);
          }
          break;
        case 5:
          if (fieldType === thrift23.Thrift.Type.I32) {
            const value_5 = input.readI32();
            _args.definition_levels_byte_length = value_5;
          } else {
            input.skip(fieldType);
          }
          break;
        case 6:
          if (fieldType === thrift23.Thrift.Type.I32) {
            const value_6 = input.readI32();
            _args.repetition_levels_byte_length = value_6;
          } else {
            input.skip(fieldType);
          }
          break;
        case 7:
          if (fieldType === thrift23.Thrift.Type.BOOL) {
            const value_7 = input.readBool();
            _args.is_compressed = value_7;
          } else {
            input.skip(fieldType);
          }
          break;
        case 8:
          if (fieldType === thrift23.Thrift.Type.STRUCT) {
            const value_8 = Statistics.read(input);
            _args.statistics = value_8;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.num_values !== void 0 && _args.num_nulls !== void 0 && _args.num_rows !== void 0 && _args.encoding !== void 0 && _args.definition_levels_byte_length !== void 0 && _args.repetition_levels_byte_length !== void 0) {
      return new DataPageHeaderV2(_args);
    } else {
      throw new thrift23.Thrift.TProtocolException(thrift23.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read DataPageHeaderV2 from input");
    }
  }
};

// dist/parquetjs/parquet-thrift/PageHeader.js
var thrift24 = __toESM(require("thrift"), 1);
var PageHeader = class {
  type;
  uncompressed_page_size;
  compressed_page_size;
  crc;
  data_page_header;
  index_page_header;
  dictionary_page_header;
  data_page_header_v2;
  constructor(args) {
    if (args != null && args.type != null) {
      this.type = args.type;
    } else {
      throw new thrift24.Thrift.TProtocolException(thrift24.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[type] is unset!");
    }
    if (args != null && args.uncompressed_page_size != null) {
      this.uncompressed_page_size = args.uncompressed_page_size;
    } else {
      throw new thrift24.Thrift.TProtocolException(thrift24.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[uncompressed_page_size] is unset!");
    }
    if (args != null && args.compressed_page_size != null) {
      this.compressed_page_size = args.compressed_page_size;
    } else {
      throw new thrift24.Thrift.TProtocolException(thrift24.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[compressed_page_size] is unset!");
    }
    if (args != null && args.crc != null) {
      this.crc = args.crc;
    }
    if (args != null && args.data_page_header != null) {
      this.data_page_header = args.data_page_header;
    }
    if (args != null && args.index_page_header != null) {
      this.index_page_header = args.index_page_header;
    }
    if (args != null && args.dictionary_page_header != null) {
      this.dictionary_page_header = args.dictionary_page_header;
    }
    if (args != null && args.data_page_header_v2 != null) {
      this.data_page_header_v2 = args.data_page_header_v2;
    }
  }
  write(output) {
    output.writeStructBegin("PageHeader");
    if (this.type != null) {
      output.writeFieldBegin("type", thrift24.Thrift.Type.I32, 1);
      output.writeI32(this.type);
      output.writeFieldEnd();
    }
    if (this.uncompressed_page_size != null) {
      output.writeFieldBegin("uncompressed_page_size", thrift24.Thrift.Type.I32, 2);
      output.writeI32(this.uncompressed_page_size);
      output.writeFieldEnd();
    }
    if (this.compressed_page_size != null) {
      output.writeFieldBegin("compressed_page_size", thrift24.Thrift.Type.I32, 3);
      output.writeI32(this.compressed_page_size);
      output.writeFieldEnd();
    }
    if (this.crc != null) {
      output.writeFieldBegin("crc", thrift24.Thrift.Type.I32, 4);
      output.writeI32(this.crc);
      output.writeFieldEnd();
    }
    if (this.data_page_header != null) {
      output.writeFieldBegin("data_page_header", thrift24.Thrift.Type.STRUCT, 5);
      this.data_page_header.write(output);
      output.writeFieldEnd();
    }
    if (this.index_page_header != null) {
      output.writeFieldBegin("index_page_header", thrift24.Thrift.Type.STRUCT, 6);
      this.index_page_header.write(output);
      output.writeFieldEnd();
    }
    if (this.dictionary_page_header != null) {
      output.writeFieldBegin("dictionary_page_header", thrift24.Thrift.Type.STRUCT, 7);
      this.dictionary_page_header.write(output);
      output.writeFieldEnd();
    }
    if (this.data_page_header_v2 != null) {
      output.writeFieldBegin("data_page_header_v2", thrift24.Thrift.Type.STRUCT, 8);
      this.data_page_header_v2.write(output);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift24.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift24.Thrift.Type.I32) {
            const value_1 = input.readI32();
            _args.type = value_1;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift24.Thrift.Type.I32) {
            const value_2 = input.readI32();
            _args.uncompressed_page_size = value_2;
          } else {
            input.skip(fieldType);
          }
          break;
        case 3:
          if (fieldType === thrift24.Thrift.Type.I32) {
            const value_3 = input.readI32();
            _args.compressed_page_size = value_3;
          } else {
            input.skip(fieldType);
          }
          break;
        case 4:
          if (fieldType === thrift24.Thrift.Type.I32) {
            const value_4 = input.readI32();
            _args.crc = value_4;
          } else {
            input.skip(fieldType);
          }
          break;
        case 5:
          if (fieldType === thrift24.Thrift.Type.STRUCT) {
            const value_5 = DataPageHeader.read(input);
            _args.data_page_header = value_5;
          } else {
            input.skip(fieldType);
          }
          break;
        case 6:
          if (fieldType === thrift24.Thrift.Type.STRUCT) {
            const value_6 = IndexPageHeader.read(input);
            _args.index_page_header = value_6;
          } else {
            input.skip(fieldType);
          }
          break;
        case 7:
          if (fieldType === thrift24.Thrift.Type.STRUCT) {
            const value_7 = DictionaryPageHeader.read(input);
            _args.dictionary_page_header = value_7;
          } else {
            input.skip(fieldType);
          }
          break;
        case 8:
          if (fieldType === thrift24.Thrift.Type.STRUCT) {
            const value_8 = DataPageHeaderV2.read(input);
            _args.data_page_header_v2 = value_8;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.type !== void 0 && _args.uncompressed_page_size !== void 0 && _args.compressed_page_size !== void 0) {
      return new PageHeader(_args);
    } else {
      throw new thrift24.Thrift.TProtocolException(thrift24.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read PageHeader from input");
    }
  }
};

// dist/parquetjs/parquet-thrift/KeyValue.js
var thrift25 = __toESM(require("thrift"), 1);
var KeyValue = class {
  key;
  value;
  constructor(args) {
    if (args != null && args.key != null) {
      this.key = args.key;
    } else {
      throw new thrift25.Thrift.TProtocolException(thrift25.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[key] is unset!");
    }
    if (args != null && args.value != null) {
      this.value = args.value;
    }
  }
  write(output) {
    output.writeStructBegin("KeyValue");
    if (this.key != null) {
      output.writeFieldBegin("key", thrift25.Thrift.Type.STRING, 1);
      output.writeString(this.key);
      output.writeFieldEnd();
    }
    if (this.value != null) {
      output.writeFieldBegin("value", thrift25.Thrift.Type.STRING, 2);
      output.writeString(this.value);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift25.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift25.Thrift.Type.STRING) {
            const value_1 = input.readString();
            _args.key = value_1;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift25.Thrift.Type.STRING) {
            const value_2 = input.readString();
            _args.value = value_2;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.key !== void 0) {
      return new KeyValue(_args);
    } else {
      throw new thrift25.Thrift.TProtocolException(thrift25.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read KeyValue from input");
    }
  }
};

// dist/parquetjs/parquet-thrift/SortingColumn.js
var thrift26 = __toESM(require("thrift"), 1);
var SortingColumn = class {
  column_idx;
  descending;
  nulls_first;
  constructor(args) {
    if (args != null && args.column_idx != null) {
      this.column_idx = args.column_idx;
    } else {
      throw new thrift26.Thrift.TProtocolException(thrift26.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[column_idx] is unset!");
    }
    if (args != null && args.descending != null) {
      this.descending = args.descending;
    } else {
      throw new thrift26.Thrift.TProtocolException(thrift26.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[descending] is unset!");
    }
    if (args != null && args.nulls_first != null) {
      this.nulls_first = args.nulls_first;
    } else {
      throw new thrift26.Thrift.TProtocolException(thrift26.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[nulls_first] is unset!");
    }
  }
  write(output) {
    output.writeStructBegin("SortingColumn");
    if (this.column_idx != null) {
      output.writeFieldBegin("column_idx", thrift26.Thrift.Type.I32, 1);
      output.writeI32(this.column_idx);
      output.writeFieldEnd();
    }
    if (this.descending != null) {
      output.writeFieldBegin("descending", thrift26.Thrift.Type.BOOL, 2);
      output.writeBool(this.descending);
      output.writeFieldEnd();
    }
    if (this.nulls_first != null) {
      output.writeFieldBegin("nulls_first", thrift26.Thrift.Type.BOOL, 3);
      output.writeBool(this.nulls_first);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift26.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift26.Thrift.Type.I32) {
            const value_1 = input.readI32();
            _args.column_idx = value_1;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift26.Thrift.Type.BOOL) {
            const value_2 = input.readBool();
            _args.descending = value_2;
          } else {
            input.skip(fieldType);
          }
          break;
        case 3:
          if (fieldType === thrift26.Thrift.Type.BOOL) {
            const value_3 = input.readBool();
            _args.nulls_first = value_3;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.column_idx !== void 0 && _args.descending !== void 0 && _args.nulls_first !== void 0) {
      return new SortingColumn(_args);
    } else {
      throw new thrift26.Thrift.TProtocolException(thrift26.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read SortingColumn from input");
    }
  }
};

// dist/parquetjs/parquet-thrift/PageEncodingStats.js
var thrift27 = __toESM(require("thrift"), 1);
var PageEncodingStats = class {
  page_type;
  encoding;
  count;
  constructor(args) {
    if (args != null && args.page_type != null) {
      this.page_type = args.page_type;
    } else {
      throw new thrift27.Thrift.TProtocolException(thrift27.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[page_type] is unset!");
    }
    if (args != null && args.encoding != null) {
      this.encoding = args.encoding;
    } else {
      throw new thrift27.Thrift.TProtocolException(thrift27.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[encoding] is unset!");
    }
    if (args != null && args.count != null) {
      this.count = args.count;
    } else {
      throw new thrift27.Thrift.TProtocolException(thrift27.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[count] is unset!");
    }
  }
  write(output) {
    output.writeStructBegin("PageEncodingStats");
    if (this.page_type != null) {
      output.writeFieldBegin("page_type", thrift27.Thrift.Type.I32, 1);
      output.writeI32(this.page_type);
      output.writeFieldEnd();
    }
    if (this.encoding != null) {
      output.writeFieldBegin("encoding", thrift27.Thrift.Type.I32, 2);
      output.writeI32(this.encoding);
      output.writeFieldEnd();
    }
    if (this.count != null) {
      output.writeFieldBegin("count", thrift27.Thrift.Type.I32, 3);
      output.writeI32(this.count);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift27.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift27.Thrift.Type.I32) {
            const value_1 = input.readI32();
            _args.page_type = value_1;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift27.Thrift.Type.I32) {
            const value_2 = input.readI32();
            _args.encoding = value_2;
          } else {
            input.skip(fieldType);
          }
          break;
        case 3:
          if (fieldType === thrift27.Thrift.Type.I32) {
            const value_3 = input.readI32();
            _args.count = value_3;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.page_type !== void 0 && _args.encoding !== void 0 && _args.count !== void 0) {
      return new PageEncodingStats(_args);
    } else {
      throw new thrift27.Thrift.TProtocolException(thrift27.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read PageEncodingStats from input");
    }
  }
};

// dist/parquetjs/parquet-thrift/ColumnMetaData.js
var import_node_int642 = __toESM(require("node-int64"), 1);
var thrift28 = __toESM(require("thrift"), 1);
var ColumnMetaData = class {
  type;
  encodings;
  path_in_schema;
  codec;
  num_values;
  total_uncompressed_size;
  total_compressed_size;
  key_value_metadata;
  data_page_offset;
  index_page_offset;
  dictionary_page_offset;
  statistics;
  encoding_stats;
  constructor(args) {
    if (args != null && args.type != null) {
      this.type = args.type;
    } else {
      throw new thrift28.Thrift.TProtocolException(thrift28.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[type] is unset!");
    }
    if (args != null && args.encodings != null) {
      this.encodings = args.encodings;
    } else {
      throw new thrift28.Thrift.TProtocolException(thrift28.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[encodings] is unset!");
    }
    if (args != null && args.path_in_schema != null) {
      this.path_in_schema = args.path_in_schema;
    } else {
      throw new thrift28.Thrift.TProtocolException(thrift28.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[path_in_schema] is unset!");
    }
    if (args != null && args.codec != null) {
      this.codec = args.codec;
    } else {
      throw new thrift28.Thrift.TProtocolException(thrift28.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[codec] is unset!");
    }
    if (args != null && args.num_values != null) {
      if (typeof args.num_values === "number") {
        this.num_values = new import_node_int642.default(args.num_values);
      } else {
        this.num_values = args.num_values;
      }
    } else {
      throw new thrift28.Thrift.TProtocolException(thrift28.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[num_values] is unset!");
    }
    if (args != null && args.total_uncompressed_size != null) {
      if (typeof args.total_uncompressed_size === "number") {
        this.total_uncompressed_size = new import_node_int642.default(args.total_uncompressed_size);
      } else {
        this.total_uncompressed_size = args.total_uncompressed_size;
      }
    } else {
      throw new thrift28.Thrift.TProtocolException(thrift28.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[total_uncompressed_size] is unset!");
    }
    if (args != null && args.total_compressed_size != null) {
      if (typeof args.total_compressed_size === "number") {
        this.total_compressed_size = new import_node_int642.default(args.total_compressed_size);
      } else {
        this.total_compressed_size = args.total_compressed_size;
      }
    } else {
      throw new thrift28.Thrift.TProtocolException(thrift28.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[total_compressed_size] is unset!");
    }
    if (args != null && args.key_value_metadata != null) {
      this.key_value_metadata = args.key_value_metadata;
    }
    if (args != null && args.data_page_offset != null) {
      if (typeof args.data_page_offset === "number") {
        this.data_page_offset = new import_node_int642.default(args.data_page_offset);
      } else {
        this.data_page_offset = args.data_page_offset;
      }
    } else {
      throw new thrift28.Thrift.TProtocolException(thrift28.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[data_page_offset] is unset!");
    }
    if (args != null && args.index_page_offset != null) {
      if (typeof args.index_page_offset === "number") {
        this.index_page_offset = new import_node_int642.default(args.index_page_offset);
      } else {
        this.index_page_offset = args.index_page_offset;
      }
    }
    if (args != null && args.dictionary_page_offset != null) {
      if (typeof args.dictionary_page_offset === "number") {
        this.dictionary_page_offset = new import_node_int642.default(args.dictionary_page_offset);
      } else {
        this.dictionary_page_offset = args.dictionary_page_offset;
      }
    }
    if (args != null && args.statistics != null) {
      this.statistics = args.statistics;
    }
    if (args != null && args.encoding_stats != null) {
      this.encoding_stats = args.encoding_stats;
    }
  }
  write(output) {
    output.writeStructBegin("ColumnMetaData");
    if (this.type != null) {
      output.writeFieldBegin("type", thrift28.Thrift.Type.I32, 1);
      output.writeI32(this.type);
      output.writeFieldEnd();
    }
    if (this.encodings != null) {
      output.writeFieldBegin("encodings", thrift28.Thrift.Type.LIST, 2);
      output.writeListBegin(thrift28.Thrift.Type.I32, this.encodings.length);
      this.encodings.forEach((value_1) => {
        output.writeI32(value_1);
      });
      output.writeListEnd();
      output.writeFieldEnd();
    }
    if (this.path_in_schema != null) {
      output.writeFieldBegin("path_in_schema", thrift28.Thrift.Type.LIST, 3);
      output.writeListBegin(thrift28.Thrift.Type.STRING, this.path_in_schema.length);
      this.path_in_schema.forEach((value_2) => {
        output.writeString(value_2);
      });
      output.writeListEnd();
      output.writeFieldEnd();
    }
    if (this.codec != null) {
      output.writeFieldBegin("codec", thrift28.Thrift.Type.I32, 4);
      output.writeI32(this.codec);
      output.writeFieldEnd();
    }
    if (this.num_values != null) {
      output.writeFieldBegin("num_values", thrift28.Thrift.Type.I64, 5);
      output.writeI64(this.num_values);
      output.writeFieldEnd();
    }
    if (this.total_uncompressed_size != null) {
      output.writeFieldBegin("total_uncompressed_size", thrift28.Thrift.Type.I64, 6);
      output.writeI64(this.total_uncompressed_size);
      output.writeFieldEnd();
    }
    if (this.total_compressed_size != null) {
      output.writeFieldBegin("total_compressed_size", thrift28.Thrift.Type.I64, 7);
      output.writeI64(this.total_compressed_size);
      output.writeFieldEnd();
    }
    if (this.key_value_metadata != null) {
      output.writeFieldBegin("key_value_metadata", thrift28.Thrift.Type.LIST, 8);
      output.writeListBegin(thrift28.Thrift.Type.STRUCT, this.key_value_metadata.length);
      this.key_value_metadata.forEach((value_3) => {
        value_3.write(output);
      });
      output.writeListEnd();
      output.writeFieldEnd();
    }
    if (this.data_page_offset != null) {
      output.writeFieldBegin("data_page_offset", thrift28.Thrift.Type.I64, 9);
      output.writeI64(this.data_page_offset);
      output.writeFieldEnd();
    }
    if (this.index_page_offset != null) {
      output.writeFieldBegin("index_page_offset", thrift28.Thrift.Type.I64, 10);
      output.writeI64(this.index_page_offset);
      output.writeFieldEnd();
    }
    if (this.dictionary_page_offset != null) {
      output.writeFieldBegin("dictionary_page_offset", thrift28.Thrift.Type.I64, 11);
      output.writeI64(this.dictionary_page_offset);
      output.writeFieldEnd();
    }
    if (this.statistics != null) {
      output.writeFieldBegin("statistics", thrift28.Thrift.Type.STRUCT, 12);
      this.statistics.write(output);
      output.writeFieldEnd();
    }
    if (this.encoding_stats != null) {
      output.writeFieldBegin("encoding_stats", thrift28.Thrift.Type.LIST, 13);
      output.writeListBegin(thrift28.Thrift.Type.STRUCT, this.encoding_stats.length);
      this.encoding_stats.forEach((value_4) => {
        value_4.write(output);
      });
      output.writeListEnd();
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift28.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift28.Thrift.Type.I32) {
            const value_5 = input.readI32();
            _args.type = value_5;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift28.Thrift.Type.LIST) {
            const value_6 = new Array();
            const metadata_1 = input.readListBegin();
            const size_1 = metadata_1.size;
            for (let i_1 = 0; i_1 < size_1; i_1++) {
              const value_7 = input.readI32();
              value_6.push(value_7);
            }
            input.readListEnd();
            _args.encodings = value_6;
          } else {
            input.skip(fieldType);
          }
          break;
        case 3:
          if (fieldType === thrift28.Thrift.Type.LIST) {
            const value_8 = new Array();
            const metadata_2 = input.readListBegin();
            const size_2 = metadata_2.size;
            for (let i_2 = 0; i_2 < size_2; i_2++) {
              const value_9 = input.readString();
              value_8.push(value_9);
            }
            input.readListEnd();
            _args.path_in_schema = value_8;
          } else {
            input.skip(fieldType);
          }
          break;
        case 4:
          if (fieldType === thrift28.Thrift.Type.I32) {
            const value_10 = input.readI32();
            _args.codec = value_10;
          } else {
            input.skip(fieldType);
          }
          break;
        case 5:
          if (fieldType === thrift28.Thrift.Type.I64) {
            const value_11 = input.readI64();
            _args.num_values = value_11;
          } else {
            input.skip(fieldType);
          }
          break;
        case 6:
          if (fieldType === thrift28.Thrift.Type.I64) {
            const value_12 = input.readI64();
            _args.total_uncompressed_size = value_12;
          } else {
            input.skip(fieldType);
          }
          break;
        case 7:
          if (fieldType === thrift28.Thrift.Type.I64) {
            const value_13 = input.readI64();
            _args.total_compressed_size = value_13;
          } else {
            input.skip(fieldType);
          }
          break;
        case 8:
          if (fieldType === thrift28.Thrift.Type.LIST) {
            const value_14 = new Array();
            const metadata_3 = input.readListBegin();
            const size_3 = metadata_3.size;
            for (let i_3 = 0; i_3 < size_3; i_3++) {
              const value_15 = KeyValue.read(input);
              value_14.push(value_15);
            }
            input.readListEnd();
            _args.key_value_metadata = value_14;
          } else {
            input.skip(fieldType);
          }
          break;
        case 9:
          if (fieldType === thrift28.Thrift.Type.I64) {
            const value_16 = input.readI64();
            _args.data_page_offset = value_16;
          } else {
            input.skip(fieldType);
          }
          break;
        case 10:
          if (fieldType === thrift28.Thrift.Type.I64) {
            const value_17 = input.readI64();
            _args.index_page_offset = value_17;
          } else {
            input.skip(fieldType);
          }
          break;
        case 11:
          if (fieldType === thrift28.Thrift.Type.I64) {
            const value_18 = input.readI64();
            _args.dictionary_page_offset = value_18;
          } else {
            input.skip(fieldType);
          }
          break;
        case 12:
          if (fieldType === thrift28.Thrift.Type.STRUCT) {
            const value_19 = Statistics.read(input);
            _args.statistics = value_19;
          } else {
            input.skip(fieldType);
          }
          break;
        case 13:
          if (fieldType === thrift28.Thrift.Type.LIST) {
            const value_20 = new Array();
            const metadata_4 = input.readListBegin();
            const size_4 = metadata_4.size;
            for (let i_4 = 0; i_4 < size_4; i_4++) {
              const value_21 = PageEncodingStats.read(input);
              value_20.push(value_21);
            }
            input.readListEnd();
            _args.encoding_stats = value_20;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.type !== void 0 && _args.encodings !== void 0 && _args.path_in_schema !== void 0 && _args.codec !== void 0 && _args.num_values !== void 0 && _args.total_uncompressed_size !== void 0 && _args.total_compressed_size !== void 0 && _args.data_page_offset !== void 0) {
      return new ColumnMetaData(_args);
    } else {
      throw new thrift28.Thrift.TProtocolException(thrift28.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read ColumnMetaData from input");
    }
  }
};

// dist/parquetjs/parquet-thrift/ColumnChunk.js
var import_node_int643 = __toESM(require("node-int64"), 1);
var thrift29 = __toESM(require("thrift"), 1);
var ColumnChunk = class {
  file_path;
  file_offset;
  meta_data;
  offset_index_offset;
  offset_index_length;
  column_index_offset;
  column_index_length;
  constructor(args) {
    if (args != null && args.file_path != null) {
      this.file_path = args.file_path;
    }
    if (args != null && args.file_offset != null) {
      if (typeof args.file_offset === "number") {
        this.file_offset = new import_node_int643.default(args.file_offset);
      } else {
        this.file_offset = args.file_offset;
      }
    } else {
      throw new thrift29.Thrift.TProtocolException(thrift29.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[file_offset] is unset!");
    }
    if (args != null && args.meta_data != null) {
      this.meta_data = args.meta_data;
    }
    if (args != null && args.offset_index_offset != null) {
      if (typeof args.offset_index_offset === "number") {
        this.offset_index_offset = new import_node_int643.default(args.offset_index_offset);
      } else {
        this.offset_index_offset = args.offset_index_offset;
      }
    }
    if (args != null && args.offset_index_length != null) {
      this.offset_index_length = args.offset_index_length;
    }
    if (args != null && args.column_index_offset != null) {
      if (typeof args.column_index_offset === "number") {
        this.column_index_offset = new import_node_int643.default(args.column_index_offset);
      } else {
        this.column_index_offset = args.column_index_offset;
      }
    }
    if (args != null && args.column_index_length != null) {
      this.column_index_length = args.column_index_length;
    }
  }
  write(output) {
    output.writeStructBegin("ColumnChunk");
    if (this.file_path != null) {
      output.writeFieldBegin("file_path", thrift29.Thrift.Type.STRING, 1);
      output.writeString(this.file_path);
      output.writeFieldEnd();
    }
    if (this.file_offset != null) {
      output.writeFieldBegin("file_offset", thrift29.Thrift.Type.I64, 2);
      output.writeI64(this.file_offset);
      output.writeFieldEnd();
    }
    if (this.meta_data != null) {
      output.writeFieldBegin("meta_data", thrift29.Thrift.Type.STRUCT, 3);
      this.meta_data.write(output);
      output.writeFieldEnd();
    }
    if (this.offset_index_offset != null) {
      output.writeFieldBegin("offset_index_offset", thrift29.Thrift.Type.I64, 4);
      output.writeI64(this.offset_index_offset);
      output.writeFieldEnd();
    }
    if (this.offset_index_length != null) {
      output.writeFieldBegin("offset_index_length", thrift29.Thrift.Type.I32, 5);
      output.writeI32(this.offset_index_length);
      output.writeFieldEnd();
    }
    if (this.column_index_offset != null) {
      output.writeFieldBegin("column_index_offset", thrift29.Thrift.Type.I64, 6);
      output.writeI64(this.column_index_offset);
      output.writeFieldEnd();
    }
    if (this.column_index_length != null) {
      output.writeFieldBegin("column_index_length", thrift29.Thrift.Type.I32, 7);
      output.writeI32(this.column_index_length);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift29.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift29.Thrift.Type.STRING) {
            const value_1 = input.readString();
            _args.file_path = value_1;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift29.Thrift.Type.I64) {
            const value_2 = input.readI64();
            _args.file_offset = value_2;
          } else {
            input.skip(fieldType);
          }
          break;
        case 3:
          if (fieldType === thrift29.Thrift.Type.STRUCT) {
            const value_3 = ColumnMetaData.read(input);
            _args.meta_data = value_3;
          } else {
            input.skip(fieldType);
          }
          break;
        case 4:
          if (fieldType === thrift29.Thrift.Type.I64) {
            const value_4 = input.readI64();
            _args.offset_index_offset = value_4;
          } else {
            input.skip(fieldType);
          }
          break;
        case 5:
          if (fieldType === thrift29.Thrift.Type.I32) {
            const value_5 = input.readI32();
            _args.offset_index_length = value_5;
          } else {
            input.skip(fieldType);
          }
          break;
        case 6:
          if (fieldType === thrift29.Thrift.Type.I64) {
            const value_6 = input.readI64();
            _args.column_index_offset = value_6;
          } else {
            input.skip(fieldType);
          }
          break;
        case 7:
          if (fieldType === thrift29.Thrift.Type.I32) {
            const value_7 = input.readI32();
            _args.column_index_length = value_7;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.file_offset !== void 0) {
      return new ColumnChunk(_args);
    } else {
      throw new thrift29.Thrift.TProtocolException(thrift29.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read ColumnChunk from input");
    }
  }
};

// dist/parquetjs/parquet-thrift/RowGroup.js
var import_node_int644 = __toESM(require("node-int64"), 1);
var thrift30 = __toESM(require("thrift"), 1);
var RowGroup = class {
  columns;
  total_byte_size;
  num_rows;
  sorting_columns;
  constructor(args) {
    if (args != null && args.columns != null) {
      this.columns = args.columns;
    } else {
      throw new thrift30.Thrift.TProtocolException(thrift30.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[columns] is unset!");
    }
    if (args != null && args.total_byte_size != null) {
      if (typeof args.total_byte_size === "number") {
        this.total_byte_size = new import_node_int644.default(args.total_byte_size);
      } else {
        this.total_byte_size = args.total_byte_size;
      }
    } else {
      throw new thrift30.Thrift.TProtocolException(thrift30.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[total_byte_size] is unset!");
    }
    if (args != null && args.num_rows != null) {
      if (typeof args.num_rows === "number") {
        this.num_rows = new import_node_int644.default(args.num_rows);
      } else {
        this.num_rows = args.num_rows;
      }
    } else {
      throw new thrift30.Thrift.TProtocolException(thrift30.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[num_rows] is unset!");
    }
    if (args != null && args.sorting_columns != null) {
      this.sorting_columns = args.sorting_columns;
    }
  }
  write(output) {
    output.writeStructBegin("RowGroup");
    if (this.columns != null) {
      output.writeFieldBegin("columns", thrift30.Thrift.Type.LIST, 1);
      output.writeListBegin(thrift30.Thrift.Type.STRUCT, this.columns.length);
      this.columns.forEach((value_1) => {
        value_1.write(output);
      });
      output.writeListEnd();
      output.writeFieldEnd();
    }
    if (this.total_byte_size != null) {
      output.writeFieldBegin("total_byte_size", thrift30.Thrift.Type.I64, 2);
      output.writeI64(this.total_byte_size);
      output.writeFieldEnd();
    }
    if (this.num_rows != null) {
      output.writeFieldBegin("num_rows", thrift30.Thrift.Type.I64, 3);
      output.writeI64(this.num_rows);
      output.writeFieldEnd();
    }
    if (this.sorting_columns != null) {
      output.writeFieldBegin("sorting_columns", thrift30.Thrift.Type.LIST, 4);
      output.writeListBegin(thrift30.Thrift.Type.STRUCT, this.sorting_columns.length);
      this.sorting_columns.forEach((value_2) => {
        value_2.write(output);
      });
      output.writeListEnd();
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift30.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift30.Thrift.Type.LIST) {
            const value_3 = new Array();
            const metadata_1 = input.readListBegin();
            const size_1 = metadata_1.size;
            for (let i_1 = 0; i_1 < size_1; i_1++) {
              const value_4 = ColumnChunk.read(input);
              value_3.push(value_4);
            }
            input.readListEnd();
            _args.columns = value_3;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift30.Thrift.Type.I64) {
            const value_5 = input.readI64();
            _args.total_byte_size = value_5;
          } else {
            input.skip(fieldType);
          }
          break;
        case 3:
          if (fieldType === thrift30.Thrift.Type.I64) {
            const value_6 = input.readI64();
            _args.num_rows = value_6;
          } else {
            input.skip(fieldType);
          }
          break;
        case 4:
          if (fieldType === thrift30.Thrift.Type.LIST) {
            const value_7 = new Array();
            const metadata_2 = input.readListBegin();
            const size_2 = metadata_2.size;
            for (let i_2 = 0; i_2 < size_2; i_2++) {
              const value_8 = SortingColumn.read(input);
              value_7.push(value_8);
            }
            input.readListEnd();
            _args.sorting_columns = value_7;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.columns !== void 0 && _args.total_byte_size !== void 0 && _args.num_rows !== void 0) {
      return new RowGroup(_args);
    } else {
      throw new thrift30.Thrift.TProtocolException(thrift30.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read RowGroup from input");
    }
  }
};

// dist/parquetjs/parquet-thrift/TypeDefinedOrder.js
var thrift31 = __toESM(require("thrift"), 1);
var TypeDefinedOrder = class {
  constructor() {
  }
  write(output) {
    output.writeStructBegin("TypeDefinedOrder");
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift31.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    return new TypeDefinedOrder();
  }
};

// dist/parquetjs/parquet-thrift/FileMetaData.js
var import_node_int645 = __toESM(require("node-int64"), 1);
var thrift33 = __toESM(require("thrift"), 1);

// dist/parquetjs/parquet-thrift/ColumnOrder.js
var thrift32 = __toESM(require("thrift"), 1);
var ColumnOrder = class {
  TYPE_ORDER;
  constructor(args) {
    let _fieldsSet = 0;
    if (args != null) {
      if (args.TYPE_ORDER != null) {
        _fieldsSet++;
        this.TYPE_ORDER = args.TYPE_ORDER;
      }
      if (_fieldsSet > 1) {
        throw new thrift32.Thrift.TProtocolException(thrift32.Thrift.TProtocolExceptionType.INVALID_DATA, "Cannot read a TUnion with more than one set value!");
      } else if (_fieldsSet < 1) {
        throw new thrift32.Thrift.TProtocolException(thrift32.Thrift.TProtocolExceptionType.INVALID_DATA, "Cannot read a TUnion with no set value!");
      }
    }
  }
  static fromTYPE_ORDER(TYPE_ORDER) {
    return new ColumnOrder({ TYPE_ORDER });
  }
  write(output) {
    output.writeStructBegin("ColumnOrder");
    if (this.TYPE_ORDER != null) {
      output.writeFieldBegin("TYPE_ORDER", thrift32.Thrift.Type.STRUCT, 1);
      this.TYPE_ORDER.write(output);
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    let _fieldsSet = 0;
    let _returnValue = null;
    input.readStructBegin();
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift32.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift32.Thrift.Type.STRUCT) {
            _fieldsSet++;
            const value_1 = TypeDefinedOrder.read(input);
            _returnValue = ColumnOrder.fromTYPE_ORDER(value_1);
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_fieldsSet > 1) {
      throw new thrift32.Thrift.TProtocolException(thrift32.Thrift.TProtocolExceptionType.INVALID_DATA, "Cannot read a TUnion with more than one set value!");
    } else if (_fieldsSet < 1) {
      throw new thrift32.Thrift.TProtocolException(thrift32.Thrift.TProtocolExceptionType.INVALID_DATA, "Cannot read a TUnion with no set value!");
    }
    if (_returnValue !== null) {
      return _returnValue;
    } else {
      throw new thrift32.Thrift.TProtocolException(thrift32.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read data for TUnion");
    }
  }
};

// dist/parquetjs/parquet-thrift/FileMetaData.js
var FileMetaData = class {
  version;
  schema;
  num_rows;
  row_groups;
  key_value_metadata;
  created_by;
  column_orders;
  constructor(args = null) {
    if (args != null && args.version != null) {
      this.version = args.version;
    } else {
      throw new thrift33.Thrift.TProtocolException(thrift33.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[version] is unset!");
    }
    if (args != null && args.schema != null) {
      this.schema = args.schema;
    } else {
      throw new thrift33.Thrift.TProtocolException(thrift33.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[schema] is unset!");
    }
    if (args != null && args.num_rows != null) {
      if (typeof args.num_rows === "number") {
        this.num_rows = new import_node_int645.default(args.num_rows);
      } else {
        this.num_rows = args.num_rows;
      }
    } else {
      throw new thrift33.Thrift.TProtocolException(thrift33.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[num_rows] is unset!");
    }
    if (args != null && args.row_groups != null) {
      this.row_groups = args.row_groups;
    } else {
      throw new thrift33.Thrift.TProtocolException(thrift33.Thrift.TProtocolExceptionType.UNKNOWN, "Required field[row_groups] is unset!");
    }
    if (args != null && args.key_value_metadata != null) {
      this.key_value_metadata = args.key_value_metadata;
    }
    if (args != null && args.created_by != null) {
      this.created_by = args.created_by;
    }
    if (args != null && args.column_orders != null) {
      this.column_orders = args.column_orders;
    }
  }
  write(output) {
    output.writeStructBegin("FileMetaData");
    if (this.version != null) {
      output.writeFieldBegin("version", thrift33.Thrift.Type.I32, 1);
      output.writeI32(this.version);
      output.writeFieldEnd();
    }
    if (this.schema != null) {
      output.writeFieldBegin("schema", thrift33.Thrift.Type.LIST, 2);
      output.writeListBegin(thrift33.Thrift.Type.STRUCT, this.schema.length);
      this.schema.forEach((value_1) => {
        value_1.write(output);
      });
      output.writeListEnd();
      output.writeFieldEnd();
    }
    if (this.num_rows != null) {
      output.writeFieldBegin("num_rows", thrift33.Thrift.Type.I64, 3);
      output.writeI64(this.num_rows);
      output.writeFieldEnd();
    }
    if (this.row_groups != null) {
      output.writeFieldBegin("row_groups", thrift33.Thrift.Type.LIST, 4);
      output.writeListBegin(thrift33.Thrift.Type.STRUCT, this.row_groups.length);
      this.row_groups.forEach((value_2) => {
        value_2.write(output);
      });
      output.writeListEnd();
      output.writeFieldEnd();
    }
    if (this.key_value_metadata != null) {
      output.writeFieldBegin("key_value_metadata", thrift33.Thrift.Type.LIST, 5);
      output.writeListBegin(thrift33.Thrift.Type.STRUCT, this.key_value_metadata.length);
      this.key_value_metadata.forEach((value_3) => {
        value_3.write(output);
      });
      output.writeListEnd();
      output.writeFieldEnd();
    }
    if (this.created_by != null) {
      output.writeFieldBegin("created_by", thrift33.Thrift.Type.STRING, 6);
      output.writeString(this.created_by);
      output.writeFieldEnd();
    }
    if (this.column_orders != null) {
      output.writeFieldBegin("column_orders", thrift33.Thrift.Type.LIST, 7);
      output.writeListBegin(thrift33.Thrift.Type.STRUCT, this.column_orders.length);
      this.column_orders.forEach((value_4) => {
        value_4.write(output);
      });
      output.writeListEnd();
      output.writeFieldEnd();
    }
    output.writeFieldStop();
    output.writeStructEnd();
    return;
  }
  static read(input) {
    input.readStructBegin();
    let _args = {};
    while (true) {
      const ret = input.readFieldBegin();
      const fieldType = ret.ftype;
      const fieldId = ret.fid;
      if (fieldType === thrift33.Thrift.Type.STOP) {
        break;
      }
      switch (fieldId) {
        case 1:
          if (fieldType === thrift33.Thrift.Type.I32) {
            const value_5 = input.readI32();
            _args.version = value_5;
          } else {
            input.skip(fieldType);
          }
          break;
        case 2:
          if (fieldType === thrift33.Thrift.Type.LIST) {
            const value_6 = new Array();
            const metadata_1 = input.readListBegin();
            const size_1 = metadata_1.size;
            for (let i_1 = 0; i_1 < size_1; i_1++) {
              const value_7 = SchemaElement.read(input);
              value_6.push(value_7);
            }
            input.readListEnd();
            _args.schema = value_6;
          } else {
            input.skip(fieldType);
          }
          break;
        case 3:
          if (fieldType === thrift33.Thrift.Type.I64) {
            const value_8 = input.readI64();
            _args.num_rows = value_8;
          } else {
            input.skip(fieldType);
          }
          break;
        case 4:
          if (fieldType === thrift33.Thrift.Type.LIST) {
            const value_9 = new Array();
            const metadata_2 = input.readListBegin();
            const size_2 = metadata_2.size;
            for (let i_2 = 0; i_2 < size_2; i_2++) {
              const value_10 = RowGroup.read(input);
              value_9.push(value_10);
            }
            input.readListEnd();
            _args.row_groups = value_9;
          } else {
            input.skip(fieldType);
          }
          break;
        case 5:
          if (fieldType === thrift33.Thrift.Type.LIST) {
            const value_11 = new Array();
            const metadata_3 = input.readListBegin();
            const size_3 = metadata_3.size;
            for (let i_3 = 0; i_3 < size_3; i_3++) {
              const value_12 = KeyValue.read(input);
              value_11.push(value_12);
            }
            input.readListEnd();
            _args.key_value_metadata = value_11;
          } else {
            input.skip(fieldType);
          }
          break;
        case 6:
          if (fieldType === thrift33.Thrift.Type.STRING) {
            const value_13 = input.readString();
            _args.created_by = value_13;
          } else {
            input.skip(fieldType);
          }
          break;
        case 7:
          if (fieldType === thrift33.Thrift.Type.LIST) {
            const value_14 = new Array();
            const metadata_4 = input.readListBegin();
            const size_4 = metadata_4.size;
            for (let i_4 = 0; i_4 < size_4; i_4++) {
              const value_15 = ColumnOrder.read(input);
              value_14.push(value_15);
            }
            input.readListEnd();
            _args.column_orders = value_14;
          } else {
            input.skip(fieldType);
          }
          break;
        default: {
          input.skip(fieldType);
        }
      }
      input.readFieldEnd();
    }
    input.readStructEnd();
    if (_args.version !== void 0 && _args.schema !== void 0 && _args.num_rows !== void 0 && _args.row_groups !== void 0) {
      return new FileMetaData(_args);
    } else {
      throw new thrift33.Thrift.TProtocolException(thrift33.Thrift.TProtocolExceptionType.UNKNOWN, "Unable to read FileMetaData from input");
    }
  }
};

// dist/lib/constants.js
var VERSION = true ? "4.3.3" : "latest";
var PARQUET_WASM_URL = "https://unpkg.com/parquet-wasm@0.6.1/esm/parquet_wasm_bg.wasm";
var PARQUET_MAGIC = "PAR1";
var PARQUET_MAGIC_ENCRYPTED = "PARE";
var PARQUET_RDLVL_TYPE = "INT32";
var PARQUET_RDLVL_ENCODING = "RLE";

// dist/parquetjs/utils/read-utils.js
var UFramedTransport = class extends import_thrift.TFramedTransport {
  readPos = 0;
};
function serializeThrift(obj) {
  const output = [];
  const transport = new import_thrift.TBufferedTransport(void 0, (buf) => {
    output.push(buf);
  });
  const protocol = new import_thrift.TCompactProtocol(transport);
  obj.write(protocol);
  transport.flush();
  return Buffer.concat(output);
}
function getThriftEnum(klass, value) {
  for (const k in klass) {
    if (klass[k] === value) {
      return k;
    }
  }
  throw new Error("Invalid ENUM value");
}
function decodeFileMetadata(buf, offset) {
  if (!offset) {
    offset = 0;
  }
  const transport = new UFramedTransport(buf);
  transport.readPos = offset;
  const protocol = new import_thrift.TCompactProtocol(transport);
  const metadata = FileMetaData.read(protocol);
  return { length: transport.readPos - offset, metadata };
}
function decodePageHeader(buf, offset) {
  if (!offset) {
    offset = 0;
  }
  const transport = new UFramedTransport(buf);
  transport.readPos = offset;
  const protocol = new import_thrift.TCompactProtocol(transport);
  const pageHeader = PageHeader.read(protocol);
  return { length: transport.readPos - offset, pageHeader };
}
function getBitWidth(val) {
  if (val === 0) {
    return 0;
  }
  return Math.ceil(Math.log2(val + 1));
}
function fieldIndexOf(arr, elem) {
  for (let j = 0; j < arr.length; j++) {
    if (arr[j].length > elem.length) {
      continue;
    }
    let m = true;
    for (let i = 0; i < elem.length; i++) {
      if (arr[j][i] === elem[i] || arr[j][i] === "+" || arr[j][i] === "#") {
        continue;
      }
      if (i >= arr[j].length && arr[j][arr[j].length - 1] === "#") {
        continue;
      }
      m = false;
      break;
    }
    if (m)
      return j;
  }
  return -1;
}

// dist/parquetjs/parser/decoders.js
async function decodeDataPages(buffer, context) {
  var _a;
  const cursor = {
    buffer,
    offset: 0,
    size: buffer.length
  };
  const data = {
    rlevels: [],
    dlevels: [],
    values: [],
    pageHeaders: [],
    count: 0
  };
  let dictionary = context.dictionary || [];
  while (
    // @ts-ignore size can be undefined
    cursor.offset < cursor.size && (!context.numValues || data.dlevels.length < Number(context.numValues))
  ) {
    const page = await decodePage(cursor, context);
    if (page.dictionary) {
      dictionary = page.dictionary;
      continue;
    }
    const valueEncoding = getThriftEnum(Encoding, (_a = page.pageHeader.data_page_header) == null ? void 0 : _a.encoding);
    if (dictionary.length && valueEncoding !== "PLAIN") {
      page.values = page.values.map((value) => dictionary[value]);
    }
    for (let index = 0; index < page.rlevels.length; index++) {
      data.rlevels.push(page.rlevels[index]);
      data.dlevels.push(page.dlevels[index]);
      const value = page.values[index];
      if (value !== void 0) {
        data.values.push(value);
      }
    }
    data.count += page.count;
    data.pageHeaders.push(page.pageHeader);
  }
  return data;
}
async function decodePage(cursor, context) {
  let page;
  const { pageHeader, length } = decodePageHeader(cursor.buffer, cursor.offset);
  cursor.offset += length;
  const pageType = getThriftEnum(PageType, pageHeader.type);
  switch (pageType) {
    case "DATA_PAGE":
      page = await decodeDataPage(cursor, pageHeader, context);
      break;
    case "DATA_PAGE_V2":
      page = await decodeDataPageV2(cursor, pageHeader, context);
      break;
    case "DICTIONARY_PAGE":
      page = {
        dictionary: await decodeDictionaryPage(cursor, pageHeader, context),
        pageHeader
      };
      break;
    default:
      throw new Error(`invalid page type: ${pageType}`);
  }
  return page;
}
function decodeSchema(schemaElements, offset, len) {
  const schema = {};
  let next = offset;
  for (let i = 0; i < len; i++) {
    const schemaElement = schemaElements[next];
    const repetitionType = next > 0 ? getThriftEnum(FieldRepetitionType, schemaElement.repetition_type) : "ROOT";
    let optional = false;
    let repeated = false;
    switch (repetitionType) {
      case "REQUIRED":
        break;
      case "OPTIONAL":
        optional = true;
        break;
      case "REPEATED":
        repeated = true;
        break;
      default:
        throw new Error("parquet: unknown repetition type");
    }
    if (schemaElement.num_children > 0) {
      const res = decodeSchema(schemaElements, next + 1, schemaElement.num_children);
      next = res.next;
      schema[schemaElement.name] = {
        // type: undefined,
        optional,
        repeated,
        fields: res.schema
      };
    } else {
      const type = getThriftEnum(Type, schemaElement.type);
      let logicalType = type;
      if (schemaElement.converted_type) {
        logicalType = getThriftEnum(ConvertedType, schemaElement.converted_type);
      }
      switch (logicalType) {
        case "DECIMAL":
          logicalType = `${logicalType}_${type}`;
          break;
        default:
      }
      schema[schemaElement.name] = {
        type: logicalType,
        typeLength: schemaElement.type_length,
        presision: schemaElement.precision,
        scale: schemaElement.scale,
        optional,
        repeated
      };
      next++;
    }
  }
  return { schema, offset, next };
}
function decodeValues4(type, encoding, cursor, count, opts) {
  if (!(encoding in PARQUET_CODECS)) {
    throw new Error(`invalid encoding: ${encoding}`);
  }
  return PARQUET_CODECS[encoding].decodeValues(type, cursor, count, opts);
}
async function decodeDataPage(cursor, header, context) {
  var _a, _b, _c, _d;
  const cursorEnd = cursor.offset + header.compressed_page_size;
  const valueCount = (_a = header.data_page_header) == null ? void 0 : _a.num_values;
  let dataCursor = cursor;
  if (context.compression !== "UNCOMPRESSED") {
    const valuesBuf = await decompress(context.compression, cursor.buffer.slice(cursor.offset, cursorEnd), header.uncompressed_page_size);
    dataCursor = {
      buffer: valuesBuf,
      offset: 0,
      size: valuesBuf.length
    };
    cursor.offset = cursorEnd;
  }
  const rLevelEncoding = getThriftEnum(Encoding, (_b = header.data_page_header) == null ? void 0 : _b.repetition_level_encoding);
  let rLevels = new Array(valueCount);
  if (context.column.rLevelMax > 0) {
    rLevels = decodeValues4(PARQUET_RDLVL_TYPE, rLevelEncoding, dataCursor, valueCount, {
      bitWidth: getBitWidth(context.column.rLevelMax),
      disableEnvelope: false
      // column: opts.column
    });
  } else {
    rLevels.fill(0);
  }
  const dLevelEncoding = getThriftEnum(Encoding, (_c = header.data_page_header) == null ? void 0 : _c.definition_level_encoding);
  let dLevels = new Array(valueCount);
  if (context.column.dLevelMax > 0) {
    dLevels = decodeValues4(PARQUET_RDLVL_TYPE, dLevelEncoding, dataCursor, valueCount, {
      bitWidth: getBitWidth(context.column.dLevelMax),
      disableEnvelope: false
      // column: opts.column
    });
  } else {
    dLevels.fill(0);
  }
  let valueCountNonNull = 0;
  for (const dlvl of dLevels) {
    if (dlvl === context.column.dLevelMax) {
      valueCountNonNull++;
    }
  }
  const valueEncoding = getThriftEnum(Encoding, (_d = header.data_page_header) == null ? void 0 : _d.encoding);
  const decodeOptions = {
    typeLength: context.column.typeLength,
    bitWidth: context.column.typeLength
  };
  const values = decodeValues4(context.column.primitiveType, valueEncoding, dataCursor, valueCountNonNull, decodeOptions);
  return {
    dlevels: dLevels,
    rlevels: rLevels,
    values,
    count: valueCount,
    pageHeader: header
  };
}
async function decodeDataPageV2(cursor, header, context) {
  var _a, _b, _c, _d;
  const cursorEnd = cursor.offset + header.compressed_page_size;
  const valueCount = (_a = header.data_page_header_v2) == null ? void 0 : _a.num_values;
  const valueCountNonNull = valueCount - ((_b = header.data_page_header_v2) == null ? void 0 : _b.num_nulls);
  const valueEncoding = getThriftEnum(Encoding, (_c = header.data_page_header_v2) == null ? void 0 : _c.encoding);
  let rLevels = new Array(valueCount);
  if (context.column.rLevelMax > 0) {
    rLevels = decodeValues4(PARQUET_RDLVL_TYPE, PARQUET_RDLVL_ENCODING, cursor, valueCount, {
      bitWidth: getBitWidth(context.column.rLevelMax),
      disableEnvelope: true
    });
  } else {
    rLevels.fill(0);
  }
  let dLevels = new Array(valueCount);
  if (context.column.dLevelMax > 0) {
    dLevels = decodeValues4(PARQUET_RDLVL_TYPE, PARQUET_RDLVL_ENCODING, cursor, valueCount, {
      bitWidth: getBitWidth(context.column.dLevelMax),
      disableEnvelope: true
    });
  } else {
    dLevels.fill(0);
  }
  let valuesBufCursor = cursor;
  if ((_d = header.data_page_header_v2) == null ? void 0 : _d.is_compressed) {
    const valuesBuf = await decompress(context.compression, cursor.buffer.slice(cursor.offset, cursorEnd), header.uncompressed_page_size);
    valuesBufCursor = {
      buffer: valuesBuf,
      offset: 0,
      size: valuesBuf.length
    };
    cursor.offset = cursorEnd;
  }
  const decodeOptions = {
    typeLength: context.column.typeLength,
    bitWidth: context.column.typeLength
  };
  const values = decodeValues4(context.column.primitiveType, valueEncoding, valuesBufCursor, valueCountNonNull, decodeOptions);
  return {
    dlevels: dLevels,
    rlevels: rLevels,
    values,
    count: valueCount,
    pageHeader: header
  };
}
async function decodeDictionaryPage(cursor, pageHeader, context) {
  var _a;
  const cursorEnd = cursor.offset + pageHeader.compressed_page_size;
  let dictCursor = {
    offset: 0,
    buffer: cursor.buffer.slice(cursor.offset, cursorEnd),
    size: cursorEnd - cursor.offset
  };
  cursor.offset = cursorEnd;
  if (context.compression !== "UNCOMPRESSED") {
    const valuesBuf = await decompress(context.compression, dictCursor.buffer.slice(dictCursor.offset, cursorEnd), pageHeader.uncompressed_page_size);
    dictCursor = {
      buffer: valuesBuf,
      offset: 0,
      size: valuesBuf.length
    };
    cursor.offset = cursorEnd;
  }
  const numValues = ((_a = pageHeader == null ? void 0 : pageHeader.dictionary_page_header) == null ? void 0 : _a.num_values) || 0;
  const decodedDictionaryValues = decodeValues4(
    context.column.primitiveType,
    context.column.encoding,
    dictCursor,
    numValues,
    // TODO - this looks wrong?
    context
  );
  let values;
  if (context == null ? void 0 : context.preserveBinary) {
    values = decodedDictionaryValues.map((d) => preserveBinary(d));
  } else {
    values = decodedDictionaryValues.map((d) => d.toString());
  }
  return values;
}
function preserveBinary(d) {
  if (ArrayBuffer.isView(d)) {
    return d;
  }
  if (Buffer.isBuffer(d)) {
    return d.buffer.slice(d.byteOffset, d.byteLength);
  }
  return d.toString();
}

// dist/parquetjs/parser/parquet-reader.js
var _ParquetReader = class {
  props;
  file;
  metadata = null;
  constructor(file, props) {
    this.file = file;
    this.props = { ..._ParquetReader.defaultProps, ...props };
  }
  close() {
    this.file.close();
  }
  // HIGH LEVEL METHODS
  /** Yield one row at a time */
  async *rowIterator(props) {
    for await (const rows of this.rowBatchIterator(props)) {
      for (const row of rows) {
        yield row;
      }
    }
  }
  /** Yield one batch of rows at a time */
  async *rowBatchIterator(props) {
    const schema = await this.getSchema();
    for await (const rowGroup of this.rowGroupIterator(props)) {
      yield materializeRows(schema, rowGroup);
    }
  }
  /** Iterate over the raw row groups */
  async *rowGroupIterator(props) {
    const columnList = ((props == null ? void 0 : props.columnList) || []).map((x) => Array.isArray(x) ? x : [x]);
    const metadata = await this.getFileMetadata();
    const schema = await this.getSchema();
    const rowGroupCount = (metadata == null ? void 0 : metadata.row_groups.length) || 0;
    for (let rowGroupIndex = 0; rowGroupIndex < rowGroupCount; rowGroupIndex++) {
      const rowGroup = await this.readRowGroup(schema, metadata.row_groups[rowGroupIndex], columnList);
      yield rowGroup;
    }
  }
  async getRowCount() {
    const metadata = await this.getFileMetadata();
    return Number(metadata.num_rows);
  }
  async getSchema() {
    const metadata = await this.getFileMetadata();
    const root = metadata.schema[0];
    const { schema: schemaDefinition } = decodeSchema(metadata.schema, 1, root.num_children);
    const schema = new ParquetSchema(schemaDefinition);
    return schema;
  }
  /**
   * Returns the user (key/value) metadata for this file
   * In parquet this is not stored on the schema like it is in arrow
   */
  async getSchemaMetadata() {
    const metadata = await this.getFileMetadata();
    const md = {};
    for (const kv of metadata.key_value_metadata) {
      md[kv.key] = kv.value;
    }
    return md;
  }
  async getFileMetadata() {
    if (!this.metadata) {
      await this.readHeader();
      this.metadata = this.readFooter();
    }
    return this.metadata;
  }
  // LOW LEVEL METHODS
  /** Metadata is stored in the footer */
  async readHeader() {
    const arrayBuffer = await this.file.read(0, PARQUET_MAGIC.length);
    const buffer = Buffer.from(arrayBuffer);
    const magic = buffer.toString();
    switch (magic) {
      case PARQUET_MAGIC:
        break;
      case PARQUET_MAGIC_ENCRYPTED:
        throw new Error("Encrypted parquet file not supported");
      default:
        throw new Error(`Invalid parquet file (magic=${magic})`);
    }
  }
  /** Metadata is stored in the footer */
  async readFooter() {
    const trailerLen = PARQUET_MAGIC.length + 4;
    const arrayBuffer = await this.file.read(this.file.size - trailerLen, trailerLen);
    const trailerBuf = Buffer.from(arrayBuffer);
    const magic = trailerBuf.slice(4).toString();
    if (magic !== PARQUET_MAGIC) {
      throw new Error(`Not a valid parquet file (magic="${magic})`);
    }
    const metadataSize = trailerBuf.readUInt32LE(0);
    const metadataOffset = this.file.size - metadataSize - trailerLen;
    if (metadataOffset < PARQUET_MAGIC.length) {
      throw new Error(`Invalid metadata size ${metadataOffset}`);
    }
    const arrayBuffer2 = await this.file.read(metadataOffset, metadataSize);
    const metadataBuf = Buffer.from(arrayBuffer2);
    const { metadata } = decodeFileMetadata(metadataBuf);
    return metadata;
  }
  /** Data is stored in row groups (similar to Apache Arrow record batches) */
  async readRowGroup(schema, rowGroup, columnList) {
    const buffer = {
      rowCount: Number(rowGroup.num_rows),
      columnData: {}
    };
    for (const colChunk of rowGroup.columns) {
      const colMetadata = colChunk.meta_data;
      const colKey = colMetadata == null ? void 0 : colMetadata.path_in_schema;
      if (columnList.length > 0 && fieldIndexOf(columnList, colKey) < 0) {
        continue;
      }
      buffer.columnData[colKey.join()] = await this.readColumnChunk(schema, colChunk);
    }
    return buffer;
  }
  /**
   * Each row group contains column chunks for all the columns.
   */
  async readColumnChunk(schema, colChunk) {
    var _a, _b, _c, _d, _e, _f, _g, _h, _i;
    if (colChunk.file_path !== void 0 && colChunk.file_path !== null) {
      throw new Error("external references are not supported");
    }
    const field = schema.findField((_a = colChunk.meta_data) == null ? void 0 : _a.path_in_schema);
    const type = getThriftEnum(Type, (_b = colChunk.meta_data) == null ? void 0 : _b.type);
    if (type !== field.primitiveType) {
      throw new Error(`chunk type not matching schema: ${type}`);
    }
    const compression = getThriftEnum(CompressionCodec, (_c = colChunk.meta_data) == null ? void 0 : _c.codec);
    const pagesOffset = Number((_d = colChunk.meta_data) == null ? void 0 : _d.data_page_offset);
    let pagesSize = Number((_e = colChunk.meta_data) == null ? void 0 : _e.total_compressed_size);
    if (!colChunk.file_path) {
      pagesSize = Math.min(this.file.size - pagesOffset, Number((_f = colChunk.meta_data) == null ? void 0 : _f.total_compressed_size));
    }
    const context = {
      type,
      rLevelMax: field.rLevelMax,
      dLevelMax: field.dLevelMax,
      compression,
      column: field,
      numValues: (_g = colChunk.meta_data) == null ? void 0 : _g.num_values,
      dictionary: [],
      // Options - TBD is this the right place for these?
      preserveBinary: this.props.preserveBinary
    };
    let dictionary;
    const dictionaryPageOffset = (_h = colChunk == null ? void 0 : colChunk.meta_data) == null ? void 0 : _h.dictionary_page_offset;
    if (dictionaryPageOffset) {
      const dictionaryOffset = Number(dictionaryPageOffset);
      dictionary = await this.getDictionary(dictionaryOffset, context, pagesOffset);
    }
    dictionary = ((_i = context.dictionary) == null ? void 0 : _i.length) ? context.dictionary : dictionary;
    const arrayBuffer = await this.file.read(pagesOffset, pagesSize);
    const pagesBuf = Buffer.from(arrayBuffer);
    return await decodeDataPages(pagesBuf, { ...context, dictionary });
  }
  /**
   * Getting dictionary for allows to flatten values by indices.
   * @param dictionaryPageOffset
   * @param context
   * @param pagesOffset
   * @returns
   */
  async getDictionary(dictionaryPageOffset, context, pagesOffset) {
    if (dictionaryPageOffset === 0) {
      return [];
    }
    const dictionarySize = Math.min(this.file.size - dictionaryPageOffset, this.props.defaultDictionarySize);
    const arrayBuffer = await this.file.read(dictionaryPageOffset, dictionarySize);
    const pagesBuf = Buffer.from(arrayBuffer);
    const cursor = { buffer: pagesBuf, offset: 0, size: pagesBuf.length };
    const decodedPage = await decodePage(cursor, context);
    return decodedPage.dictionary;
  }
};
var ParquetReader = _ParquetReader;
__publicField(ParquetReader, "defaultProps", {
  // max ArrayBuffer size in js is 2Gb
  defaultDictionarySize: 2147483648,
  preserveBinary: false
});

// dist/lib/arrow/convert-schema-from-parquet.js
var PARQUET_TYPE_MAPPING = {
  BOOLEAN: "bool",
  INT32: "int32",
  INT64: "float64",
  INT96: "float64",
  FLOAT: "float32",
  DOUBLE: "float64",
  BYTE_ARRAY: "binary",
  FIXED_LEN_BYTE_ARRAY: "binary",
  UTF8: "utf8",
  DATE: "int32",
  TIME_MILLIS: "int64",
  TIME_MICROS: "int64",
  TIMESTAMP_MILLIS: "int64",
  TIMESTAMP_MICROS: "int64",
  UINT_8: "int32",
  UINT_16: "uint16",
  UINT_32: "uint32",
  UINT_64: "uint64",
  INT_8: "int8",
  INT_16: "int16",
  INT_32: "int32",
  INT_64: "int64",
  JSON: "binary",
  BSON: "binary",
  // TODO check interal type
  INTERVAL: "binary",
  DECIMAL_INT32: "float32",
  DECIMAL_INT64: "float64",
  DECIMAL_BYTE_ARRAY: "float64",
  DECIMAL_FIXED_LEN_BYTE_ARRAY: "float64"
};
function convertParquetSchema(parquetSchema, parquetMetadata) {
  const fields = getFields(parquetSchema.schema);
  const metadata = parquetMetadata && getSchemaMetadata(parquetMetadata);
  const schema = {
    fields,
    metadata: metadata || {}
  };
  return schema;
}
function getFields(schema) {
  const fields = [];
  for (const name in schema) {
    const field = schema[name];
    if (field.fields) {
      const children = getFields(field.fields);
      fields.push({ name, type: { type: "struct", children }, nullable: field.optional });
    } else {
      const type = PARQUET_TYPE_MAPPING[field.type];
      const metadata = getFieldMetadata(field);
      const arrowField = { name, type, nullable: field.optional, metadata };
      fields.push(arrowField);
    }
  }
  return fields;
}
function getFieldMetadata(field) {
  let metadata;
  for (const key in field) {
    if (key !== "name") {
      let value = field[key] || "";
      value = typeof field[key] !== "string" ? JSON.stringify(field[key]) : field[key];
      metadata = metadata || {};
      metadata[key] = value;
    }
  }
  return metadata;
}
function getSchemaMetadata(parquetMetadata) {
  let metadata;
  const keyValueList = parquetMetadata.key_value_metadata || [];
  for (const { key, value } of keyValueList) {
    if (typeof value === "string") {
      metadata = metadata || {};
      metadata[key] = value;
    }
  }
  return metadata;
}

// dist/lib/parsers/get-parquet-schema.js
var import_gis = require("@loaders.gl/gis");
async function getSchemaFromParquetReader(reader) {
  const parquetSchema = await reader.getSchema();
  const parquetMetadata = await reader.getFileMetadata();
  const schema = convertParquetSchema(parquetSchema, parquetMetadata);
  (0, import_gis.unpackGeoMetadata)(schema);
  (0, import_gis.unpackJSONStringMetadata)(schema, "pandas");
  return schema;
}

// dist/lib/parsers/parse-parquet.js
async function parseParquetFile(file, options) {
  var _a, _b;
  installBufferPolyfill();
  await preloadCompressions(options);
  const reader = new ParquetReader(file, {
    preserveBinary: (_a = options == null ? void 0 : options.parquet) == null ? void 0 : _a.preserveBinary
  });
  const schema = await getSchemaFromParquetReader(reader);
  const rows = [];
  const rowBatches = reader.rowBatchIterator(options == null ? void 0 : options.parquet);
  for await (const rowBatch of rowBatches) {
    let limitHasReached = false;
    for (const row of rowBatch) {
      if ((options == null ? void 0 : options.limit) && rows.length >= (options == null ? void 0 : options.limit)) {
        limitHasReached = true;
        break;
      }
      rows.push(row);
    }
    if (limitHasReached) {
      import_log.default.warn(`Rows number limit has been reached. Only first ${options == null ? void 0 : options.limit} are loaded`)();
      break;
    }
  }
  const objectRowTable = {
    shape: "object-row-table",
    schema,
    data: rows
  };
  const shape = (_b = options == null ? void 0 : options.parquet) == null ? void 0 : _b.shape;
  return convertTable(objectRowTable, shape);
}
async function* parseParquetFileInBatches(file, options) {
  var _a, _b;
  installBufferPolyfill();
  await preloadCompressions(options);
  const reader = new ParquetReader(file, {
    preserveBinary: (_a = options == null ? void 0 : options.parquet) == null ? void 0 : _a.preserveBinary
  });
  const schema = await getSchemaFromParquetReader(reader);
  const rowBatches = reader.rowBatchIterator(options == null ? void 0 : options.parquet);
  for await (const rows of rowBatches) {
    const objectRowTable = {
      shape: "object-row-table",
      schema,
      data: rows
    };
    const shape = (_b = options == null ? void 0 : options.parquet) == null ? void 0 : _b.shape;
    const table = convertTable(objectRowTable, shape);
    yield {
      batchType: "data",
      schema,
      ...table,
      length: rows.length
    };
  }
}
function convertTable(objectRowTable, shape) {
  switch (shape) {
    case "object-row-table":
      return objectRowTable;
    case "geojson-table":
      return objectRowTable;
    default:
      throw new Error(shape);
  }
}

// dist/lib/parsers/parse-geoparquet.js
var import_gis2 = require("@loaders.gl/gis");
var import_wkt = require("@loaders.gl/wkt");
async function parseGeoParquetFile(file, options) {
  var _a;
  const table = await parseParquetFile(file, { ...options, shape: "object-row-table" });
  const shape = (_a = options == null ? void 0 : options.parquet) == null ? void 0 : _a.shape;
  return convertTable2(table, shape);
}
async function* parseGeoParquetFileInBatches(file, options) {
  var _a;
  const tableBatches = parseParquetFileInBatches(file, { ...options, shape: "object-row-table" });
  for await (const batch of tableBatches) {
    const shape = (_a = options == null ? void 0 : options.parquet) == null ? void 0 : _a.shape;
    yield convertBatch(batch, shape);
  }
}
function convertTable2(objectRowTable, shape) {
  switch (shape) {
    case "object-row-table":
      return objectRowTable;
    case "geojson-table":
      try {
        return (0, import_gis2.convertWKBTableToGeoJSON)(objectRowTable, objectRowTable.schema, [
          import_wkt.WKTLoader,
          import_wkt.WKBLoader
        ]);
      } catch (error) {
        return objectRowTable;
      }
    default:
      throw new Error(shape);
  }
}
function convertBatch(objectRowBatch, shape) {
  switch (shape) {
    case "object-row-table":
      return objectRowBatch;
    case "geojson-table":
      try {
        const geojsonTable = (0, import_gis2.convertWKBTableToGeoJSON)(objectRowBatch, objectRowBatch.schema, [
          import_wkt.WKTLoader,
          import_wkt.WKBLoader
        ]);
        return {
          ...objectRowBatch,
          ...geojsonTable
        };
      } catch (error) {
        return objectRowBatch;
      }
    default:
      throw new Error(shape);
  }
}

// dist/lib/parsers/parse-parquet-to-columns.js
async function parseParquetFileInColumns(file, options) {
  installBufferPolyfill();
  await preloadCompressions(options);
  for await (const batch of parseParquetFileInColumnarBatches(file, options)) {
    return {
      shape: "columnar-table",
      schema: batch.schema,
      data: batch.data
    };
  }
  throw new Error("empty table");
}
async function* parseParquetFileInColumnarBatches(file, options) {
  installBufferPolyfill();
  await preloadCompressions(options);
  const reader = new ParquetReader(file);
  const schema = await getSchemaFromParquetReader(reader);
  const parquetSchema = await reader.getSchema();
  const rowGroups = reader.rowGroupIterator(options == null ? void 0 : options.parquet);
  for await (const rowGroup of rowGroups) {
    yield convertRowGroupToTableBatch(rowGroup, parquetSchema, schema);
  }
}
function convertRowGroupToTableBatch(rowGroup, parquetSchema, schema) {
  const data = materializeColumns(parquetSchema, rowGroup);
  return {
    shape: "columnar-table",
    batchType: "data",
    schema,
    data,
    length: rowGroup.rowCount
  };
}

// dist/parquet-loader.js
var VERSION2 = true ? "4.3.3" : "latest";
var ParquetWorkerLoader = {
  dataType: null,
  batchType: null,
  name: "Apache Parquet",
  id: "parquet",
  module: "parquet",
  version: VERSION2,
  worker: false,
  category: "table",
  extensions: ["parquet"],
  mimeTypes: ["application/octet-stream"],
  binary: true,
  tests: ["PAR1", "PARE"],
  options: {
    parquet: {
      shape: "object-row-table",
      columnList: [],
      geoparquet: true,
      url: void 0,
      preserveBinary: false
    }
  }
};
var ParquetLoader = {
  ...ParquetWorkerLoader,
  dataType: null,
  batchType: null,
  parse: (arrayBuffer, options) => parseParquetFile(new import_loader_utils2.BlobFile(arrayBuffer), options),
  parseFile: parseParquetFile,
  parseFileInBatches: parseParquetFileInBatches
};
ParquetLoader.Buffer = Buffer3;
var GeoParquetWorkerLoader = {
  dataType: null,
  batchType: null,
  name: "Apache Parquet",
  id: "parquet",
  module: "parquet",
  version: VERSION2,
  worker: true,
  category: "table",
  extensions: ["parquet"],
  mimeTypes: ["application/octet-stream"],
  binary: true,
  tests: ["PAR1", "PARE"],
  options: {
    parquet: {
      shape: "geojson-table",
      columnList: [],
      geoparquet: true,
      url: void 0,
      preserveBinary: false
    }
  }
};
var GeoParquetLoader = {
  ...GeoParquetWorkerLoader,
  parse(arrayBuffer, options) {
    return parseGeoParquetFile(new import_loader_utils2.BlobFile(arrayBuffer), options);
  },
  parseFile: parseGeoParquetFile,
  parseFileInBatches: parseGeoParquetFileInBatches
};
var ParquetColumnarWorkerLoader = {
  dataType: null,
  batchType: null,
  name: "Apache Parquet",
  id: "parquet",
  module: "parquet",
  version: VERSION2,
  worker: true,
  category: "table",
  extensions: ["parquet"],
  mimeTypes: ["application/octet-stream"],
  binary: true,
  tests: ["PAR1", "PARE"],
  options: ParquetLoader.options
};
var ParquetColumnarLoader = {
  ...ParquetColumnarWorkerLoader,
  parse(arrayBuffer, options) {
    return parseParquetFileInColumns(new import_loader_utils2.BlobFile(arrayBuffer), options);
  },
  parseFile: parseParquetFileInColumns,
  parseFileInBatches: parseParquetFileInColumnarBatches
};

// dist/parquet-writer.js
var VERSION3 = true ? "4.3.3" : "latest";
var ParquetWriter = {
  name: "Apache Parquet",
  id: "parquet",
  module: "parquet",
  version: VERSION3,
  extensions: ["parquet"],
  mimeTypes: ["application/octet-stream"],
  binary: true,
  options: {},
  encode: async (data, options) => encodeSync(data, options),
  encodeSync
};
function encodeSync(data, options) {
  return new ArrayBuffer(0);
}

// dist/parquet-wasm-loader.js
var import_loader_utils4 = require("@loaders.gl/loader-utils");

// dist/lib/parsers/parse-parquet-wasm.js
var import_arrow = require("@loaders.gl/arrow");
var arrow = __toESM(require("apache-arrow"), 1);

// dist/lib/utils/load-wasm.js
var import_parquet_wasm = __toESM(require("parquet-wasm"), 1);
var parquetWasm = __toESM(require("parquet-wasm"), 1);
var initializePromise;
async function loadWasm(wasmUrl = PARQUET_WASM_URL) {
  if (!initializePromise && typeof import_parquet_wasm.default === "function") {
    if (!wasmUrl) {
      throw new Error("ParquetLoader: No wasmUrl provided");
    }
    initializePromise = (0, import_parquet_wasm.default)(wasmUrl);
  }
  await initializePromise;
  return parquetWasm;
}

// dist/lib/utils/make-stream-iterator.js
var import_loader_utils3 = require("@loaders.gl/loader-utils");
function makeStreamIterator(stream, options) {
  return import_loader_utils3.isBrowser ? makeBrowserStreamIterator(stream, options) : makeNodeStreamIterator(stream, options);
}
async function* makeBrowserStreamIterator(stream, options) {
  const reader = stream.getReader();
  let nextBatchPromise;
  try {
    while (true) {
      const currentBatchPromise = nextBatchPromise || reader.read();
      if (options == null ? void 0 : options._streamReadAhead) {
        nextBatchPromise = reader.read();
      }
      const { done, value } = await currentBatchPromise;
      if (done) {
        return;
      }
      if (value) {
        yield value;
      }
    }
  } catch (error) {
    reader.releaseLock();
  }
}
async function* makeNodeStreamIterator(stream, options) {
  yield* stream;
}

// dist/lib/parsers/parse-parquet-wasm.js
async function parseParquetFileWasm(file, options) {
  const wasmUrl = options == null ? void 0 : options.wasmUrl;
  const wasm = await loadWasm(wasmUrl);
  let parquetFile;
  if (file.handle instanceof Blob) {
    parquetFile = await wasm.ParquetFile.fromFile(file.handle);
  } else {
    parquetFile = await wasm.ParquetFile.fromUrl(file.url);
  }
  const wasmTable = await parquetFile.read(options);
  const ipcStream = wasmTable.intoIPCStream();
  const arrowTable = arrow.tableFromIPC(ipcStream);
  return {
    shape: "arrow-table",
    schema: (0, import_arrow.serializeArrowSchema)(arrowTable.schema),
    data: arrowTable
  };
}
async function* parseParquetFileInBatchesWasm(file, options) {
  const wasmUrl = options == null ? void 0 : options.wasmUrl;
  const wasm = await loadWasm(wasmUrl);
  let parquetFile;
  if (file.handle instanceof Blob) {
    parquetFile = await wasm.ParquetFile.fromFile(file.handle);
  } else {
    parquetFile = await wasm.ParquetFile.fromUrl(file.url);
  }
  const stream = await parquetFile.stream(options);
  let schema;
  for await (const table of makeStreamIterator(stream)) {
    schema ||= (0, import_arrow.serializeArrowSchema)(table.schema);
    yield {
      batchType: "data",
      shape: "arrow-table",
      schema,
      data: table.batches[0],
      length: table.numRows
    };
  }
}

// dist/parquet-wasm-loader.js
var ParquetWasmWorkerLoader = {
  dataType: null,
  batchType: null,
  name: "Apache Parquet",
  id: "parquet-wasm",
  module: "parquet",
  version: VERSION,
  worker: false,
  category: "table",
  extensions: ["parquet"],
  mimeTypes: ["application/octet-stream"],
  binary: true,
  tests: ["PAR1", "PARE"],
  options: {
    parquet: {
      shape: "arrow-table",
      limit: void 0,
      // Provide a limit to the number of rows to be read.
      offset: 0,
      // Provide an offset to skip over the given number of rows.
      batchSize: void 0,
      // The number of rows in each batch. If not provided, the upstream parquet default is 1024.
      columns: void 0,
      // The column names from the file to read.
      rowGroups: void 0,
      // Only read data from the provided row group indexes.
      concurrency: void 0,
      // The number of concurrent requests to make
      wasmUrl: PARQUET_WASM_URL
    }
  }
};
var ParquetWasmLoader = {
  ...ParquetWasmWorkerLoader,
  parse(arrayBuffer, options) {
    const wasmOptions = { ...ParquetWasmLoader.options.parquet, ...options == null ? void 0 : options.parquet };
    return parseParquetFileWasm(new import_loader_utils4.BlobFile(arrayBuffer), wasmOptions);
  },
  parseFile(file, options) {
    const wasmOptions = { ...ParquetWasmLoader.options.parquet, ...options == null ? void 0 : options.parquet };
    return parseParquetFileWasm(file, wasmOptions);
  },
  parseFileInBatches(file, options) {
    const wasmOptions = { ...ParquetWasmLoader.options.parquet, ...options == null ? void 0 : options.parquet };
    return parseParquetFileInBatchesWasm(file, wasmOptions);
  }
};

// dist/lib/encoders/encode-parquet-wasm.js
var arrow2 = __toESM(require("apache-arrow"), 1);
async function encode(table, options) {
  var _a;
  const wasmUrl = (_a = options.parquet) == null ? void 0 : _a.wasmUrl;
  const wasm = await loadWasm(wasmUrl);
  const arrowTable = table.data;
  const ipcStream = arrow2.tableToIPC(arrowTable);
  const wasmTable = wasm.Table.fromIPCStream(ipcStream);
  const wasmProperties = new wasm.WriterPropertiesBuilder().build();
  try {
    const parquetBytes = wasm.writeParquet(wasmTable, wasmProperties);
    return parquetBytes.buffer.slice(parquetBytes.byteOffset, parquetBytes.byteLength + parquetBytes.byteOffset);
  } finally {
  }
}

// dist/parquet-wasm-writer.js
var ParquetWasmWriter = {
  name: "Apache Parquet",
  id: "parquet-wasm",
  module: "parquet",
  version: VERSION,
  extensions: ["parquet"],
  mimeTypes: ["application/octet-stream"],
  binary: true,
  options: {
    parquet: {
      wasmUrl: PARQUET_WASM_URL
    }
  },
  encode(arrowTable, options) {
    options = { parquet: { ...ParquetWasmWriter.options.parquet, ...options == null ? void 0 : options.parquet }, ...options };
    return encode(arrowTable, options);
  }
};

// dist/parquetjs/utils/file-utils.js
var fs = __toESM(require("fs"), 1);
function oswrite(os, buf) {
  return new Promise((resolve, reject) => {
    os.write(buf, (err) => {
      if (err) {
        reject(err);
      } else {
        resolve();
      }
    });
  });
}
function osclose(os) {
  return new Promise((resolve, reject) => {
    os.close((err) => {
      if (err) {
        reject(err);
      } else {
        resolve();
      }
    });
  });
}
function osopen(path, opts) {
  return new Promise((resolve, reject) => {
    const outputStream = fs.createWriteStream(path, opts);
    outputStream.once("open", (fd) => resolve(outputStream));
    outputStream.once("error", (err) => reject(err));
  });
}

// dist/parquetjs/encoder/parquet-encoder.js
var import_node_int646 = __toESM(require("node-int64"), 1);
var PARQUET_MAGIC2 = "PAR1";
var PARQUET_VERSION = 1;
var PARQUET_DEFAULT_PAGE_SIZE = 8192;
var PARQUET_DEFAULT_ROW_GROUP_SIZE = 4096;
var PARQUET_RDLVL_TYPE2 = "INT32";
var PARQUET_RDLVL_ENCODING2 = "RLE";
var ParquetEncoder = class {
  /**
   * Convenience method to create a new buffered parquet writer that writes to
   * the specified file
   */
  static async openFile(schema, path, opts) {
    const outputStream = await osopen(path, opts);
    return ParquetEncoder.openStream(schema, outputStream, opts);
  }
  /**
   * Convenience method to create a new buffered parquet writer that writes to
   * the specified stream
   */
  static async openStream(schema, outputStream, opts = {}) {
    const envelopeWriter = await ParquetEnvelopeWriter.openStream(schema, outputStream, opts);
    return new ParquetEncoder(schema, envelopeWriter, opts);
  }
  schema;
  envelopeWriter;
  rowBuffer;
  rowGroupSize;
  closed;
  userMetadata;
  /**
   * Create a new buffered parquet writer for a given envelope writer
   */
  constructor(schema, envelopeWriter, opts) {
    this.schema = schema;
    this.envelopeWriter = envelopeWriter;
    this.rowBuffer = {};
    this.rowGroupSize = opts.rowGroupSize || PARQUET_DEFAULT_ROW_GROUP_SIZE;
    this.closed = false;
    this.userMetadata = {};
    this.writeHeader();
  }
  async writeHeader() {
    try {
      await this.envelopeWriter.writeHeader();
    } catch (err) {
      await this.envelopeWriter.close();
      throw err;
    }
  }
  /**
   * Append a single row to the parquet file. Rows are buffered in memory until
   * rowGroupSize rows are in the buffer or close() is called
   */
  async appendRow(row) {
    if (this.closed) {
      throw new Error("writer was closed");
    }
    shredRecord(this.schema, row, this.rowBuffer);
    if (this.rowBuffer.rowCount >= this.rowGroupSize) {
      this.rowBuffer = {};
    }
  }
  /**
   * Finish writing the parquet file and commit the footer to disk. This method
   * MUST be called after you are finished adding rows. You must not call this
   * method twice on the same object or add any rows after the close() method has
   * been called
   */
  async close(callback) {
    if (this.closed) {
      throw new Error("writer was closed");
    }
    this.closed = true;
    if (this.rowBuffer.rowCount > 0 || this.rowBuffer.rowCount >= this.rowGroupSize) {
      this.rowBuffer = {};
    }
    await this.envelopeWriter.writeFooter(this.userMetadata);
    await this.envelopeWriter.close();
    if (callback) {
      callback();
    }
  }
  /**
   * Add key<>value metadata to the file
   */
  setMetadata(key, value) {
    this.userMetadata[String(key)] = String(value);
  }
  /**
   * Set the parquet row group size. This values controls the maximum number
   * of rows that are buffered in memory at any given time as well as the number
   * of rows that are co-located on disk. A higher value is generally better for
   * read-time I/O performance at the tradeoff of write-time memory usage.
   */
  setRowGroupSize(cnt) {
    this.rowGroupSize = cnt;
  }
  /**
   * Set the parquet data page size. The data page size controls the maximum
   * number of column values that are written to disk as a consecutive array
   */
  setPageSize(cnt) {
    this.envelopeWriter.setPageSize(cnt);
  }
};
var ParquetEnvelopeWriter = class {
  /**
   * Create a new parquet envelope writer that writes to the specified stream
   */
  static async openStream(schema, outputStream, opts) {
    const writeFn = oswrite.bind(void 0, outputStream);
    const closeFn = osclose.bind(void 0, outputStream);
    return new ParquetEnvelopeWriter(schema, writeFn, closeFn, 0, opts);
  }
  schema;
  write;
  close;
  offset;
  rowCount;
  rowGroups;
  pageSize;
  useDataPageV2;
  constructor(schema, writeFn, closeFn, fileOffset, opts) {
    this.schema = schema;
    this.write = writeFn;
    this.close = closeFn;
    this.offset = fileOffset;
    this.rowCount = 0;
    this.rowGroups = [];
    this.pageSize = opts.pageSize || PARQUET_DEFAULT_PAGE_SIZE;
    this.useDataPageV2 = "useDataPageV2" in opts ? Boolean(opts.useDataPageV2) : false;
  }
  writeSection(buf) {
    this.offset += buf.length;
    return this.write(buf);
  }
  /**
   * Encode the parquet file header
   */
  writeHeader() {
    return this.writeSection(Buffer.from(PARQUET_MAGIC2));
  }
  /**
   * Encode a parquet row group. The records object should be created using the
   * shredRecord method
   */
  async writeRowGroup(records) {
    const rgroup = await encodeRowGroup(this.schema, records, {
      baseOffset: this.offset,
      pageSize: this.pageSize,
      useDataPageV2: this.useDataPageV2
    });
    this.rowCount += records.rowCount;
    this.rowGroups.push(rgroup.metadata);
    return await this.writeSection(rgroup.body);
  }
  /**
   * Write the parquet file footer
   */
  writeFooter(userMetadata) {
    if (!userMetadata) {
      userMetadata = {};
    }
    return this.writeSection(encodeFooter(this.schema, this.rowCount, this.rowGroups, userMetadata));
  }
  /**
   * Set the parquet data page size. The data page size controls the maximum
   * number of column values that are written to disk as a consecutive array
   */
  setPageSize(cnt) {
    this.pageSize = cnt;
  }
};
function encodeValues4(type, encoding, values, opts) {
  if (!(encoding in PARQUET_CODECS)) {
    throw new Error(`invalid encoding: ${encoding}`);
  }
  return PARQUET_CODECS[encoding].encodeValues(type, values, opts);
}
async function encodeDataPage(column, data) {
  let rLevelsBuf = Buffer.alloc(0);
  if (column.rLevelMax > 0) {
    rLevelsBuf = encodeValues4(PARQUET_RDLVL_TYPE2, PARQUET_RDLVL_ENCODING2, data.rlevels, {
      bitWidth: getBitWidth(column.rLevelMax)
      // disableEnvelope: false
    });
  }
  let dLevelsBuf = Buffer.alloc(0);
  if (column.dLevelMax > 0) {
    dLevelsBuf = encodeValues4(PARQUET_RDLVL_TYPE2, PARQUET_RDLVL_ENCODING2, data.dlevels, {
      bitWidth: getBitWidth(column.dLevelMax)
      // disableEnvelope: false
    });
  }
  const valuesBuf = encodeValues4(column.primitiveType, column.encoding, data.values, {
    typeLength: column.typeLength,
    bitWidth: column.typeLength
  });
  const dataBuf = Buffer.concat([rLevelsBuf, dLevelsBuf, valuesBuf]);
  const compressedBuf = await deflate(column.compression, dataBuf);
  const header = new PageHeader({
    type: PageType.DATA_PAGE,
    data_page_header: new DataPageHeader({
      num_values: data.count,
      encoding: Encoding[column.encoding],
      definition_level_encoding: Encoding[PARQUET_RDLVL_ENCODING2],
      // [PARQUET_RDLVL_ENCODING],
      repetition_level_encoding: Encoding[PARQUET_RDLVL_ENCODING2]
      // [PARQUET_RDLVL_ENCODING]
    }),
    uncompressed_page_size: dataBuf.length,
    compressed_page_size: compressedBuf.length
  });
  const headerBuf = serializeThrift(header);
  const page = Buffer.concat([headerBuf, compressedBuf]);
  return { header, headerSize: headerBuf.length, page };
}
async function encodeDataPageV2(column, data, rowCount) {
  const valuesBuf = encodeValues4(column.primitiveType, column.encoding, data.values, {
    typeLength: column.typeLength,
    bitWidth: column.typeLength
  });
  const compressedBuf = await deflate(column.compression, valuesBuf);
  let rLevelsBuf = Buffer.alloc(0);
  if (column.rLevelMax > 0) {
    rLevelsBuf = encodeValues4(PARQUET_RDLVL_TYPE2, PARQUET_RDLVL_ENCODING2, data.rlevels, {
      bitWidth: getBitWidth(column.rLevelMax),
      disableEnvelope: true
    });
  }
  let dLevelsBuf = Buffer.alloc(0);
  if (column.dLevelMax > 0) {
    dLevelsBuf = encodeValues4(PARQUET_RDLVL_TYPE2, PARQUET_RDLVL_ENCODING2, data.dlevels, {
      bitWidth: getBitWidth(column.dLevelMax),
      disableEnvelope: true
    });
  }
  const header = new PageHeader({
    type: PageType.DATA_PAGE_V2,
    data_page_header_v2: new DataPageHeaderV2({
      num_values: data.count,
      num_nulls: data.count - data.values.length,
      num_rows: rowCount,
      encoding: Encoding[column.encoding],
      definition_levels_byte_length: dLevelsBuf.length,
      repetition_levels_byte_length: rLevelsBuf.length,
      is_compressed: column.compression !== "UNCOMPRESSED"
    }),
    uncompressed_page_size: rLevelsBuf.length + dLevelsBuf.length + valuesBuf.length,
    compressed_page_size: rLevelsBuf.length + dLevelsBuf.length + compressedBuf.length
  });
  const headerBuf = serializeThrift(header);
  const page = Buffer.concat([headerBuf, rLevelsBuf, dLevelsBuf, compressedBuf]);
  return { header, headerSize: headerBuf.length, page };
}
async function encodeColumnChunk(column, buffer, offset, opts) {
  const data = buffer.columnData[column.path.join()];
  const baseOffset = (opts.baseOffset || 0) + offset;
  let pageBuf;
  let total_uncompressed_size = 0;
  let total_compressed_size = 0;
  {
    const result = opts.useDataPageV2 ? await encodeDataPageV2(column, data, buffer.rowCount) : await encodeDataPage(column, data);
    pageBuf = result.page;
    total_uncompressed_size += result.header.uncompressed_page_size + result.headerSize;
    total_compressed_size += result.header.compressed_page_size + result.headerSize;
  }
  const metadata = new ColumnMetaData({
    path_in_schema: column.path,
    num_values: data.count,
    data_page_offset: baseOffset,
    encodings: [],
    total_uncompressed_size,
    //  : pagesBuf.length,
    total_compressed_size,
    type: Type[column.primitiveType],
    codec: CompressionCodec[column.compression]
  });
  metadata.encodings.push(Encoding[PARQUET_RDLVL_ENCODING2]);
  metadata.encodings.push(Encoding[column.encoding]);
  const metadataOffset = baseOffset + pageBuf.length;
  const body = Buffer.concat([pageBuf, serializeThrift(metadata)]);
  return { body, metadata, metadataOffset };
}
async function encodeRowGroup(schema, data, opts) {
  const metadata = new RowGroup({
    num_rows: data.rowCount,
    columns: [],
    total_byte_size: 0
  });
  let body = Buffer.alloc(0);
  for (const field of schema.fieldList) {
    if (field.isNested) {
      continue;
    }
    const cchunkData = await encodeColumnChunk(field, data, body.length, opts);
    const cchunk = new ColumnChunk({
      file_offset: cchunkData.metadataOffset,
      meta_data: cchunkData.metadata
    });
    metadata.columns.push(cchunk);
    metadata.total_byte_size = new import_node_int646.default(Number(metadata.total_byte_size) + cchunkData.body.length);
    body = Buffer.concat([body, cchunkData.body]);
  }
  return { body, metadata };
}
function encodeFooter(schema, rowCount, rowGroups, userMetadata) {
  var _a, _b;
  const metadata = new FileMetaData({
    version: PARQUET_VERSION,
    created_by: "parquets",
    num_rows: rowCount,
    row_groups: rowGroups,
    schema: [],
    key_value_metadata: []
  });
  for (const key in userMetadata) {
    const kv = new KeyValue({
      key,
      value: userMetadata[key]
    });
    (_b = (_a = metadata.key_value_metadata) == null ? void 0 : _a.push) == null ? void 0 : _b.call(_a, kv);
  }
  {
    const schemaRoot = new SchemaElement({
      name: "root",
      num_children: Object.keys(schema.fields).length
    });
    metadata.schema.push(schemaRoot);
  }
  for (const field of schema.fieldList) {
    const relt = FieldRepetitionType[field.repetitionType];
    const schemaElem = new SchemaElement({
      name: field.name,
      repetition_type: relt
    });
    if (field.isNested) {
      schemaElem.num_children = field.fieldCount;
    } else {
      schemaElem.type = Type[field.primitiveType];
    }
    if (field.originalType) {
      schemaElem.converted_type = ConvertedType[field.originalType];
    }
    schemaElem.type_length = field.typeLength;
    metadata.schema.push(schemaElem);
  }
  const metadataEncoded = serializeThrift(metadata);
  const footerEncoded = Buffer.alloc(metadataEncoded.length + 8);
  metadataEncoded.copy(footerEncoded);
  footerEncoded.writeUInt32LE(metadataEncoded.length, metadataEncoded.length);
  footerEncoded.write(PARQUET_MAGIC2, metadataEncoded.length + 4);
  return footerEncoded;
}
/* !
 * The buffer module from node.js, for the browser.
 * @author   Feross Aboukhadijeh <https://feross.org>
 * @license  MIT
 * https://github.com/feross/buffer/blob/master/AUTHORS.md
 */
//# sourceMappingURL=index.cjs.map
