export type CSVParserConfig = {
    dynamicTyping?: boolean | Function | {};
    dynamicTypingFunction?: Function;
    chunk?: boolean;
    chunkSize?: number | null;
    step?: Function;
    transform?: boolean;
    preview?: number;
    newline?: string;
    comments?: boolean;
    skipEmptyLines?: boolean | 'greedy';
    delimitersToGuess?: string[];
    quoteChar?: string;
    escapeChar?: string;
    delimiter?: string;
    fastMode?: boolean;
};
declare function CsvToJson(_input: any, _config?: CSVParserConfig, Streamer?: any): any;
declare function JsonToCsv(_input: any, _config: any): string;
/** ChunkStreamer is the base prototype for various streamer implementations. */
declare class ChunkStreamer {
    _handle: any;
    _config: any;
    _finished: boolean;
    _completed: boolean;
    _input: null;
    _baseIndex: number;
    _partialLine: string;
    _rowCount: number;
    _start: number;
    isFirstChunk: boolean;
    _completeResults: {
        data: never[];
        errors: never[];
        meta: {};
    };
    constructor(config: CSVParserConfig);
    parseChunk(chunk: any, isFakeChunk?: boolean): any;
    _sendError(error: any): void;
}
declare class ParserHandle {
    _config: any;
    /** Number of times step was called (number of rows parsed) */
    _stepCounter: number;
    /** Number of rows that have been parsed so far */
    _rowCounter: number;
    /** The input being parsed */
    _input: any;
    /** The core parser being used */
    _parser: any;
    /** Whether we are paused or not */
    _paused: boolean;
    /** Whether the parser has aborted or not */
    _aborted: boolean;
    /** Temporary state between delimiter detection and processing results */
    _delimiterError: boolean;
    /** Fields are from the header row of the input, if there is one */
    _fields: string[];
    /** The last results returned from the parser */
    _results: {
        data: any[][] | Record<string, any>[];
        errors: any[];
        meta: Record<string, any>;
    };
    constructor(_config: CSVParserConfig);
    /**
     * Parses input. Most users won't need, and shouldn't mess with, the baseIndex
     * and ignoreLastRow parameters. They are used by streamers (wrapper functions)
     * when an input comes in multiple chunks, like from a file.
     */
    parse(input: any, baseIndex: any, ignoreLastRow: any): {
        data: any[][] | Record<string, any>[];
        errors: any[];
        meta: Record<string, any>;
    } | {
        meta: {
            paused: boolean;
        };
    };
    paused(): boolean;
    pause(): void;
    resume(): void;
    aborted(): boolean;
    abort(): void;
    testEmptyLine(s: any): boolean;
    processResults(): {
        data: any[][] | Record<string, any>[];
        errors: any[];
        meta: Record<string, any>;
    };
    needsHeaderRow(): any;
    fillHeaderFields(): void;
    shouldApplyDynamicTyping(field: any): boolean;
    parseDynamic(field: any, value: any): any;
    applyHeaderAndDynamicTypingAndTransformation(): {
        data: any[][] | Record<string, any>[];
        errors: any[];
        meta: Record<string, any>;
    };
    processRow(rowSource: any, i: any): any[] | Record<string, any>;
    guessDelimiter(input: any, newline: any, skipEmptyLines: any, comments: any, delimitersToGuess: any): {
        successful: boolean;
        bestDelimiter: any;
    };
    addError(type: any, code: any, msg: any, row?: any): void;
}
/** The core parser implements speedy and correct CSV parsing */
declare function Parser(config: any): void;
declare const Papa: {
    parse: typeof CsvToJson;
    unparse: typeof JsonToCsv;
    RECORD_SEP: string;
    UNIT_SEP: string;
    BYTE_ORDER_MARK: string;
    BAD_DELIMITERS: string[];
    WORKERS_SUPPORTED: boolean;
    NODE_STREAM_INPUT: number;
    LocalChunkSize: number;
    RemoteChunkSize: number;
    DefaultDelimiter: string;
    Parser: typeof Parser;
    ParserHandle: typeof ParserHandle;
    ChunkStreamer: typeof ChunkStreamer;
};
export default Papa;
//# sourceMappingURL=papaparse.d.ts.map